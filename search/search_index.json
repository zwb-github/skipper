{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 This is the documentation page of Skipper . Skipper is an HTTP router and reverse proxy for service composition. It\u2019s designed to handle large amounts of dynamically configured HTTP route definitions (>800000 routes) with detailed lookup conditions, and flexible augmentation of the request flow with filters. It can be used out of the box or extended with custom lookup, filter logic and configuration sources. HTTP Proxy \u00b6 Skipper identifies routes based on the requests\u2019 properties, such as path, method, host and headers using the predicates . It allows the modification of the requests and responses with filters that are independently configured for each route. Learn here more about how it works. Kubernetes Ingress \u00b6 Skipper can be used to run as a Kubernetes Ingress controller. Details with examples of Skipper\u2019s capabilities and an overview can be found in the ingress-controller deployment docs .","title":"Introduction"},{"location":"#introduction","text":"This is the documentation page of Skipper . Skipper is an HTTP router and reverse proxy for service composition. It\u2019s designed to handle large amounts of dynamically configured HTTP route definitions (>800000 routes) with detailed lookup conditions, and flexible augmentation of the request flow with filters. It can be used out of the box or extended with custom lookup, filter logic and configuration sources.","title":"Introduction"},{"location":"#http-proxy","text":"Skipper identifies routes based on the requests\u2019 properties, such as path, method, host and headers using the predicates . It allows the modification of the requests and responses with filters that are independently configured for each route. Learn here more about how it works.","title":"HTTP Proxy"},{"location":"#kubernetes-ingress","text":"Skipper can be used to run as a Kubernetes Ingress controller. Details with examples of Skipper\u2019s capabilities and an overview can be found in the ingress-controller deployment docs .","title":"Kubernetes Ingress"},{"location":"data-clients/eskip-file/","text":"Eskip File \u00b6 Eskip file dataclient can be used to serve static defined routes, read from an eskip file. The file format eskip shows your route definitions in a clear way: % cat example.eskip hello : Path ( \" / hello \" ) -> \" https : // www . example . org \" ' The Skipper project has two binaries, one is skipper , the other is eskip . Eskip can be used to validate the syntax of your routes file before reloading a production server: % eskip check example.eskip To run Skipper serving routes from an eskip file you have to use -routes-file <file> parameter: % skipper -routes-file example.eskip A more complicated example with different routes, matches, predicates and filters shows that you can name your route and use preconditions and create, change, delete HTTP headers as you like: % cat complicated_example.eskip hostHeaderMatch : Host ( \"^ skipper . teapot . org $\" ) -> setRequestHeader ( \" Authorization \" , \" Basic YWRtaW46YWRtaW5zcGFzc3dvcmQK \" ) -> \" https : // target - to . auth - with . basic - auth . enterprise . com \" ; baiduPathMatch : Path ( \" / baidu \" ) -> setRequestHeader ( \" Host \" , \" www . baidu . com \" ) -> setPath ( \" / s \" ) -> setQuery ( \" wd \" , \" godoc skipper \" ) -> \" http : // www . baidu . com \" ; googleWildcardMatch : * -> setPath ( \" / search \" ) -> setQuery ( \" q \" , \" godoc skipper \" ) -> \" https : // www . google . com \" ; yandexWildacardIfCookie : * && Cookie ( \" yandex \" , \" true \" ) -> setPath ( \" / search / \" ) -> setQuery ( \" text \" , \" godoc skipper \" ) -> tee ( \" http : // 127.0 . 0.1 : 12345 / \" ) -> \" https : // yandex . ru \" ; The former example shows 4 routes: hostHeaderMatch, baiduPathMatch, googleWildcardMatch and yandexWildcardIfCookie. hostHeaderMatch: used if HTTP host header is exactly: \u201cskipper.teapot.org\u201d, sets a Basic Authorization header and sends the modified request to https://target-to.auth-with.basic-auth.enterprise.com baiduPathMatch: used in case the request patch matches /baidu it will set the Host header to the proxy request it will set the path from /baidu to /s it will set the querystring to \u201cws=godoc skipper\u201d and sends the modified request to http://baidu.com googleWildcardMatch: used as default if no other route matches it will set the path to /search it will set the querystring to \u201cq=godoc skipper\u201d and sends the modified request to https://www.google.com yandexWildcardIfCookie: used as default if a Cookie named \u201cyandex\u201d has the value \u201ctrue\u201d it will set the path to /search/ it will set the querystring to \u201ctext=godoc skipper\u201d it will send a copy of the modified request to http://127.0.0.1:12345/ (similar to unix tee ) and drop the response and sends the modified request to https://yandex.ru More examples you find in eskip file format description, in filters and in predicates . Eskip file format is also used if you print your current routes in skipper, for example (metrics listener required): % curl localhost:9911/routes * -> setResponseHeader ( \" Content - Type \" , \" application / json ; charset = utf - 8 \" ) -> inlineContent ( \" { \\ \" foo \\ \" : 3 } \" ) -> < shunt >","title":"Eskip File"},{"location":"data-clients/eskip-file/#eskip-file","text":"Eskip file dataclient can be used to serve static defined routes, read from an eskip file. The file format eskip shows your route definitions in a clear way: % cat example.eskip hello : Path ( \" / hello \" ) -> \" https : // www . example . org \" ' The Skipper project has two binaries, one is skipper , the other is eskip . Eskip can be used to validate the syntax of your routes file before reloading a production server: % eskip check example.eskip To run Skipper serving routes from an eskip file you have to use -routes-file <file> parameter: % skipper -routes-file example.eskip A more complicated example with different routes, matches, predicates and filters shows that you can name your route and use preconditions and create, change, delete HTTP headers as you like: % cat complicated_example.eskip hostHeaderMatch : Host ( \"^ skipper . teapot . org $\" ) -> setRequestHeader ( \" Authorization \" , \" Basic YWRtaW46YWRtaW5zcGFzc3dvcmQK \" ) -> \" https : // target - to . auth - with . basic - auth . enterprise . com \" ; baiduPathMatch : Path ( \" / baidu \" ) -> setRequestHeader ( \" Host \" , \" www . baidu . com \" ) -> setPath ( \" / s \" ) -> setQuery ( \" wd \" , \" godoc skipper \" ) -> \" http : // www . baidu . com \" ; googleWildcardMatch : * -> setPath ( \" / search \" ) -> setQuery ( \" q \" , \" godoc skipper \" ) -> \" https : // www . google . com \" ; yandexWildacardIfCookie : * && Cookie ( \" yandex \" , \" true \" ) -> setPath ( \" / search / \" ) -> setQuery ( \" text \" , \" godoc skipper \" ) -> tee ( \" http : // 127.0 . 0.1 : 12345 / \" ) -> \" https : // yandex . ru \" ; The former example shows 4 routes: hostHeaderMatch, baiduPathMatch, googleWildcardMatch and yandexWildcardIfCookie. hostHeaderMatch: used if HTTP host header is exactly: \u201cskipper.teapot.org\u201d, sets a Basic Authorization header and sends the modified request to https://target-to.auth-with.basic-auth.enterprise.com baiduPathMatch: used in case the request patch matches /baidu it will set the Host header to the proxy request it will set the path from /baidu to /s it will set the querystring to \u201cws=godoc skipper\u201d and sends the modified request to http://baidu.com googleWildcardMatch: used as default if no other route matches it will set the path to /search it will set the querystring to \u201cq=godoc skipper\u201d and sends the modified request to https://www.google.com yandexWildcardIfCookie: used as default if a Cookie named \u201cyandex\u201d has the value \u201ctrue\u201d it will set the path to /search/ it will set the querystring to \u201ctext=godoc skipper\u201d it will send a copy of the modified request to http://127.0.0.1:12345/ (similar to unix tee ) and drop the response and sends the modified request to https://yandex.ru More examples you find in eskip file format description, in filters and in predicates . Eskip file format is also used if you print your current routes in skipper, for example (metrics listener required): % curl localhost:9911/routes * -> setResponseHeader ( \" Content - Type \" , \" application / json ; charset = utf - 8 \" ) -> inlineContent ( \" { \\ \" foo \\ \" : 3 } \" ) -> < shunt >","title":"Eskip File"},{"location":"data-clients/etcd/","text":"etcd \u00b6 etcd is an open-source distributed key value store: https://github.com/etcd-io/etcd . Skipper can use it as a route configuration storage and continuously synchronize the routing from etcd. Why storing Skipper routes in etcd? \u00b6 When running multiple Skipper instances, changing the configuration of each instance by accessing the instances directly on the fly can be complex and error-prone. With etcd, we need to update the routes only in etcd and each Skipper instance will synchronize its routing from the new version. Further benefits of using etcd are improved resiliency and the usage of a standard configuration storage for various system components of a distributed system, not only Skipper. Note : in case of Kubernetes, the standard recommended way is to use the Kubernetes Ingress API . Starting Skipper with etcd \u00b6 Example: skipper -etcd-urls http://localhost:2379,http://localhost:4001 An additional startup option is the -etcd-prefix . When using multiple Skipper deployments with different purpose, this option allows us to store separate configuration sets for them in the same etcd cluster. Example: skipper -etcd-urls https://cluster-config -etcd-prefix skipper1 Note : when the etcd URL points to an etcd proxy , Skipper will internally use the proxy only to resolve the URLs of the etcd replicas, and access them for the route configuration directly. etcd version \u00b6 Skipper uses currently the V2 API of etcd. Storage schema \u00b6 Skipper expects to find the route configuration by default at the /v2/keys/skipper/routes path. In this path, the \u2018skipper\u2019 segment can be optionally overridden by the -etcd-prefix startup option. The /v2/keys/skipper/routes node is a directory that contains the routes as individual child nodes, accessed by the path /v2/keys/skipper/routes/<routeID> . The value of the route nodes is the route expression without the route ID in eskip format . Maintaining route configuration in etcd \u00b6 etcd (v2) allows generic access to its API via the HTTP protocol. It also provides a supporting client tool: etcdctl. Following the above described schema, both of them can be used to maintain Skipper routes. In addition, Skipper also provides a supporting client tool: eskip , which can provide more convenient access to the routes in etcd. Getting all routes, a single route, insert or update and delete via HTTP: curl http://localhost:2379/v2/keys/skipper/routes curl http://localhost:2379/v2/keys/skipper/routes/hello curl -X PUT -d 'value=* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' http://localhost:2379/v2/keys/skipper/routes/hello curl -X DELETE http://localhost:2379/v2/keys/skipper/routes/hello Getting all route IDs, a route expression stored with an ID, insert or update and delete with etcdctl: etcdctl --endpoints http://localhost:2379,http://localhost:4001 ls /skipper/routes etcdctl --endpoints http://localhost:2379,http://localhost:4001 get /skipper/routes/hello etcdctl --endpoints http://localhost:2379,http://localhost:4001 set -- /skipper/routes/hello '* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' etcdctl --endpoints http://localhost:2379,http://localhost:4001 rm /skipper/routes/bello We use the name \u2018eskip\u2019 for two related concepts: the eskip syntax of route configuration and the eskip command line tool. The command line tool can be used to check the syntax of skipper routes, format route files, prepend or append filters to multiple routes, and also to access etcd. Getting all routes, a single route, insert or update and delete with eskip: eskip print -etcd-urls http://localhost:2379,http://localhost:4001 eskip print -etcd-urls http://localhost:2379,http://localhost:4001 | grep hello eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 -routes 'hello: * -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' eskip delete -etcd-urls http://localhost:2379,http://localhost:4001 -ids hello When storing multiple configuration sets in etcd, we can use the -etcd-prefix to distinguish between them. Instead of using routes inline, it may be more convenient to edit them in a file and store them in etcd directly from the file. Contents of example.eskip: hello : * - > status ( 200 ) - > inlineContent ( \"Hello, world!\" ) - > < shunt >; helloTest : Path ( \"/test\" ) - > status ( 200 ) - > inlineContent ( \"Hello, test!\" ) - > < shunt >; Updating those routes in etcd that are defined in the file, or inserting them from the file in case they don\u2019t exist in etcd, yet: eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip The above command won\u2019t modify or delete those routes, whose ID is missing from example.eskip. To fully sync a set of routes from a file to etcd, use the reset subcommand: eskip reset -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip For more information see the documentation or eskip -help .","title":"Etcd"},{"location":"data-clients/etcd/#etcd","text":"etcd is an open-source distributed key value store: https://github.com/etcd-io/etcd . Skipper can use it as a route configuration storage and continuously synchronize the routing from etcd.","title":"etcd"},{"location":"data-clients/etcd/#why-storing-skipper-routes-in-etcd","text":"When running multiple Skipper instances, changing the configuration of each instance by accessing the instances directly on the fly can be complex and error-prone. With etcd, we need to update the routes only in etcd and each Skipper instance will synchronize its routing from the new version. Further benefits of using etcd are improved resiliency and the usage of a standard configuration storage for various system components of a distributed system, not only Skipper. Note : in case of Kubernetes, the standard recommended way is to use the Kubernetes Ingress API .","title":"Why storing Skipper routes in etcd?"},{"location":"data-clients/etcd/#starting-skipper-with-etcd","text":"Example: skipper -etcd-urls http://localhost:2379,http://localhost:4001 An additional startup option is the -etcd-prefix . When using multiple Skipper deployments with different purpose, this option allows us to store separate configuration sets for them in the same etcd cluster. Example: skipper -etcd-urls https://cluster-config -etcd-prefix skipper1 Note : when the etcd URL points to an etcd proxy , Skipper will internally use the proxy only to resolve the URLs of the etcd replicas, and access them for the route configuration directly.","title":"Starting Skipper with etcd"},{"location":"data-clients/etcd/#etcd-version","text":"Skipper uses currently the V2 API of etcd.","title":"etcd version"},{"location":"data-clients/etcd/#storage-schema","text":"Skipper expects to find the route configuration by default at the /v2/keys/skipper/routes path. In this path, the \u2018skipper\u2019 segment can be optionally overridden by the -etcd-prefix startup option. The /v2/keys/skipper/routes node is a directory that contains the routes as individual child nodes, accessed by the path /v2/keys/skipper/routes/<routeID> . The value of the route nodes is the route expression without the route ID in eskip format .","title":"Storage schema"},{"location":"data-clients/etcd/#maintaining-route-configuration-in-etcd","text":"etcd (v2) allows generic access to its API via the HTTP protocol. It also provides a supporting client tool: etcdctl. Following the above described schema, both of them can be used to maintain Skipper routes. In addition, Skipper also provides a supporting client tool: eskip , which can provide more convenient access to the routes in etcd. Getting all routes, a single route, insert or update and delete via HTTP: curl http://localhost:2379/v2/keys/skipper/routes curl http://localhost:2379/v2/keys/skipper/routes/hello curl -X PUT -d 'value=* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' http://localhost:2379/v2/keys/skipper/routes/hello curl -X DELETE http://localhost:2379/v2/keys/skipper/routes/hello Getting all route IDs, a route expression stored with an ID, insert or update and delete with etcdctl: etcdctl --endpoints http://localhost:2379,http://localhost:4001 ls /skipper/routes etcdctl --endpoints http://localhost:2379,http://localhost:4001 get /skipper/routes/hello etcdctl --endpoints http://localhost:2379,http://localhost:4001 set -- /skipper/routes/hello '* -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' etcdctl --endpoints http://localhost:2379,http://localhost:4001 rm /skipper/routes/bello We use the name \u2018eskip\u2019 for two related concepts: the eskip syntax of route configuration and the eskip command line tool. The command line tool can be used to check the syntax of skipper routes, format route files, prepend or append filters to multiple routes, and also to access etcd. Getting all routes, a single route, insert or update and delete with eskip: eskip print -etcd-urls http://localhost:2379,http://localhost:4001 eskip print -etcd-urls http://localhost:2379,http://localhost:4001 | grep hello eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 -routes 'hello: * -> status(200) -> inlineContent(\"Hello, world!\") -> <shunt>' eskip delete -etcd-urls http://localhost:2379,http://localhost:4001 -ids hello When storing multiple configuration sets in etcd, we can use the -etcd-prefix to distinguish between them. Instead of using routes inline, it may be more convenient to edit them in a file and store them in etcd directly from the file. Contents of example.eskip: hello : * - > status ( 200 ) - > inlineContent ( \"Hello, world!\" ) - > < shunt >; helloTest : Path ( \"/test\" ) - > status ( 200 ) - > inlineContent ( \"Hello, test!\" ) - > < shunt >; Updating those routes in etcd that are defined in the file, or inserting them from the file in case they don\u2019t exist in etcd, yet: eskip upsert -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip The above command won\u2019t modify or delete those routes, whose ID is missing from example.eskip. To fully sync a set of routes from a file to etcd, use the reset subcommand: eskip reset -etcd-urls http://localhost:2379,http://localhost:4001 example.eskip For more information see the documentation or eskip -help .","title":"Maintaining route configuration in etcd"},{"location":"data-clients/kubernetes/","text":"Kubernetes \u00b6 Skipper\u2019s Kubernetes dataclient can be used, if you want to run Skipper as kubernetes-ingress-controller . It will get its route information from provisioned Ingress Objects . Detailed information you find in our godoc for dataclient kubernetes . Kubernetes Ingress Controller deployment \u00b6 How to install Skipper ingress-controller for cluster operators. Kubernetes Ingress Usage \u00b6 Find out more how to use Skipper ingress features for deployers. Why to choose Skipper? \u00b6 Kubernetes is a fast changing environment and traditional http routers are not made for frequently changing routing tables. Skipper is a http proxy made to apply updates very often. Skipper is used in production with more than 200.000 routing table entries. Skipper has Filters to change http data and Predicates to change the matching rules, both can combined and chained. You can set these in ingress.yaml files to build resiliency patterns like ratelimit or circuitbreaker. You can also use them to build more highlevel deployment patterns, for example feature toggles, shadow traffic or blue-green deployments. Skipper\u2019s main features: Filters - create, update, delete all kind of HTTP data collection of base http manipulations : for example manipulating Path, Querystring, ResponseHeader, RequestHeader and redirect handling cookie handling circuitbreakers : consecutiveBreaker or rateBreaker ratelimit : based on client or backend data Shadow traffic: tee() Predicates - advanced matching capability URL Path match: Path(\"/foo\") Host header match: Host(\"^www.example.org$\") Querystring : QueryParam(\"featureX\") Cookie based : Cookie(\"alpha\", /^enabled$/) source whitelist : Source(\"1.2.3.4/24\") time based interval traffic by percentage supports also sticky sessions Kubernetes integration All Filters and Predicates can be used with 2 annotations Predicates: zalando.org/skipper-predicate Filters: zalando.org/skipper-filter Custom routes can be defined with the annotation zalando.org/skipper-routes metrics access logs Blue-Green deployments, with another Ingress annotation zalando.org/backend-weights","title":"Kubernetes"},{"location":"data-clients/kubernetes/#kubernetes","text":"Skipper\u2019s Kubernetes dataclient can be used, if you want to run Skipper as kubernetes-ingress-controller . It will get its route information from provisioned Ingress Objects . Detailed information you find in our godoc for dataclient kubernetes .","title":"Kubernetes"},{"location":"data-clients/kubernetes/#kubernetes-ingress-controller-deployment","text":"How to install Skipper ingress-controller for cluster operators.","title":"Kubernetes Ingress Controller deployment"},{"location":"data-clients/kubernetes/#kubernetes-ingress-usage","text":"Find out more how to use Skipper ingress features for deployers.","title":"Kubernetes Ingress Usage"},{"location":"data-clients/kubernetes/#why-to-choose-skipper","text":"Kubernetes is a fast changing environment and traditional http routers are not made for frequently changing routing tables. Skipper is a http proxy made to apply updates very often. Skipper is used in production with more than 200.000 routing table entries. Skipper has Filters to change http data and Predicates to change the matching rules, both can combined and chained. You can set these in ingress.yaml files to build resiliency patterns like ratelimit or circuitbreaker. You can also use them to build more highlevel deployment patterns, for example feature toggles, shadow traffic or blue-green deployments. Skipper\u2019s main features: Filters - create, update, delete all kind of HTTP data collection of base http manipulations : for example manipulating Path, Querystring, ResponseHeader, RequestHeader and redirect handling cookie handling circuitbreakers : consecutiveBreaker or rateBreaker ratelimit : based on client or backend data Shadow traffic: tee() Predicates - advanced matching capability URL Path match: Path(\"/foo\") Host header match: Host(\"^www.example.org$\") Querystring : QueryParam(\"featureX\") Cookie based : Cookie(\"alpha\", /^enabled$/) source whitelist : Source(\"1.2.3.4/24\") time based interval traffic by percentage supports also sticky sessions Kubernetes integration All Filters and Predicates can be used with 2 annotations Predicates: zalando.org/skipper-predicate Filters: zalando.org/skipper-filter Custom routes can be defined with the annotation zalando.org/skipper-routes metrics access logs Blue-Green deployments, with another Ingress annotation zalando.org/backend-weights","title":"Why to choose Skipper?"},{"location":"data-clients/route-string/","text":"Route String \u00b6 Route string dataclient can be used to create simple demo applications, for example if you want to show traffic switching or ratelimiting or just need to serve some json in your demo. Serve text \u00b6 Serve with Content-Type: text/plain; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Serve HTML with CSS \u00b6 Serve with Content-Type: text/html; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Serve JSON \u00b6 Serve with Content-Type: application/json; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"{\\\"foo\\\": 3}\", \"application/json; charset=utf-8\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090 : 9090 -it registry . opensource . zalan . do / pathfinder / skipper : latest skipper -inline-routes '* -> inlineContent(\"{\\\"foo\\\": 3}\", \"application/json; charset=utf-8\") -> <shunt>' Proxy to a given URL \u00b6 If you just have to build a workaround and you do not want to use socat to do a tcp proxy, but proxy http, you can do: % skipper -inline-routes '* -> \"https://my-new-backend.example.org/\"'","title":"Route String"},{"location":"data-clients/route-string/#route-string","text":"Route string dataclient can be used to create simple demo applications, for example if you want to show traffic switching or ratelimiting or just need to serve some json in your demo.","title":"Route String"},{"location":"data-clients/route-string/#serve-text","text":"Serve with Content-Type: text/plain; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\"Hello, world!\") -> <shunt>'","title":"Serve text"},{"location":"data-clients/route-string/#serve-html-with-css","text":"Serve with Content-Type: text/html; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> ' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090:9090 -it registry.opensource.zalan.do/pathfinder/skipper:latest skipper -inline-routes '* -> inlineContent(\" <html><body style= \\\"background-color: orange;\\\" ></body></html> \") -> <shunt> '","title":"Serve HTML with CSS"},{"location":"data-clients/route-string/#serve-json","text":"Serve with Content-Type: application/json; charset=utf-8 Example (Open your browser http://localhost:9090/ ): skipper -inline-routes '* -> inlineContent(\"{\\\"foo\\\": 3}\", \"application/json; charset=utf-8\") -> <shunt>' Docker Example (Open your browser http://localhost:9090/ ): docker run -p 9090 : 9090 -it registry . opensource . zalan . do / pathfinder / skipper : latest skipper -inline-routes '* -> inlineContent(\"{\\\"foo\\\": 3}\", \"application/json; charset=utf-8\") -> <shunt>'","title":"Serve JSON"},{"location":"data-clients/route-string/#proxy-to-a-given-url","text":"If you just have to build a workaround and you do not want to use socat to do a tcp proxy, but proxy http, you can do: % skipper -inline-routes '* -> \"https://my-new-backend.example.org/\"'","title":"Proxy to a given URL"},{"location":"kubernetes/east-west-usage/","text":"East-West Usage \u00b6 If you run Skipper with an East-West setup , you can use the configured ingress also to do service-to-service calls, bypassing your ingress loadbalancer and stay inside the cluster. It depends on the configuration, but the default is that you can connect via HTTP to <name>.<namespace>.skipper.cluster.local to your application based on the ingress configuration. Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo.example.org http : paths : - backend : serviceName : example servicePort : 80 Or as a RouteGroup : apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : demo namespace : default spec : hosts : - demo.example.org backends : - name : backend type : service serviceName : example servicePort : 80 defaultBackends : - backendName : backend Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl http://demo.default.skipper.cluster.local/ Metrics will change, because skipper stores metrics per HTTP Host header, which changes with cluster internal calls from demo.example.org to demo.default.skipper.cluster.local . You can use all features as defined in Ingress Usage , Filters , Predicates via annotations as before and also custom-routes .","title":"East-West aka svc-to-svc"},{"location":"kubernetes/east-west-usage/#east-west-usage","text":"If you run Skipper with an East-West setup , you can use the configured ingress also to do service-to-service calls, bypassing your ingress loadbalancer and stay inside the cluster. It depends on the configuration, but the default is that you can connect via HTTP to <name>.<namespace>.skipper.cluster.local to your application based on the ingress configuration. Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo.example.org http : paths : - backend : serviceName : example servicePort : 80 Or as a RouteGroup : apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : demo namespace : default spec : hosts : - demo.example.org backends : - name : backend type : service serviceName : example servicePort : 80 defaultBackends : - backendName : backend Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl http://demo.default.skipper.cluster.local/ Metrics will change, because skipper stores metrics per HTTP Host header, which changes with cluster internal calls from demo.example.org to demo.default.skipper.cluster.local . You can use all features as defined in Ingress Usage , Filters , Predicates via annotations as before and also custom-routes .","title":"East-West Usage"},{"location":"kubernetes/ingress-backends/","text":"Kubernetes Backend Deployments \u00b6 Kubernetes Race Condition problem \u00b6 As described in #652 , there is a problem that exists in Kubernetes, while terminating Pods. Terminating Pods could be graceful, but the nature of distributed environments will show failures, because not all components in the distributed system changed already their state. When a Pod terminates, the controller-manager has to update the endpoints of the Kubernetes service . Additionally Skipper has to get this endpoints list. Skipper polls the kube-apiserver every -source-poll-timeout=<ms> , which defaults to 3000. Reducing this interval or implementing watch will only reduce the timeframe, but not fix the underlying race condition. Mitigation strategies can be different and the next section document strategies for application developers to mitigate the problem. Teardown strategies \u00b6 An application that is target of an ingress can circumvent HTTP code 504s Gateway Timeouts with these strategies: use Pod lifecycle hooks use a SIGTERM handler to switch readinessProbe to unhealthy and exit later, or just wait for SIGKILL terminating the process. Pod Lifecycle Hooks \u00b6 Kubernetes Pod Lifecycle Hooks in the Pod spec can have a preStop command which executes for example a binary. The following will execute the binary sleep with argument 20 to wait 20 seconds before terminating the containers within the Pod: lifecycle : preStop : exec : command : [ \"sleep\" , \"20\" ] 20 seconds should be enough to fade your Pod out of the endpoints list and Skipper\u2019s routing table. SIGTERM handling in Containers \u00b6 An application can implement a SIGTERM handler, that changes the readinessProbe target to unhealthy for the application instance. This will make sure it will be deleted from the endpoints list and from Skipper\u2019s routing table. Similar to Pod Lifecycle Hooks you could sleep 20 seconds and after that terminate your application or you just wait until SIGKILL will cleanup the instance after 60s. go func () { var sigs chan os . Signal sigs = make ( chan os . Signal , 1 ) signal . Notify ( sigs , syscall . SIGTERM ) for { select { case <- sigs : healthCheck = unhealthy time . Sleep ( 20 * time . Second ) os . Exit ( 0 ) } } }()","title":"Ingress Backends"},{"location":"kubernetes/ingress-backends/#kubernetes-backend-deployments","text":"","title":"Kubernetes Backend Deployments"},{"location":"kubernetes/ingress-backends/#kubernetes-race-condition-problem","text":"As described in #652 , there is a problem that exists in Kubernetes, while terminating Pods. Terminating Pods could be graceful, but the nature of distributed environments will show failures, because not all components in the distributed system changed already their state. When a Pod terminates, the controller-manager has to update the endpoints of the Kubernetes service . Additionally Skipper has to get this endpoints list. Skipper polls the kube-apiserver every -source-poll-timeout=<ms> , which defaults to 3000. Reducing this interval or implementing watch will only reduce the timeframe, but not fix the underlying race condition. Mitigation strategies can be different and the next section document strategies for application developers to mitigate the problem.","title":"Kubernetes Race Condition problem"},{"location":"kubernetes/ingress-backends/#teardown-strategies","text":"An application that is target of an ingress can circumvent HTTP code 504s Gateway Timeouts with these strategies: use Pod lifecycle hooks use a SIGTERM handler to switch readinessProbe to unhealthy and exit later, or just wait for SIGKILL terminating the process.","title":"Teardown strategies"},{"location":"kubernetes/ingress-backends/#pod-lifecycle-hooks","text":"Kubernetes Pod Lifecycle Hooks in the Pod spec can have a preStop command which executes for example a binary. The following will execute the binary sleep with argument 20 to wait 20 seconds before terminating the containers within the Pod: lifecycle : preStop : exec : command : [ \"sleep\" , \"20\" ] 20 seconds should be enough to fade your Pod out of the endpoints list and Skipper\u2019s routing table.","title":"Pod Lifecycle Hooks"},{"location":"kubernetes/ingress-backends/#sigterm-handling-in-containers","text":"An application can implement a SIGTERM handler, that changes the readinessProbe target to unhealthy for the application instance. This will make sure it will be deleted from the endpoints list and from Skipper\u2019s routing table. Similar to Pod Lifecycle Hooks you could sleep 20 seconds and after that terminate your application or you just wait until SIGKILL will cleanup the instance after 60s. go func () { var sigs chan os . Signal sigs = make ( chan os . Signal , 1 ) signal . Notify ( sigs , syscall . SIGTERM ) for { select { case <- sigs : healthCheck = unhealthy time . Sleep ( 20 * time . Second ) os . Exit ( 0 ) } } }()","title":"SIGTERM handling in Containers"},{"location":"kubernetes/ingress-controller/","text":"Skipper Ingress Controller \u00b6 This documentation is meant for cluster operators and describes how to install Skipper as Ingress-Controller in your Kubernetes Cluster. Why you should use Skipper as ingress controller? \u00b6 Baremetal load balancers perform really well, but their configuration is not updated frequently and most of the installations are not meant for rapid change. With the introduction of Kubernetes this assumption is no longer valid and there was a need for a HTTP router which supported backend routes which changed very frequently. Skipper was initially designed for a rapidly changing routing tree and subsequently used to implement an ingress controller in Kubernetes. Cloud load balancers scale well and can be updated frequently, but do not provide many features. Skipper has advanced resiliency and deployment features, which you can use to enhance your environment. For example, ratelimiters, circuitbreakers, blue-green deployments, shadow traffic and more . Comparison with other Ingress Controllers \u00b6 At Zalando we chose to run kube-ingress-aws-controller with skipper ingress as the target group. While AWS load balancers give us features like TLS termination, automated certificate rotation, possible WAF , and Security Groups , the HTTP routing capabilities are very limited. Skipper\u2019s main advantage compared to other HTTP routers is matching and changing HTTP. Another advantage for us and for skipper users in general is that defaults with kube-ingress-aws-controller , just work as you would expect. There are a number of other ingress controllers including traefik , nginx , haproxy or aws-alb-ingress-controller . Why not one of these? HAproxy and Nginx are well understood and good TCP/HTTP proxies, that were built before Kubernetes. As a result, the first drawback is their reliance on static configuration files which comes from a time when routes and their configurations were relatively static. Secondly, the list of annotations to implement even basic features are already quite a big list for users. Skipper was built to support dynamically changing route configurations, which happens quite often in Kubernetes. Other advantage of using Skipper is that we are able to easily implement automated canary deployments, automated blue-green deployments or shadow traffic . However there are some features that have better support in aws-alb-ingress-controller , HAproxy and nginx . For instance the sendfile() operation. If you need to stream a large file or large amount of files, then you may want to go for one of these options. aws-alb-ingress-controller directly routes traffic to your Kubernetes services, which is both good and bad, because it can reduce latency, but comes with the risk of depending on kube-proxy routing. kube-proxy routing can take up to 30 seconds, ETCD ttl, for finding pods from dead nodes. In Skipper we passively observe errors from endpoints and are able to drop these from the load balancer members. We add these to an actively checked member pool, which will enable endpoints if these are healthy again from skipper\u2019s point of view. Additionally the aws-alb-ingress-controller does not support features like ALB sharing, or Server Name Indication which can reduce costs. Features like path rewriting are also not currently supported. Traefik has a good community and support for Kubernetes. Skipper originates from Project Mosaic which was started in 2015. Back then Traefik was not yet a mature project and still had time to go before the v1.0.0 release. Traefik also does not currently support our OpenTracing provider. It also did not support traffic splitting when we started stackset-controller for automated traffic switching. We have also recently done significant work on running Skipper as API gateway within Kubernetes, which could potentially help many teams that run many small services on Kubernetes. Skipper predicates and filters are a powerful abstraction which can enhance the system easily. Comparison with service mesh \u00b6 Why run Skipper and not Istio , Linkerd or other service-mesh solutions? Skipper has a Kubernetes native integration, which is reliable, proven in production since end of 2015 as of March 2019 run in 112 Kubernetes clusters at Zalando. Skipper already has most of the features provided by service meshes: Authentication/Authorization in Kubernetes ingress , and can also integrate a custom service with webhook Diagnosis tools that support latency, bandwidth throttling, random content and more. Rich Metrics which you can enable and disable in the Prometheus format. Support for different Opentracing providers including jaeger, lightstep and instana Ratelimits support with cluster ratelimits as an pending solution, which enables you to stop login attacks easily Connects to endpoints directly, instead of using Kubernetes services Retries requests, if the request can be safely retried, which is only the case if the error happens on the TCP/IP connection establishment or a backend whose requests are defined as idempotent. Simple East-West Communication which enables proper communication paths without the need of yet another tool to do service discovery. See how to run skipper as API Gateway with East-West setup , if you want to run this powerful setup. Kubernetes, Skipper and DNS are the service discovery in this case. Blue-green deployments with automation if you like to use stackset-controller shadow-traffic to determine if the new version is able to handle the traffic the same as the old one A simple way to do A/B tests You are free to use cloud providers TLS terminations and certificate rotation, which is reliable and secure. Employees cannot download private keys and certificates are certified by a public CA. Many mTLS setups rely on insecure CA handling and are hard to debug in case of failure. We are happy to receive issues and pull requests in our repository, but if you need a feature which can not be implemented upstream, you are also free to use skipper as a library and create internal features to do whatever you want. With Skipper you do not need to choose to go all-in and you are able to add features as soon as you need or are comfortable. What is an Ingress-Controller? \u00b6 Ingress-controllers are serving http requests into a Kubernetes cluster. Most of the time traffic will pass through ingress and go to the Kubernetes endpoints of the respective pods. For having a successful ingress, you need to have a DNS name pointing to a set of stable IP addresses that act as a load balancer. Skipper as ingress-controller: cloud: deploy behind the cloud load balancer baremetal: deploy behind your hardware/software load balancer and have all skipper as members in one pool. You would point your DNS entries to the load balancer in front of skipper, for example automated using external-dns . Why skipper uses endpoints and not services? \u00b6 Skipper does not use the ClusterIP of Kubernetes Services to route traffic to the pods. Instead it uses the Endpoints API to bypass kube-proxy created iptables to remove overhead like conntrack entries for iptables DNAT. Skipper can also reuse connections to Pods, such that you have no overhead in establishing connections all the time. To prevent errors on node failures, Skipper also does automatic retries to another endpoint in case it gets a connection refused or TLS handshake error to the endpoint. Other reasons are future support of features like session affinity, different load balancer algorithms or distributed loadbalancing also known as service mesh. AWS deployment \u00b6 In AWS, this could be an ALB with DNS pointing to the ALB. The ALB can then point to an ingress-controller running on an EC2 node and uses Kubernetes hostnetwork port specification in the Pod spec. A logical overview of the traffic flow in AWS is shown in this picture: We described that Skipper bypasses Kubernetes Service and uses directly endpoints for good reasons , therefore the real traffic flow is shown in the next picture. Baremetal deployment \u00b6 In datacenter, baremetal environments, you probably have a hardware load balancer or some haproxy or nginx setup, that serves most of your production traffic and DNS points to these endpoints. For example *.ingress.example.com could point to your virtual server IPs in front of ingress. Skippers could be used as pool members, which do the http routing. Your load balancer of choice could have a wildcard certificate for *.ingress.example.com and DNS for this would point to your load balancer. You can also automate DNS records with external-dns , if you for example use PowerDNS as provider and have a load balancer controller that modifies the status field in ingress to your load balancer virtual IP. Requirements \u00b6 In general for one endpoint you need, a DNS A/AAAA record pointing to one or more load balancer IPs. Skipper is best used behind this layer 4 load balancer to route and manipulate HTTP data. minimal example: layer 4 load balancer has 1.2.3.4:80 as socket for a virtual server pointing to all skipper ingress *.ingress.example.com points to 1.2.3.4 ingress object with host entry for myapp.ingress.example.com targets a service type ClusterIP service type ClusterIP has a selector that targets your Pods of your myapp deployment TLS example: same as before, but you would terminate TLS on your layer 4 load balancer layer 4 load balancer has 1.2.3.4:443 as socket for a virtual server you can use an automated redirect for all port 80 requests to https with -kubernetes-https-redirect and change the default redirect code with -kubernetes-https-redirect-code Install Skipper as ingress-controller \u00b6 You should have a base understanding of Kubernetes and Ingress . Prerequisites: You should checkout the git repository to have access to the manifests: git clone https://github.com/zalando/skipper.git You should enter the cloned directory: cd skipper You have to choose how to install skipper-ingress. You can install it as dameonset or as deployment . Beware, in order to get traffic from the internet, we would need to have a load balancer in front to direct all traffic to skipper. Skipper will route the traffic based on ingress objects. The load balancer should have a HTTP health check, that does a GET request to /kube-system/healthz on all Kubernetes worker nodes. This method is simple and used successfully in production. In AWS you can run kube-ingress-aws-controller to create these load balancers automatically based on the ingress definition. Deployment style \u00b6 Follow the deployment style you like: dameonset or deployment . Daemonset \u00b6 We start to deploy skipper-ingress as a daemonset, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. To deploy all manifests required for the daemonset style, you can run: kubectl create -f docs/kubernetes/deploy/daemonset # cat docs/kubernetes/deploy/daemonset/daemonset.yaml apiVersion : apps/v1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.11.1 component : ingress spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.11.1 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag. Deployment \u00b6 We start to deploy skipper-ingress as a deployment with an HPA, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. To deploy all manifests required for the deployment style, you can run: kubectl create -f docs/kubernetes/deploy/deployment Now, let\u2019s see what we have just deployed. This will create serviceaccount, PodSecurityPolicy and RBAC rules such that skipper-ingress is allowed to listen on the hostnetwork. # cat docs/kubernetes/deploy/deployment/rbac.yaml apiVersion : policy/v1beta1 kind : PodSecurityPolicy metadata : name : hostnetwork spec : hostNetwork : true hostPorts : - max : 10000 min : 50 supplementalGroups : rule : RunAsAny fsGroup : rule : RunAsAny runAsUser : # Require the container to run without root privileges. rule : 'MustRunAsNonRoot' seLinux : rule : RunAsAny --- apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRole metadata : name : hostnetwork-psp rules : - apiGroups : - extensions resourceNames : - hostnetwork resources : - podsecuritypolicies verbs : - use --- apiVersion : v1 kind : ServiceAccount metadata : name : skipper-ingress namespace : kube-system --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRole metadata : name : skipper-ingress rules : - apiGroups : - extensions resources : - ingresses verbs : - get - list - apiGroups : [ \"\" ] resources : - namespaces - services - endpoints - pods verbs : - get - list - apiGroups : - zalando.org resources : - routegroups verbs : - get - list --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : skipper-ingress roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : skipper-ingress subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : RoleBinding metadata : name : skipper-ingress-hostnetwork-psp namespace : kube-system roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : hostnetwork-psp subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system The next file creates deployment with all options passed to skipper, that you should care in a basic production setup. # cat docs/kubernetes/deploy/deployment/deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.11.40 component : ingress spec : strategy : rollingUpdate : maxSurge : 0 selector : matchLabels : application : skipper-ingress template : metadata : labels : application : skipper-ingress version : v0.11.40 component : ingress spec : affinity : podAntiAffinity : requiredDuringSchedulingIgnoredDuringExecution : - labelSelector : matchExpressions : - key : application operator : In values : - skipper-ingress topologyKey : kubernetes.io/hostname priorityClassName : system-cluster-critical serviceAccountName : skipper-ingress nodeSelector : kubernetes.io/role : worker dnsPolicy : ClusterFirstWithHostNet hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.11.40 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-disable-metrics-compat\" - \"-enable-profile\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.0001,.00025,.0005,.00075,.001,.0025,.005,.0075,.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" - \"-expect-continue-timeout-backend=30s\" - \"-keepalive-backend=30s\" - \"-max-idle-connection-backend=0\" - \"-response-header-timeout-backend=1m\" - \"-timeout-backend=1m\" - \"-tls-timeout-backend=1m\" - \"-close-idle-conns-period=20s\" - \"-idle-timeout-server=62s\" - \"-read-timeout-server=5m\" - \"-write-timeout-server=60s\" - '-default-filters-prepend=enableAccessLog(4,5) -> lifo(2000,20000,\"3s\")' resources : limits : cpu : \"4\" memory : \"1Gi\" requests : cpu : \"4\" memory : \"1Gi\" readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 60 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 This will deploy a HorizontalPodAutoscaler to scale skipper-ingress based on load. # cat docs/kubernetes/deploy/deployment/hpa.yaml apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress spec : scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : skipper-ingress minReplicas : 3 maxReplicas : 50 metrics : - type : Resource resource : name : cpu targetAverageUtilization : 70 - type : Resource resource : name : memory targetAverageUtilization : 70 The next file will group skipper-ingress with a service, such that internal clients can access skipper via Kubernetes service. # cat docs/kubernetes/deploy/deployment/service.yaml kind : Service apiVersion : v1 metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress annotations : prometheus.io/path : /metrics prometheus.io/port : \"9911\" prometheus.io/scrape : \"true\" spec : type : ClusterIP ports : - port : 80 targetPort : 9999 protocol : TCP selector : application : skipper-ingress Test your skipper setup \u00b6 We now deploy a simple demo application serving html: # cat docs/kubernetes/deploy/demo/deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : skipper-demo spec : replicas : 2 template : metadata : labels : application : skipper-demo spec : containers : - name : skipper-demo image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 args : - \"skipper\" - \"-inline-routes\" - \"* -> inlineContent(\\\"<body style='color: white; background-color: green;'><h1>Hello!</h1>\\\") -> <shunt>\" ports : - containerPort : 9090 We deploy a service type ClusterIP that we will select from ingress: # cat docs/kubernetes/deploy/demo/svc.yaml apiVersion : v1 kind : Service metadata : name : skipper-demo labels : application : skipper-demo spec : type : ClusterIP ports : - port : 80 protocol : TCP targetPort : 9090 name : external selector : application : skipper-demo To deploy the demo application, you have to run: kubectl create -f docs/kubernetes/deploy/demo/ Now we have a skipper-ingress running as daemonset or deployment exposing the TCP port 9999 on each worker nodes, which has a running skipper-ingress instance, a backend application running with 2 replicas that serves some html on TCP port 9090, and we expose a cluster service on TCP port 80. Besides skipper-ingress, deployment and service can not be reached from outside the cluster. Now we expose the application with Ingress to the external network: # cat demo-ing.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: skipper-demo spec: rules: - host: skipper-demo.<mydomain.org> http: paths: - backend: serviceName: skipper-demo servicePort: 80 To deploy this ingress, you have to run: kubectl create -f demo-ing.yaml Skipper will configure itself for the given ingress, such that you can test doing: curl -v -H \"Host: skipper-demo.<mydomain.org>\" http://<nodeip>:9999/ The next question you may ask is: how to expose this to your customers? The answer depends on your setup and complexity requirements. In the simplest case you could add one A record in your DNS *.<mydomain.org> to your frontend load balancer IP that directs all traffic from *.<mydomain.org> to all Kubernetes worker nodes on TCP port 9999. The load balancer health check should make sure, that only nodes with ready skipper-ingress instances will get traffic. A more complex setup we use in production and can be done with something that configures your frontend load balancer, for example kube-aws-ingress-controller , and your DNS, external-dns automatically. Multiple skipper deployments \u00b6 If you want to split for example internal and public traffic, it might be a good choice to split your ingress deployments. Skipper has the flag --kubernetes-ingress-class=<string> to only select ingress objects that have the annotation kubernetes.io/ingress.class set to <string> . Skipper will only create routes for ingress objects with it\u2019s annotation or ingress objects that do not have this annotation. The default ingress class is skipper , if not set. You have to create your ingress objects with the annotation kubernetes.io/ingress.class: skipper to make sure only skipper will serve the traffic. Example ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : kubernetes.io/ingress.class : skipper name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Scoping Skipper Deployments to a Single Namespace \u00b6 In some instances you might want skipper to only watch for ingress objects created in a single namespace. This can be achieved by using kubernetes-namespace=<string> where <string> is the Kubernetes namespace. Specifying this option forces Skipper to look at the namespace ingresses endpoint rather than the cluster-wide ingresses endpoint. By default this value is an empty string ( \"\" ) and will scope the skipper instance to be cluster-wide, watching all Ingress objects across all namespaces. Helm-based deployment \u00b6 Helm calls itself the package manager for Kubernetes and therefore take cares of the deployment of whole applications including resources like services, configurations and so on. Skipper is also available as community contributed Helm chart in the public quay.io registry. The latest packaged release can be found here . The source code is available at GitHub . The chart includes resource definitions for the following use cases: RBAC CoreOS Prometheus-Operator As this chart is not maintained by the Skipper developers and is still under development only the basic deployment workflow is covered here. Check the GitHub repository for all details. To be able to deploy the chart you will need the following components: helm CLI (Install guide here ) Helm registry plugin (available here ) If your environment is setup correctly you should be able to run helm version --client and helm registry version quay.io and get some information about your tooling without any error. It is possible to deploy the chart without any further configuration like this: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ \"your release name e.g. skipper\" The --wait switch can be omitted as it only takes care that Helm is waiting until the chart is completely deployed (meaning all resources are created). To update the deployment to a newer version the same command can be used. If you have RBAC enabled in your Kubernetes instance you don\u2019t have to create all the previously described resources on your own but you can let Helm create them by simply adding one more switch: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ --set rbac.create=true \\ \"your release name e.g. skipper\" There are some more options available for customization of the chart. Check the repository if you need more configuration possibilities. Run as API Gateway with East-West setup \u00b6 East-West means cluster internal service-to-service communication. For this you need to resolve DNS to skipper for an additional domain .skipper.cluster.local we introduce and add HTTP routes to route to the specified backend from your normal ingress object. Skipper \u00b6 To enable the East-West in skipper, you need to run skipper with -enable-kubernetes-east-west enabled. Skipper will duplicate all routes with a Host() predicate and change it to match the host header scheme: <name>.<namespace>.skipper.cluster.local . You need also to have a kubernetes service type ClusterIP and write down the IP (p.e. 10.3.11.28 ), which you will need in CoreDNS setup. CoreDNS \u00b6 You can create the DNS records with the template plugin from CoreDNS. Corefile example: .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } template IN A skipper.cluster.local { match \"^.*[.]skipper[.]cluster[.]local\" answer \" {{ .Name }} 60 IN A 10.3.11.28\" fallthrough } prometheus :9153 proxy . /etc/resolv.conf cache 30 reload } Usage \u00b6 If the setup was done correctly, the following ingress example will create an internal route with Host(/^demo[.]default[.]skipper[.]cluster[.]local) predicate: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl demo.default.skipper.cluster.local Running with Cluster Ratelimits \u00b6 Cluster ratelimits require a communication exchange method to build a skipper swarm to have a shared knowledge about the requests passing all skipper instances. To enable this feature you need to add command line option -enable-swarm and -enable-ratelimits . The rest depends on the implementation, that can be: Redis SWIM Redis based \u00b6 Additionally you have to add -swarm-redis-urls to skipper args: . For example: -swarm-redis-urls=skipper-redis-0.skipper-redis.kube-system.svc.cluster.local:6379,skipper-redis-1.skipper-redis.kube-system.svc.cluster.local:6379 . Running skipper with hostNetwork in kubernetes will not be able to resolve redis hostnames as shown in the example, if skipper does not have dnsPolicy: ClusterFirstWithHostNet in it\u2019s Pod spec, see also DNS policy in the official Kubernetes documentation . This setup is considered experimental and should be carefully tested before running it in production. Example redis statefulset with headless service: apiVersion : apps/v1 kind : StatefulSet metadata : labels : application : skipper-redis version : v4.0.9 name : skipper-redis namespace : kube-system spec : replicas : 2 selector : matchLabels : application : skipper-redis serviceName : skipper-redis template : metadata : labels : application : skipper-redis version : v4.0.9 spec : containers : - image : registry.opensource.zalan.do/zmon/redis:4.0.9-master-6 name : skipper-redis ports : - containerPort : 6379 protocol : TCP readinessProbe : exec : command : - redis-cli - ping failureThreshold : 3 initialDelaySeconds : 10 periodSeconds : 60 successThreshold : 1 timeoutSeconds : 1 resources : limits : cpu : 100m memory : 100Mi dnsPolicy : ClusterFirst restartPolicy : Always schedulerName : default-scheduler --- apiVersion : v1 kind : Service metadata : labels : application : skipper-redis name : skipper-redis namespace : kube-system spec : clusterIP : None ports : - port : 6379 protocol : TCP targetPort : 6379 selector : application : skipper-redis type : ClusterIP SWIM based \u00b6 SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting for example to use for cluster ratelimits. This setup is not considered stable enough to run production, yet. Additionally you have to add the following command line flags to skipper\u2019s container spec args: : -swarm-port=9990 -swarm-label-selector-key=application -swarm-label-selector-value=skipper-ingress -swarm-leave-timeout=5s -swarm-max-msg-buffer=4194304 -swarm-namespace=kube-system and open another port in Kubernetes and your Firewall settings to make the communication work with TCP and UDP to the specified swarm-port : - containerPort : 9990 hostPort : 9990 name : swarm-port protocol : TCP","title":"Ingress Controller Deployment"},{"location":"kubernetes/ingress-controller/#skipper-ingress-controller","text":"This documentation is meant for cluster operators and describes how to install Skipper as Ingress-Controller in your Kubernetes Cluster.","title":"Skipper Ingress Controller"},{"location":"kubernetes/ingress-controller/#why-you-should-use-skipper-as-ingress-controller","text":"Baremetal load balancers perform really well, but their configuration is not updated frequently and most of the installations are not meant for rapid change. With the introduction of Kubernetes this assumption is no longer valid and there was a need for a HTTP router which supported backend routes which changed very frequently. Skipper was initially designed for a rapidly changing routing tree and subsequently used to implement an ingress controller in Kubernetes. Cloud load balancers scale well and can be updated frequently, but do not provide many features. Skipper has advanced resiliency and deployment features, which you can use to enhance your environment. For example, ratelimiters, circuitbreakers, blue-green deployments, shadow traffic and more .","title":"Why you should use Skipper as ingress controller?"},{"location":"kubernetes/ingress-controller/#comparison-with-other-ingress-controllers","text":"At Zalando we chose to run kube-ingress-aws-controller with skipper ingress as the target group. While AWS load balancers give us features like TLS termination, automated certificate rotation, possible WAF , and Security Groups , the HTTP routing capabilities are very limited. Skipper\u2019s main advantage compared to other HTTP routers is matching and changing HTTP. Another advantage for us and for skipper users in general is that defaults with kube-ingress-aws-controller , just work as you would expect. There are a number of other ingress controllers including traefik , nginx , haproxy or aws-alb-ingress-controller . Why not one of these? HAproxy and Nginx are well understood and good TCP/HTTP proxies, that were built before Kubernetes. As a result, the first drawback is their reliance on static configuration files which comes from a time when routes and their configurations were relatively static. Secondly, the list of annotations to implement even basic features are already quite a big list for users. Skipper was built to support dynamically changing route configurations, which happens quite often in Kubernetes. Other advantage of using Skipper is that we are able to easily implement automated canary deployments, automated blue-green deployments or shadow traffic . However there are some features that have better support in aws-alb-ingress-controller , HAproxy and nginx . For instance the sendfile() operation. If you need to stream a large file or large amount of files, then you may want to go for one of these options. aws-alb-ingress-controller directly routes traffic to your Kubernetes services, which is both good and bad, because it can reduce latency, but comes with the risk of depending on kube-proxy routing. kube-proxy routing can take up to 30 seconds, ETCD ttl, for finding pods from dead nodes. In Skipper we passively observe errors from endpoints and are able to drop these from the load balancer members. We add these to an actively checked member pool, which will enable endpoints if these are healthy again from skipper\u2019s point of view. Additionally the aws-alb-ingress-controller does not support features like ALB sharing, or Server Name Indication which can reduce costs. Features like path rewriting are also not currently supported. Traefik has a good community and support for Kubernetes. Skipper originates from Project Mosaic which was started in 2015. Back then Traefik was not yet a mature project and still had time to go before the v1.0.0 release. Traefik also does not currently support our OpenTracing provider. It also did not support traffic splitting when we started stackset-controller for automated traffic switching. We have also recently done significant work on running Skipper as API gateway within Kubernetes, which could potentially help many teams that run many small services on Kubernetes. Skipper predicates and filters are a powerful abstraction which can enhance the system easily.","title":"Comparison with other Ingress Controllers"},{"location":"kubernetes/ingress-controller/#comparison-with-service-mesh","text":"Why run Skipper and not Istio , Linkerd or other service-mesh solutions? Skipper has a Kubernetes native integration, which is reliable, proven in production since end of 2015 as of March 2019 run in 112 Kubernetes clusters at Zalando. Skipper already has most of the features provided by service meshes: Authentication/Authorization in Kubernetes ingress , and can also integrate a custom service with webhook Diagnosis tools that support latency, bandwidth throttling, random content and more. Rich Metrics which you can enable and disable in the Prometheus format. Support for different Opentracing providers including jaeger, lightstep and instana Ratelimits support with cluster ratelimits as an pending solution, which enables you to stop login attacks easily Connects to endpoints directly, instead of using Kubernetes services Retries requests, if the request can be safely retried, which is only the case if the error happens on the TCP/IP connection establishment or a backend whose requests are defined as idempotent. Simple East-West Communication which enables proper communication paths without the need of yet another tool to do service discovery. See how to run skipper as API Gateway with East-West setup , if you want to run this powerful setup. Kubernetes, Skipper and DNS are the service discovery in this case. Blue-green deployments with automation if you like to use stackset-controller shadow-traffic to determine if the new version is able to handle the traffic the same as the old one A simple way to do A/B tests You are free to use cloud providers TLS terminations and certificate rotation, which is reliable and secure. Employees cannot download private keys and certificates are certified by a public CA. Many mTLS setups rely on insecure CA handling and are hard to debug in case of failure. We are happy to receive issues and pull requests in our repository, but if you need a feature which can not be implemented upstream, you are also free to use skipper as a library and create internal features to do whatever you want. With Skipper you do not need to choose to go all-in and you are able to add features as soon as you need or are comfortable.","title":"Comparison with service mesh"},{"location":"kubernetes/ingress-controller/#what-is-an-ingress-controller","text":"Ingress-controllers are serving http requests into a Kubernetes cluster. Most of the time traffic will pass through ingress and go to the Kubernetes endpoints of the respective pods. For having a successful ingress, you need to have a DNS name pointing to a set of stable IP addresses that act as a load balancer. Skipper as ingress-controller: cloud: deploy behind the cloud load balancer baremetal: deploy behind your hardware/software load balancer and have all skipper as members in one pool. You would point your DNS entries to the load balancer in front of skipper, for example automated using external-dns .","title":"What is an Ingress-Controller?"},{"location":"kubernetes/ingress-controller/#why-skipper-uses-endpoints-and-not-services","text":"Skipper does not use the ClusterIP of Kubernetes Services to route traffic to the pods. Instead it uses the Endpoints API to bypass kube-proxy created iptables to remove overhead like conntrack entries for iptables DNAT. Skipper can also reuse connections to Pods, such that you have no overhead in establishing connections all the time. To prevent errors on node failures, Skipper also does automatic retries to another endpoint in case it gets a connection refused or TLS handshake error to the endpoint. Other reasons are future support of features like session affinity, different load balancer algorithms or distributed loadbalancing also known as service mesh.","title":"Why skipper uses endpoints and not services?"},{"location":"kubernetes/ingress-controller/#aws-deployment","text":"In AWS, this could be an ALB with DNS pointing to the ALB. The ALB can then point to an ingress-controller running on an EC2 node and uses Kubernetes hostnetwork port specification in the Pod spec. A logical overview of the traffic flow in AWS is shown in this picture: We described that Skipper bypasses Kubernetes Service and uses directly endpoints for good reasons , therefore the real traffic flow is shown in the next picture.","title":"AWS deployment"},{"location":"kubernetes/ingress-controller/#baremetal-deployment","text":"In datacenter, baremetal environments, you probably have a hardware load balancer or some haproxy or nginx setup, that serves most of your production traffic and DNS points to these endpoints. For example *.ingress.example.com could point to your virtual server IPs in front of ingress. Skippers could be used as pool members, which do the http routing. Your load balancer of choice could have a wildcard certificate for *.ingress.example.com and DNS for this would point to your load balancer. You can also automate DNS records with external-dns , if you for example use PowerDNS as provider and have a load balancer controller that modifies the status field in ingress to your load balancer virtual IP.","title":"Baremetal deployment"},{"location":"kubernetes/ingress-controller/#requirements","text":"In general for one endpoint you need, a DNS A/AAAA record pointing to one or more load balancer IPs. Skipper is best used behind this layer 4 load balancer to route and manipulate HTTP data. minimal example: layer 4 load balancer has 1.2.3.4:80 as socket for a virtual server pointing to all skipper ingress *.ingress.example.com points to 1.2.3.4 ingress object with host entry for myapp.ingress.example.com targets a service type ClusterIP service type ClusterIP has a selector that targets your Pods of your myapp deployment TLS example: same as before, but you would terminate TLS on your layer 4 load balancer layer 4 load balancer has 1.2.3.4:443 as socket for a virtual server you can use an automated redirect for all port 80 requests to https with -kubernetes-https-redirect and change the default redirect code with -kubernetes-https-redirect-code","title":"Requirements"},{"location":"kubernetes/ingress-controller/#install-skipper-as-ingress-controller","text":"You should have a base understanding of Kubernetes and Ingress . Prerequisites: You should checkout the git repository to have access to the manifests: git clone https://github.com/zalando/skipper.git You should enter the cloned directory: cd skipper You have to choose how to install skipper-ingress. You can install it as dameonset or as deployment . Beware, in order to get traffic from the internet, we would need to have a load balancer in front to direct all traffic to skipper. Skipper will route the traffic based on ingress objects. The load balancer should have a HTTP health check, that does a GET request to /kube-system/healthz on all Kubernetes worker nodes. This method is simple and used successfully in production. In AWS you can run kube-ingress-aws-controller to create these load balancers automatically based on the ingress definition.","title":"Install Skipper as ingress-controller"},{"location":"kubernetes/ingress-controller/#deployment-style","text":"Follow the deployment style you like: dameonset or deployment .","title":"Deployment style"},{"location":"kubernetes/ingress-controller/#daemonset","text":"We start to deploy skipper-ingress as a daemonset, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. To deploy all manifests required for the daemonset style, you can run: kubectl create -f docs/kubernetes/deploy/daemonset # cat docs/kubernetes/deploy/daemonset/daemonset.yaml apiVersion : apps/v1 kind : DaemonSet metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.10.180 component : ingress spec : selector : matchLabels : application : skipper-ingress updateStrategy : type : RollingUpdate template : metadata : name : skipper-ingress labels : application : skipper-ingress version : v0.11.1 component : ingress spec : priorityClassName : system-node-critical tolerations : - key : dedicated operator : Exists nodeSelector : kubernetes.io/role : worker hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.11.1 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 - name : metrics-port containerPort : 9911 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=codahale,prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" resources : requests : cpu : 150m memory : 150Mi readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 5 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 Please check, that you are using the latest release , we do not maintain the latest tag.","title":"Daemonset"},{"location":"kubernetes/ingress-controller/#deployment","text":"We start to deploy skipper-ingress as a deployment with an HPA, use hostNetwork and expose the TCP port 9999 on each Kubernetes worker node for incoming ingress traffic. To deploy all manifests required for the deployment style, you can run: kubectl create -f docs/kubernetes/deploy/deployment Now, let\u2019s see what we have just deployed. This will create serviceaccount, PodSecurityPolicy and RBAC rules such that skipper-ingress is allowed to listen on the hostnetwork. # cat docs/kubernetes/deploy/deployment/rbac.yaml apiVersion : policy/v1beta1 kind : PodSecurityPolicy metadata : name : hostnetwork spec : hostNetwork : true hostPorts : - max : 10000 min : 50 supplementalGroups : rule : RunAsAny fsGroup : rule : RunAsAny runAsUser : # Require the container to run without root privileges. rule : 'MustRunAsNonRoot' seLinux : rule : RunAsAny --- apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRole metadata : name : hostnetwork-psp rules : - apiGroups : - extensions resourceNames : - hostnetwork resources : - podsecuritypolicies verbs : - use --- apiVersion : v1 kind : ServiceAccount metadata : name : skipper-ingress namespace : kube-system --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRole metadata : name : skipper-ingress rules : - apiGroups : - extensions resources : - ingresses verbs : - get - list - apiGroups : [ \"\" ] resources : - namespaces - services - endpoints - pods verbs : - get - list - apiGroups : - zalando.org resources : - routegroups verbs : - get - list --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : ClusterRoleBinding metadata : name : skipper-ingress roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : skipper-ingress subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system --- apiVersion : rbac.authorization.k8s.io/v1beta1 kind : RoleBinding metadata : name : skipper-ingress-hostnetwork-psp namespace : kube-system roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : hostnetwork-psp subjects : - kind : ServiceAccount name : skipper-ingress namespace : kube-system The next file creates deployment with all options passed to skipper, that you should care in a basic production setup. # cat docs/kubernetes/deploy/deployment/deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress version : v0.11.40 component : ingress spec : strategy : rollingUpdate : maxSurge : 0 selector : matchLabels : application : skipper-ingress template : metadata : labels : application : skipper-ingress version : v0.11.40 component : ingress spec : affinity : podAntiAffinity : requiredDuringSchedulingIgnoredDuringExecution : - labelSelector : matchExpressions : - key : application operator : In values : - skipper-ingress topologyKey : kubernetes.io/hostname priorityClassName : system-cluster-critical serviceAccountName : skipper-ingress nodeSelector : kubernetes.io/role : worker dnsPolicy : ClusterFirstWithHostNet hostNetwork : true containers : - name : skipper-ingress image : registry.opensource.zalan.do/pathfinder/skipper:v0.11.40 ports : - name : ingress-port containerPort : 9999 hostPort : 9999 args : - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-serve-host-metrics\" - \"-disable-metrics-compat\" - \"-enable-profile\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-metrics-exp-decay-sample\" - \"-reverse-source-predicate\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=prometheus\" - \"-enable-connection-metrics\" - \"-max-audit-body=0\" - \"-histogram-metric-buckets=.0001,.00025,.0005,.00075,.001,.0025,.005,.0075,.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" - \"-expect-continue-timeout-backend=30s\" - \"-keepalive-backend=30s\" - \"-max-idle-connection-backend=0\" - \"-response-header-timeout-backend=1m\" - \"-timeout-backend=1m\" - \"-tls-timeout-backend=1m\" - \"-close-idle-conns-period=20s\" - \"-idle-timeout-server=62s\" - \"-read-timeout-server=5m\" - \"-write-timeout-server=60s\" - '-default-filters-prepend=enableAccessLog(4,5) -> lifo(2000,20000,\"3s\")' resources : limits : cpu : \"4\" memory : \"1Gi\" requests : cpu : \"4\" memory : \"1Gi\" readinessProbe : httpGet : path : /kube-system/healthz port : 9999 initialDelaySeconds : 60 timeoutSeconds : 5 securityContext : readOnlyRootFilesystem : true runAsNonRoot : true runAsUser : 1000 This will deploy a HorizontalPodAutoscaler to scale skipper-ingress based on load. # cat docs/kubernetes/deploy/deployment/hpa.yaml apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress spec : scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : skipper-ingress minReplicas : 3 maxReplicas : 50 metrics : - type : Resource resource : name : cpu targetAverageUtilization : 70 - type : Resource resource : name : memory targetAverageUtilization : 70 The next file will group skipper-ingress with a service, such that internal clients can access skipper via Kubernetes service. # cat docs/kubernetes/deploy/deployment/service.yaml kind : Service apiVersion : v1 metadata : name : skipper-ingress namespace : kube-system labels : application : skipper-ingress annotations : prometheus.io/path : /metrics prometheus.io/port : \"9911\" prometheus.io/scrape : \"true\" spec : type : ClusterIP ports : - port : 80 targetPort : 9999 protocol : TCP selector : application : skipper-ingress","title":"Deployment"},{"location":"kubernetes/ingress-controller/#test-your-skipper-setup","text":"We now deploy a simple demo application serving html: # cat docs/kubernetes/deploy/demo/deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : skipper-demo spec : replicas : 2 template : metadata : labels : application : skipper-demo spec : containers : - name : skipper-demo image : registry.opensource.zalan.do/pathfinder/skipper:v0.10.180 args : - \"skipper\" - \"-inline-routes\" - \"* -> inlineContent(\\\"<body style='color: white; background-color: green;'><h1>Hello!</h1>\\\") -> <shunt>\" ports : - containerPort : 9090 We deploy a service type ClusterIP that we will select from ingress: # cat docs/kubernetes/deploy/demo/svc.yaml apiVersion : v1 kind : Service metadata : name : skipper-demo labels : application : skipper-demo spec : type : ClusterIP ports : - port : 80 protocol : TCP targetPort : 9090 name : external selector : application : skipper-demo To deploy the demo application, you have to run: kubectl create -f docs/kubernetes/deploy/demo/ Now we have a skipper-ingress running as daemonset or deployment exposing the TCP port 9999 on each worker nodes, which has a running skipper-ingress instance, a backend application running with 2 replicas that serves some html on TCP port 9090, and we expose a cluster service on TCP port 80. Besides skipper-ingress, deployment and service can not be reached from outside the cluster. Now we expose the application with Ingress to the external network: # cat demo-ing.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: skipper-demo spec: rules: - host: skipper-demo.<mydomain.org> http: paths: - backend: serviceName: skipper-demo servicePort: 80 To deploy this ingress, you have to run: kubectl create -f demo-ing.yaml Skipper will configure itself for the given ingress, such that you can test doing: curl -v -H \"Host: skipper-demo.<mydomain.org>\" http://<nodeip>:9999/ The next question you may ask is: how to expose this to your customers? The answer depends on your setup and complexity requirements. In the simplest case you could add one A record in your DNS *.<mydomain.org> to your frontend load balancer IP that directs all traffic from *.<mydomain.org> to all Kubernetes worker nodes on TCP port 9999. The load balancer health check should make sure, that only nodes with ready skipper-ingress instances will get traffic. A more complex setup we use in production and can be done with something that configures your frontend load balancer, for example kube-aws-ingress-controller , and your DNS, external-dns automatically.","title":"Test your skipper setup"},{"location":"kubernetes/ingress-controller/#multiple-skipper-deployments","text":"If you want to split for example internal and public traffic, it might be a good choice to split your ingress deployments. Skipper has the flag --kubernetes-ingress-class=<string> to only select ingress objects that have the annotation kubernetes.io/ingress.class set to <string> . Skipper will only create routes for ingress objects with it\u2019s annotation or ingress objects that do not have this annotation. The default ingress class is skipper , if not set. You have to create your ingress objects with the annotation kubernetes.io/ingress.class: skipper to make sure only skipper will serve the traffic. Example ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : kubernetes.io/ingress.class : skipper name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Multiple skipper deployments"},{"location":"kubernetes/ingress-controller/#scoping-skipper-deployments-to-a-single-namespace","text":"In some instances you might want skipper to only watch for ingress objects created in a single namespace. This can be achieved by using kubernetes-namespace=<string> where <string> is the Kubernetes namespace. Specifying this option forces Skipper to look at the namespace ingresses endpoint rather than the cluster-wide ingresses endpoint. By default this value is an empty string ( \"\" ) and will scope the skipper instance to be cluster-wide, watching all Ingress objects across all namespaces.","title":"Scoping Skipper Deployments to a Single Namespace"},{"location":"kubernetes/ingress-controller/#helm-based-deployment","text":"Helm calls itself the package manager for Kubernetes and therefore take cares of the deployment of whole applications including resources like services, configurations and so on. Skipper is also available as community contributed Helm chart in the public quay.io registry. The latest packaged release can be found here . The source code is available at GitHub . The chart includes resource definitions for the following use cases: RBAC CoreOS Prometheus-Operator As this chart is not maintained by the Skipper developers and is still under development only the basic deployment workflow is covered here. Check the GitHub repository for all details. To be able to deploy the chart you will need the following components: helm CLI (Install guide here ) Helm registry plugin (available here ) If your environment is setup correctly you should be able to run helm version --client and helm registry version quay.io and get some information about your tooling without any error. It is possible to deploy the chart without any further configuration like this: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ \"your release name e.g. skipper\" The --wait switch can be omitted as it only takes care that Helm is waiting until the chart is completely deployed (meaning all resources are created). To update the deployment to a newer version the same command can be used. If you have RBAC enabled in your Kubernetes instance you don\u2019t have to create all the previously described resources on your own but you can let Helm create them by simply adding one more switch: helm registry upgrade quay.io/baez/skipper -- \\ --install \\ --wait \\ --set rbac.create=true \\ \"your release name e.g. skipper\" There are some more options available for customization of the chart. Check the repository if you need more configuration possibilities.","title":"Helm-based deployment"},{"location":"kubernetes/ingress-controller/#run-as-api-gateway-with-east-west-setup","text":"East-West means cluster internal service-to-service communication. For this you need to resolve DNS to skipper for an additional domain .skipper.cluster.local we introduce and add HTTP routes to route to the specified backend from your normal ingress object.","title":"Run as API Gateway with East-West setup"},{"location":"kubernetes/ingress-controller/#skipper","text":"To enable the East-West in skipper, you need to run skipper with -enable-kubernetes-east-west enabled. Skipper will duplicate all routes with a Host() predicate and change it to match the host header scheme: <name>.<namespace>.skipper.cluster.local . You need also to have a kubernetes service type ClusterIP and write down the IP (p.e. 10.3.11.28 ), which you will need in CoreDNS setup.","title":"Skipper"},{"location":"kubernetes/ingress-controller/#coredns","text":"You can create the DNS records with the template plugin from CoreDNS. Corefile example: .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } template IN A skipper.cluster.local { match \"^.*[.]skipper[.]cluster[.]local\" answer \" {{ .Name }} 60 IN A 10.3.11.28\" fallthrough } prometheus :9153 proxy . /etc/resolv.conf cache 30 reload }","title":"CoreDNS"},{"location":"kubernetes/ingress-controller/#usage","text":"If the setup was done correctly, the following ingress example will create an internal route with Host(/^demo[.]default[.]skipper[.]cluster[.]local) predicate: apiVersion : extensions / v1beta1 kind : Ingress metadata : name : demo namespace : default spec : rules : - host : demo . example . org http : paths : - backend : serviceName : example servicePort : 80 Your clients inside the cluster should call this example with demo.default.skipper.cluster.local in their host header. Example from inside a container: curl demo.default.skipper.cluster.local","title":"Usage"},{"location":"kubernetes/ingress-controller/#running-with-cluster-ratelimits","text":"Cluster ratelimits require a communication exchange method to build a skipper swarm to have a shared knowledge about the requests passing all skipper instances. To enable this feature you need to add command line option -enable-swarm and -enable-ratelimits . The rest depends on the implementation, that can be: Redis SWIM","title":"Running with Cluster Ratelimits"},{"location":"kubernetes/ingress-controller/#redis-based","text":"Additionally you have to add -swarm-redis-urls to skipper args: . For example: -swarm-redis-urls=skipper-redis-0.skipper-redis.kube-system.svc.cluster.local:6379,skipper-redis-1.skipper-redis.kube-system.svc.cluster.local:6379 . Running skipper with hostNetwork in kubernetes will not be able to resolve redis hostnames as shown in the example, if skipper does not have dnsPolicy: ClusterFirstWithHostNet in it\u2019s Pod spec, see also DNS policy in the official Kubernetes documentation . This setup is considered experimental and should be carefully tested before running it in production. Example redis statefulset with headless service: apiVersion : apps/v1 kind : StatefulSet metadata : labels : application : skipper-redis version : v4.0.9 name : skipper-redis namespace : kube-system spec : replicas : 2 selector : matchLabels : application : skipper-redis serviceName : skipper-redis template : metadata : labels : application : skipper-redis version : v4.0.9 spec : containers : - image : registry.opensource.zalan.do/zmon/redis:4.0.9-master-6 name : skipper-redis ports : - containerPort : 6379 protocol : TCP readinessProbe : exec : command : - redis-cli - ping failureThreshold : 3 initialDelaySeconds : 10 periodSeconds : 60 successThreshold : 1 timeoutSeconds : 1 resources : limits : cpu : 100m memory : 100Mi dnsPolicy : ClusterFirst restartPolicy : Always schedulerName : default-scheduler --- apiVersion : v1 kind : Service metadata : labels : application : skipper-redis name : skipper-redis namespace : kube-system spec : clusterIP : None ports : - port : 6379 protocol : TCP targetPort : 6379 selector : application : skipper-redis type : ClusterIP","title":"Redis based"},{"location":"kubernetes/ingress-controller/#swim-based","text":"SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting for example to use for cluster ratelimits. This setup is not considered stable enough to run production, yet. Additionally you have to add the following command line flags to skipper\u2019s container spec args: : -swarm-port=9990 -swarm-label-selector-key=application -swarm-label-selector-value=skipper-ingress -swarm-leave-timeout=5s -swarm-max-msg-buffer=4194304 -swarm-namespace=kube-system and open another port in Kubernetes and your Firewall settings to make the communication work with TCP and UDP to the specified swarm-port : - containerPort : 9990 hostPort : 9990 name : swarm-port protocol : TCP","title":"SWIM based"},{"location":"kubernetes/ingress-usage/","text":"Skipper Ingress Usage \u00b6 This documentation is meant for people deploying to Kubernetes Clusters and describes to use Ingress and low level and high level features Skipper provides. RouteGroups , a relatively new feature, also support each of these features, with an alternative format that supports them in a more native way. The documentation contains a section with mapping Ingress to RouteGroups. Skipper Ingress Annotations \u00b6 Annotation example data usage zalando.org/backend-weights {\"my-app-1\": 80, \"my-app-2\": 20} blue-green deployments zalando.org/skipper-filter consecutiveBreaker(15) arbitrary filters zalando.org/skipper-predicate QueryParam(\"version\", \"^alpha$\") arbitrary predicates zalando.org/skipper-routes Method(\"OPTIONS\") -> status(200) -> <shunt> extra custom routes zalando.org/ratelimit ratelimit(50, \"1m\") deprecated, use zalando.org/skipper-filter instead zalando.org/skipper-ingress-redirect \"true\" change the default HTTPS redirect behavior for specific ingresses (true/false) zalando.org/skipper-ingress-redirect-code 301 change the default HTTPS redirect code for specific ingresses zalando.org/skipper-loadbalancer consistentHash defaults to roundRobin , see available choices zalando.org/skipper-backend-protocol fastcgi ( experimental ) defaults to http , see available choices zalando.org/skipper-ingress-path-mode path-prefix defaults to kubernetes-ingress , see available choices , to change the default use -kubernetes-path-mode Supported Service types \u00b6 Ingress backend definitions are services, which have different service types . Service type supported workaround ClusterIP yes \u2014 NodePort yes \u2014 ExternalName no, related issue use deployment with routestring LoadBalancer no it should not, because Kubernetes cloud-controller-manager will maintain it HTTP Host header routing \u00b6 HTTP host header is defined within the rules host section and this route will match by http Host: app-default.example.org and route to endpoints selected by the Kubernetes service app-svc on port 80 . apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 To have 2 routes with different Host headers serving the same backends, you have to specify 2 entries in the rules section, as Kubernetes defined the ingress spec. This is often used in cases of migrations from one domain to another one or migrations to or from bare metal datacenters to cloud providers or inter cloud or intra cloud providers migrations. Examples are AWS account migration, AWS to GCP migration, GCP to bare metal migration or bare metal to Alibaba Cloud migration. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 - host : foo.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Multiple Ingresses defining the same route \u00b6 Warning If multiple ingresses define the same host and the same predicates, traffic routing may become non-deterministic. Consider the following two ingresses which have the same hostname and therefore overlap. In skipper the routing of this is currently undefined as skipper doesn\u2019t pick one over the other, but just creates routes (possible overlapping) for each of the ingresses. In this example (taken from the issues we saw in production clusters) one ingress points to a service with no endpoints and the other to a service with endpoints. (Most likely service-x was renamed to service-x-live and the old ingress was forgot). apiVersion : extensions/v1beta1 kind : Ingress metadata : name : service-x spec : rules : - host : service-x.example.org http : paths : - backend : serviceName : service-x # this service has 0 endpoints servicePort : 80 \u200b apiVersion : extensions/v1beta1 kind : Ingress metadata : name : service-x-live spec : rules : - host : service-x.example.org http : paths : - backend : serviceName : service-x-live servicePort : 80 Ingress path handling \u00b6 Ingress paths can be interpreted in four different modes: based on the kubernetes ingress specification as plain regular expression as a path prefix The default is the kubernetes ingress mode. It can be changed by a startup option to any of the other modes, and the individual ingress rules can also override the default behavior with the zalando.org/skipper-ingress-path-mode annotation. E.g.: zalando.org/skipper-ingress-path-mode: path-prefix Kubernetes ingress specification base path \u00b6 By default, the ingress path mode is set to kubernetes-ingress , which is interpreted as a regular expression with a mandatory leading / , and is automatically prepended by a ^ control character, enforcing that the path has to be at the start of the incoming request path. Plain regular expression \u00b6 When the path mode is set to path-regexp , the ingress path is interpreted similar to the default kubernetes ingress specification way, but is not prepended by the ^ control character. Path prefix \u00b6 When the path mode is set to path-prefix , the ingress path is not a regular expression. As an example, /foo/bar will match /foo/bar or /foo/bar/baz , but won\u2019t match /foo/barooz . When PathPrefix is used, the path matching becomes deterministic when a request could match more than one ingress routes otherwise. In PathPrefix mode, when a Path or PathSubtree predicate is set in an annotation, the predicate in the annotation takes precedence over the normal ingress path. Filters and Predicates \u00b6 Filters can manipulate http data, which is not possible in the ingress spec. Predicates change the route matching, beyond normal ingress definitions This example shows how to add predicates and filters: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : predicate1 && predicate2 && .. && predicateN zalando.org/skipper-filter : filter1 -> filter2 -> .. -> filterN name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Custom Routes \u00b6 Custom routes is a way of extending the default routes configured for an ingress resource. Sometimes you just want to return a header, redirect or even static html content. You can return from skipper without doing a proxy call to a backend, if you end your filter chain with <shunt> . The use of <shunt> recommends the use in combination with status() filter, to not respond with the default http code, which defaults to 404. To match your custom route with higher priority than your ingress you also have to add another predicate, for example the Method(\u201cGET\u201d) predicate to match the route with higher priority. Custom routes specified in ingress will always add the Host() predicate to match the host header specified in the ingress rules: . If there is a path: definition in your ingress, then it will be based on the skipper command line parameter -kubernetes-path-mode set one of theses predicates: Path() PathSubtree() PathRegexp() If you have a path: value defined in your ingress resource, a custom route is not allowed to use Path() nor PathSubtree() predicates. You will get an error in Skipper logs, similar to: [APP]time=\"2019-01-02T13:30:16Z\" level=error msg=\"Failed to add route having 2 path routes: Path(\\\"/foo/bar\\\") -> inlineContent(\\\"custom route\\\") -> status(200) -> <shunt>\" Redirects \u00b6 Overwrite the current ingress with a redirect \u00b6 Sometimes you want to overwrite the current ingress with a redirect to a nicer downtime page. The following example shows how to create a temporary redirect with status code 307 to https://outage.example.org . No requests will pass to your backend defined, because the created route from the annotation zalando.org/skipper-routes will get 3 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") && PathRegexp(\"/\") , instead of the 2 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") , that will be created for the ingress backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando.org/skipper-routes : | redirect_app_default: PathRegexp(\"/\") -> redirectTo(307, \"https://outage.example.org/\") -> <shunt>; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app-svc servicePort : 80 Redirect a specific path from ingress \u00b6 Sometimes you want to have a redirect from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path . The following example shows how to create a permanent redirect with status code 308 from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path , other paths will not be redirected and passed to the backend selected by serviceName=app-svc and servicePort=80 : apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando.org/skipper-routes : | redirect_app_default: PathRegexp(\"/myredirect\") -> redirectTo(308, \"https://somewhere.example.org/another/path\") -> <shunt>; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app-svc servicePort : 80 Return static content \u00b6 The following example sets a response header X: bar , a response body <html><body>hello</body></html> and respond from the ingress directly with a HTTP status code 200: zalando.org/skipper-routes: | Path(\"/\") -> setResponseHeader(\"X\", \"bar\") -> inlineContent(\" <html><body> hello </body></html> \") -> status(200) -> <shunt> Keep in mind that you need a valid backend definition to backends which are available, otherwise Skipper would not accept the entire route definition from the ingress object for safety reasons. CORS example \u00b6 This example shows how to add a custom route for handling OPTIONS requests. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-routes : | Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 This will generate a custom route for the ingress which looks like this: Host(/^app-default[.]example[.]org$/) && Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> Multiple routes \u00b6 You can also set multiple routes, but you have to set the names of the route as defined in eskip: zalando . org / skipper-routes : | routename1 : Path ( \"/\" ) - > localRatelimit ( 2 , \"1h\" ) - > inlineContent ( \"A\" ) - > status ( 200 ) - > < shunt >; routename2 : Path ( \"/foo\" ) - > localRatelimit ( 5 , \"1h\" ) - > inlineContent ( \"B\" ) - > status ( 200 ) - > < shunt >; Make sure the ; semicolon is used to terminate the routes, if you use multiple routes definitions. Disclaimer : This feature works only with having different Path* predicates in ingress, if there are no paths rules defined. For example this will not work: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : skipper-ingress annotations : kubernetes.io/ingress.class : skipper zalando.org/skipper-routes : | redirect1: Path(\"/foo/\") -> redirectTo(308, \"/bar/\") -> <shunt>; spec : rules : - host : foo.bar http : paths : - path : /something/ backend : serviceName : something servicePort : 80 - path : /else/ backend : serviceName : else servicePort : 80 A possible solution will be a skipper route CRD: https://github.com/zalando/skipper/issues/660 Filters - Basic HTTP manipulations \u00b6 HTTP manipulations are done by using skipper filters. Changes can be done in the request path, meaning request to your backend or in the response path to the client, which made the request. The following examples can be used within zalando.org/skipper-filter annotation. Add a request Header \u00b6 Add a HTTP header in the request path to your backend. setRequestHeader(\"X-Foo\", \"bar\") Add a response Header \u00b6 Add a HTTP header in the response path of your clients. setResponseHeader(\"X-Foo\", \"bar\") Enable gzip \u00b6 Compress responses with gzip. compress() // compress all valid MIME types compress(\"text/html\") // only compress HTML files compress(9, \"text/html\") // control the level of compression, 1 = fastest, 9 = best compression, 0 = no compression Set the Path \u00b6 Change the path in the request path to your backend to /newPath/ . setPath(\"/newPath/\") Modify Path \u00b6 Modify the path in the request path from /api/foo to your backend to /foo . modPath(\"^/api/\", \"/\") Set the Querystring \u00b6 Set the Querystring in the request path to your backend to ?text=godoc%20skipper . setQuery(\"text\", \"godoc skipper\") Redirect \u00b6 Create a redirect with HTTP code 301 to https://foo.example.org/ . redirectTo(301, \"https://foo.example.org/\") Cookies \u00b6 Set a Cookie in the request path to your backend. requestCookie(\"test-session\", \"abc\") Set a Cookie in the response path of your clients. responseCookie(\"test-session\", \"abc\", 31536000) responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") // response cookie without HttpOnly: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\") Authorization \u00b6 Our authentication and authorization tutorial or filter auth godoc shows how to use filters for authorization. Basic Auth \u00b6 % htpasswd -nbm myName myPassword basicAuth ( \" / path / to / htpasswd \" ) basicAuth ( \" / path / to / htpasswd \" , \" My Website \" ) Bearer Token (OAuth/JWT) \u00b6 OAuth2/JWT tokens can be validated and allowed based on different content of the token. Please check the filter documentation for that: oauthTokeninfoAnyScope oauthTokeninfoAllScope oauthTokeninfoAnyKV oauthTokeninfoAllKV There are also auth predicates , which will allow you to match a route based on the content of a token: JWTPayloadAnyKV() JWTPayloadAllKV() These are not validating the tokens, which should be done separately by the filters mentioned above. Diagnosis - Throttling Bandwidth - Latency \u00b6 For diagnosis purpose there are filters that enable you to throttle the bandwidth or add latency. For the full list of filters see our diag filter godoc page . bandwidth(30) // incoming in kb/s backendBandwidth(30) // outgoing in kb/s backendLatency(120) // in ms Filter documentation: latency bandwidth chunks backendlatency backendChunks randomcontent Flow Id to trace request flows \u00b6 To trace request flows skipper can generate a unique Flow Id for every HTTP request that it receives. You can then find the trace of the request in all your access logs. Skipper sets the X-Flow-Id header to a unique value. Read more about this in our flowid filter and godoc . flowId(\"reuse\") Filters - reliability features \u00b6 Filters can modify http requests and responses. There are plenty of things you can do with them. Circuitbreaker \u00b6 Consecutive Breaker \u00b6 The consecutiveBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N (in this example N=15), where N is a mandatory argument of the filter and there are some more optional arguments documented. consecutiveBreaker(15) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : consecutiveBreaker(15) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Rate Breaker \u00b6 The rateBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N within a window of the last M requests, where N (in this example 30) and M (in this example 300) are mandatory arguments of the filter and there are some more optional arguments documented. rateBreaker(30, 300) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : rateBreaker(30, 300) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Ratelimits \u00b6 There are two kind of ratelimits: Client side ratelimits are used to slow down login enumeration attacks, that targets your login pages. This is a security protection for DDoS or login attacks. Service or backend side ratelimits are used to protect your services due too much traffic. This can be used in an emergency situation to make sure you calm down ingress traffic or in general if you know how much calls per duration your backend is able to handle. Cluster ratelimits can be enforced either on client or on service side as described above. Ratelimits are enforced per route. More details you will find in ratelimit package and in our ratelimit tutorial . Client Ratelimits \u00b6 The example shows 20 calls per hour per client, based on X-Forwarded-For header or IP incase there is no X-Forwarded-For header set, are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 If you need to rate limit service to service communication and you use Authorization headers to protect your backend from your clients, then you can pass a 3 parameter to group clients by \u201cAuthorization Header\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\", \"auth\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Service Ratelimits \u00b6 The example shows 50 calls per minute are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : ratelimit(50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Cluster Ratelimits \u00b6 Cluster ratelimits are eventual consistent and require the flag -enable-swarm to be set. Service \u00b6 The example shows 50 calls per minute are allowed to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterRatelimit(\"groupSvcApp\", 50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Client \u00b6 The example shows 10 calls per hour are allowed per client, X-Forwarded-For header, to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterClientRatelimit(\"groupSvcApp\", 10, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Shadow Traffic \u00b6 If you want to test a new replacement of a production service with production load, you can copy incoming requests to your new endpoint and ignore the responses from your new backend. This can be done by the tee() and teenf() filters. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : teenf(\"https://app-new.example.org\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Predicates \u00b6 Predicates are influencing the route matching, which you might want to carefully test before using it in production. This enables you to do feature toggles or time based enabling endpoints. You can use all kinds of predicates with filters together. Feature Toggle \u00b6 Feature toggles are often implemented as query string to select a new feature. Normally you would have to implement this in your application, but Skipper can help you with that and you can select routes with an ingress definition. You create 2 ingresses that matches the same route, here host header match to app-default.example.org and one ingress has a defined query parameter to select the route to the alpha version deployment. If the query string in the URL has version=alpha set, for example https://app-default.example.org/mypath?version=alpha , the service alpha-svc will get the traffic, if not prod-svc . alpha-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : QueryParam(\"version\", \"^alpha$\") name : alpha-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : alpha-svc servicePort : 80 prod-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : prod-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : prod-svc servicePort : 80 IP Whitelisting \u00b6 This ingress route will only allow traffic from networks 1.2.3.0/24 and 195.168.0.0/17 apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Source(\"1.2.3.0/24\", \"195.168.0.0/17\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 A/B test \u00b6 Implementing A/B testing is heavy. Skipper can help you to do that. You need to have a traffic split somewhere and have your customers sticky to either A or B flavor of your application. Most likely people would implement using cookies. Skipper can set a cookie with responseCookie() in a response to the client and the cookie predicate can be used to match the route based on the cookie. Like this you can have sticky sessions to either A or B for your clients. This example shows to have 10% traffic using A and the rest using B. 10% choice of setting the Cookie \u201cflavor\u201d to \u201cA\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Traffic(.1, \"flavor\", \"A\") zalando.org/skipper-filter : responseCookie(\"flavor\", \"A\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 Rest is setting Cookie \u201cflavor\u201d to \u201cB\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : responseCookie(\"flavor, \"B\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 To be sticky, you have to create 2 ingress with predicate to match routes with the cookie we set before. For \u201cA\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^A$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 For \u201cB\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 Blue-Green deployments \u00b6 To do blue-green deployments you have to have control over traffic switching. Skipper gives you the opportunity to set weights to backend services in your ingress specification. zalando.org/backend-weights is a hash map, which key relates to the serviceName of the backend and the value is the weight of traffic you want to send to the particular backend. It works for more than 2 backends, but for simplicity this example shows 2 backends, which should be the default case for supporting blue-green deployments. In the following example my-app-1 service will get 80% of the traffic and my-app-2 will get 20% of the traffic: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-app labels : application : my-app annotations : zalando.org/backend-weights : | {\"my-app-1\": 80, \"my-app-2\": 20} spec : rules : - host : my-app.example.org http : paths : - backend : serviceName : my-app-1 servicePort : http path : / - backend : serviceName : my-app-2 servicePort : http path : / For more advanced blue-green deployments, check out our stackset-controller . Chaining Filters and Predicates \u00b6 You can set multiple filters in a chain similar to the eskip format . apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) && Source(\"1.2.3.0/24\", \"195.168.0.0/17\") zalando.org/skipper-filter : localRatelimit(50, \"10m\") -> requestCookie(\"test-session\", \"abc\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Controlling HTTPS redirect \u00b6 Skipper Ingress can provide HTTP->HTTPS redirection. Enabling it and setting the status code used by default can be done with the command line options: -kubernetes-https-redirect and -kubernetes-https-redirect-code . By using annotations, this behavior can be overridden from the individual ingress specs for the scope of routes generated based on these ingresses specs. Annotations: zalando.org/skipper-ingress-redirect : the possible values are true or false. When the global HTTPS redirect is disabled, the value true enables it for the current ingress. When the global redirect is enabled, the value false disables it for the current ingress. zalando.org/skipper-ingress-redirect-code : the possible values are integers 300 <= x < 400 . Sets the redirect status code for the current ingress. Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-ingress-redirect : \"true\" zalando.org/skipper-ingress-redirect-code : 301 name : app spec : rules : - host : mobile-api.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 Load Balancer Algorithm \u00b6 You can set the loadbalancer algorithm, which is used to find the next endpoint for a given request with the ingress annotation zalando.org/skipper-loadbalancer . For example, for some workloads you might want to have always the same endpoint for the same client. For this use case there is the consistent hash algorithm, that finds for a client detected by the IP or X-Forwarded-For header, the same backend. If the backend is not available it would switch to another one. Annotations: zalando.org/skipper-loadbalancer see available choices Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-loadbalancer : consistentHash name : app spec : rules : - host : websocket.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Ingress Usage"},{"location":"kubernetes/ingress-usage/#skipper-ingress-usage","text":"This documentation is meant for people deploying to Kubernetes Clusters and describes to use Ingress and low level and high level features Skipper provides. RouteGroups , a relatively new feature, also support each of these features, with an alternative format that supports them in a more native way. The documentation contains a section with mapping Ingress to RouteGroups.","title":"Skipper Ingress Usage"},{"location":"kubernetes/ingress-usage/#skipper-ingress-annotations","text":"Annotation example data usage zalando.org/backend-weights {\"my-app-1\": 80, \"my-app-2\": 20} blue-green deployments zalando.org/skipper-filter consecutiveBreaker(15) arbitrary filters zalando.org/skipper-predicate QueryParam(\"version\", \"^alpha$\") arbitrary predicates zalando.org/skipper-routes Method(\"OPTIONS\") -> status(200) -> <shunt> extra custom routes zalando.org/ratelimit ratelimit(50, \"1m\") deprecated, use zalando.org/skipper-filter instead zalando.org/skipper-ingress-redirect \"true\" change the default HTTPS redirect behavior for specific ingresses (true/false) zalando.org/skipper-ingress-redirect-code 301 change the default HTTPS redirect code for specific ingresses zalando.org/skipper-loadbalancer consistentHash defaults to roundRobin , see available choices zalando.org/skipper-backend-protocol fastcgi ( experimental ) defaults to http , see available choices zalando.org/skipper-ingress-path-mode path-prefix defaults to kubernetes-ingress , see available choices , to change the default use -kubernetes-path-mode","title":"Skipper Ingress Annotations"},{"location":"kubernetes/ingress-usage/#supported-service-types","text":"Ingress backend definitions are services, which have different service types . Service type supported workaround ClusterIP yes \u2014 NodePort yes \u2014 ExternalName no, related issue use deployment with routestring LoadBalancer no it should not, because Kubernetes cloud-controller-manager will maintain it","title":"Supported Service types"},{"location":"kubernetes/ingress-usage/#http-host-header-routing","text":"HTTP host header is defined within the rules host section and this route will match by http Host: app-default.example.org and route to endpoints selected by the Kubernetes service app-svc on port 80 . apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 To have 2 routes with different Host headers serving the same backends, you have to specify 2 entries in the rules section, as Kubernetes defined the ingress spec. This is often used in cases of migrations from one domain to another one or migrations to or from bare metal datacenters to cloud providers or inter cloud or intra cloud providers migrations. Examples are AWS account migration, AWS to GCP migration, GCP to bare metal migration or bare metal to Alibaba Cloud migration. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 - host : foo.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"HTTP Host header routing"},{"location":"kubernetes/ingress-usage/#multiple-ingresses-defining-the-same-route","text":"Warning If multiple ingresses define the same host and the same predicates, traffic routing may become non-deterministic. Consider the following two ingresses which have the same hostname and therefore overlap. In skipper the routing of this is currently undefined as skipper doesn\u2019t pick one over the other, but just creates routes (possible overlapping) for each of the ingresses. In this example (taken from the issues we saw in production clusters) one ingress points to a service with no endpoints and the other to a service with endpoints. (Most likely service-x was renamed to service-x-live and the old ingress was forgot). apiVersion : extensions/v1beta1 kind : Ingress metadata : name : service-x spec : rules : - host : service-x.example.org http : paths : - backend : serviceName : service-x # this service has 0 endpoints servicePort : 80 \u200b apiVersion : extensions/v1beta1 kind : Ingress metadata : name : service-x-live spec : rules : - host : service-x.example.org http : paths : - backend : serviceName : service-x-live servicePort : 80","title":"Multiple Ingresses defining the same route"},{"location":"kubernetes/ingress-usage/#ingress-path-handling","text":"Ingress paths can be interpreted in four different modes: based on the kubernetes ingress specification as plain regular expression as a path prefix The default is the kubernetes ingress mode. It can be changed by a startup option to any of the other modes, and the individual ingress rules can also override the default behavior with the zalando.org/skipper-ingress-path-mode annotation. E.g.: zalando.org/skipper-ingress-path-mode: path-prefix","title":"Ingress path handling"},{"location":"kubernetes/ingress-usage/#kubernetes-ingress-specification-base-path","text":"By default, the ingress path mode is set to kubernetes-ingress , which is interpreted as a regular expression with a mandatory leading / , and is automatically prepended by a ^ control character, enforcing that the path has to be at the start of the incoming request path.","title":"Kubernetes ingress specification base path"},{"location":"kubernetes/ingress-usage/#plain-regular-expression","text":"When the path mode is set to path-regexp , the ingress path is interpreted similar to the default kubernetes ingress specification way, but is not prepended by the ^ control character.","title":"Plain regular expression"},{"location":"kubernetes/ingress-usage/#path-prefix","text":"When the path mode is set to path-prefix , the ingress path is not a regular expression. As an example, /foo/bar will match /foo/bar or /foo/bar/baz , but won\u2019t match /foo/barooz . When PathPrefix is used, the path matching becomes deterministic when a request could match more than one ingress routes otherwise. In PathPrefix mode, when a Path or PathSubtree predicate is set in an annotation, the predicate in the annotation takes precedence over the normal ingress path.","title":"Path prefix"},{"location":"kubernetes/ingress-usage/#filters-and-predicates","text":"Filters can manipulate http data, which is not possible in the ingress spec. Predicates change the route matching, beyond normal ingress definitions This example shows how to add predicates and filters: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : predicate1 && predicate2 && .. && predicateN zalando.org/skipper-filter : filter1 -> filter2 -> .. -> filterN name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Filters and Predicates"},{"location":"kubernetes/ingress-usage/#custom-routes","text":"Custom routes is a way of extending the default routes configured for an ingress resource. Sometimes you just want to return a header, redirect or even static html content. You can return from skipper without doing a proxy call to a backend, if you end your filter chain with <shunt> . The use of <shunt> recommends the use in combination with status() filter, to not respond with the default http code, which defaults to 404. To match your custom route with higher priority than your ingress you also have to add another predicate, for example the Method(\u201cGET\u201d) predicate to match the route with higher priority. Custom routes specified in ingress will always add the Host() predicate to match the host header specified in the ingress rules: . If there is a path: definition in your ingress, then it will be based on the skipper command line parameter -kubernetes-path-mode set one of theses predicates: Path() PathSubtree() PathRegexp() If you have a path: value defined in your ingress resource, a custom route is not allowed to use Path() nor PathSubtree() predicates. You will get an error in Skipper logs, similar to: [APP]time=\"2019-01-02T13:30:16Z\" level=error msg=\"Failed to add route having 2 path routes: Path(\\\"/foo/bar\\\") -> inlineContent(\\\"custom route\\\") -> status(200) -> <shunt>\"","title":"Custom Routes"},{"location":"kubernetes/ingress-usage/#redirects","text":"","title":"Redirects"},{"location":"kubernetes/ingress-usage/#overwrite-the-current-ingress-with-a-redirect","text":"Sometimes you want to overwrite the current ingress with a redirect to a nicer downtime page. The following example shows how to create a temporary redirect with status code 307 to https://outage.example.org . No requests will pass to your backend defined, because the created route from the annotation zalando.org/skipper-routes will get 3 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") && PathRegexp(\"/\") , instead of the 2 Predicates Host(\"^app-default[.]example[.]org$\") && Path(\"/\") , that will be created for the ingress backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando.org/skipper-routes : | redirect_app_default: PathRegexp(\"/\") -> redirectTo(307, \"https://outage.example.org/\") -> <shunt>; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app-svc servicePort : 80","title":"Overwrite the current ingress with a redirect"},{"location":"kubernetes/ingress-usage/#redirect-a-specific-path-from-ingress","text":"Sometimes you want to have a redirect from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path . The following example shows how to create a permanent redirect with status code 308 from http://app-default.example.org/myredirect to https://somewhere.example.org/another/path , other paths will not be redirected and passed to the backend selected by serviceName=app-svc and servicePort=80 : apiVersion : extensions/v1beta1 kind : Ingress metadata : name : app namespace : default annotations : zalando.org/skipper-routes : | redirect_app_default: PathRegexp(\"/myredirect\") -> redirectTo(308, \"https://somewhere.example.org/another/path\") -> <shunt>; spec : rules : - host : \"app-default.example.org\" http : paths : - path : / backend : serviceName : app-svc servicePort : 80","title":"Redirect a specific path from ingress"},{"location":"kubernetes/ingress-usage/#return-static-content","text":"The following example sets a response header X: bar , a response body <html><body>hello</body></html> and respond from the ingress directly with a HTTP status code 200: zalando.org/skipper-routes: | Path(\"/\") -> setResponseHeader(\"X\", \"bar\") -> inlineContent(\" <html><body> hello </body></html> \") -> status(200) -> <shunt> Keep in mind that you need a valid backend definition to backends which are available, otherwise Skipper would not accept the entire route definition from the ingress object for safety reasons.","title":"Return static content"},{"location":"kubernetes/ingress-usage/#cors-example","text":"This example shows how to add a custom route for handling OPTIONS requests. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-routes : | Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt> name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 This will generate a custom route for the ingress which looks like this: Host(/^app-default[.]example[.]org$/) && Method(\"OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Origin\", \"*\") -> setResponseHeader(\"Access-Control-Allow-Methods\", \"GET, OPTIONS\") -> setResponseHeader(\"Access-Control-Allow-Headers\", \"Authorization\") -> status(200) -> <shunt>","title":"CORS example"},{"location":"kubernetes/ingress-usage/#multiple-routes","text":"You can also set multiple routes, but you have to set the names of the route as defined in eskip: zalando . org / skipper-routes : | routename1 : Path ( \"/\" ) - > localRatelimit ( 2 , \"1h\" ) - > inlineContent ( \"A\" ) - > status ( 200 ) - > < shunt >; routename2 : Path ( \"/foo\" ) - > localRatelimit ( 5 , \"1h\" ) - > inlineContent ( \"B\" ) - > status ( 200 ) - > < shunt >; Make sure the ; semicolon is used to terminate the routes, if you use multiple routes definitions. Disclaimer : This feature works only with having different Path* predicates in ingress, if there are no paths rules defined. For example this will not work: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : skipper-ingress annotations : kubernetes.io/ingress.class : skipper zalando.org/skipper-routes : | redirect1: Path(\"/foo/\") -> redirectTo(308, \"/bar/\") -> <shunt>; spec : rules : - host : foo.bar http : paths : - path : /something/ backend : serviceName : something servicePort : 80 - path : /else/ backend : serviceName : else servicePort : 80 A possible solution will be a skipper route CRD: https://github.com/zalando/skipper/issues/660","title":"Multiple routes"},{"location":"kubernetes/ingress-usage/#filters-basic-http-manipulations","text":"HTTP manipulations are done by using skipper filters. Changes can be done in the request path, meaning request to your backend or in the response path to the client, which made the request. The following examples can be used within zalando.org/skipper-filter annotation.","title":"Filters - Basic HTTP manipulations"},{"location":"kubernetes/ingress-usage/#add-a-request-header","text":"Add a HTTP header in the request path to your backend. setRequestHeader(\"X-Foo\", \"bar\")","title":"Add a request Header"},{"location":"kubernetes/ingress-usage/#add-a-response-header","text":"Add a HTTP header in the response path of your clients. setResponseHeader(\"X-Foo\", \"bar\")","title":"Add a response Header"},{"location":"kubernetes/ingress-usage/#enable-gzip","text":"Compress responses with gzip. compress() // compress all valid MIME types compress(\"text/html\") // only compress HTML files compress(9, \"text/html\") // control the level of compression, 1 = fastest, 9 = best compression, 0 = no compression","title":"Enable gzip"},{"location":"kubernetes/ingress-usage/#set-the-path","text":"Change the path in the request path to your backend to /newPath/ . setPath(\"/newPath/\")","title":"Set the Path"},{"location":"kubernetes/ingress-usage/#modify-path","text":"Modify the path in the request path from /api/foo to your backend to /foo . modPath(\"^/api/\", \"/\")","title":"Modify Path"},{"location":"kubernetes/ingress-usage/#set-the-querystring","text":"Set the Querystring in the request path to your backend to ?text=godoc%20skipper . setQuery(\"text\", \"godoc skipper\")","title":"Set the Querystring"},{"location":"kubernetes/ingress-usage/#redirect","text":"Create a redirect with HTTP code 301 to https://foo.example.org/ . redirectTo(301, \"https://foo.example.org/\")","title":"Redirect"},{"location":"kubernetes/ingress-usage/#cookies","text":"Set a Cookie in the request path to your backend. requestCookie(\"test-session\", \"abc\") Set a Cookie in the response path of your clients. responseCookie(\"test-session\", \"abc\", 31536000) responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") // response cookie without HttpOnly: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\")","title":"Cookies"},{"location":"kubernetes/ingress-usage/#authorization","text":"Our authentication and authorization tutorial or filter auth godoc shows how to use filters for authorization.","title":"Authorization"},{"location":"kubernetes/ingress-usage/#basic-auth","text":"% htpasswd -nbm myName myPassword basicAuth ( \" / path / to / htpasswd \" ) basicAuth ( \" / path / to / htpasswd \" , \" My Website \" )","title":"Basic Auth"},{"location":"kubernetes/ingress-usage/#bearer-token-oauthjwt","text":"OAuth2/JWT tokens can be validated and allowed based on different content of the token. Please check the filter documentation for that: oauthTokeninfoAnyScope oauthTokeninfoAllScope oauthTokeninfoAnyKV oauthTokeninfoAllKV There are also auth predicates , which will allow you to match a route based on the content of a token: JWTPayloadAnyKV() JWTPayloadAllKV() These are not validating the tokens, which should be done separately by the filters mentioned above.","title":"Bearer Token (OAuth/JWT)"},{"location":"kubernetes/ingress-usage/#diagnosis-throttling-bandwidth-latency","text":"For diagnosis purpose there are filters that enable you to throttle the bandwidth or add latency. For the full list of filters see our diag filter godoc page . bandwidth(30) // incoming in kb/s backendBandwidth(30) // outgoing in kb/s backendLatency(120) // in ms Filter documentation: latency bandwidth chunks backendlatency backendChunks randomcontent","title":"Diagnosis - Throttling Bandwidth - Latency"},{"location":"kubernetes/ingress-usage/#flow-id-to-trace-request-flows","text":"To trace request flows skipper can generate a unique Flow Id for every HTTP request that it receives. You can then find the trace of the request in all your access logs. Skipper sets the X-Flow-Id header to a unique value. Read more about this in our flowid filter and godoc . flowId(\"reuse\")","title":"Flow Id to trace request flows"},{"location":"kubernetes/ingress-usage/#filters-reliability-features","text":"Filters can modify http requests and responses. There are plenty of things you can do with them.","title":"Filters - reliability features"},{"location":"kubernetes/ingress-usage/#circuitbreaker","text":"","title":"Circuitbreaker"},{"location":"kubernetes/ingress-usage/#consecutive-breaker","text":"The consecutiveBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N (in this example N=15), where N is a mandatory argument of the filter and there are some more optional arguments documented. consecutiveBreaker(15) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : consecutiveBreaker(15) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Consecutive Breaker"},{"location":"kubernetes/ingress-usage/#rate-breaker","text":"The rateBreaker filter is a breaker for the ingress route that open if the backend failures for the route reach a value of N within a window of the last M requests, where N (in this example 30) and M (in this example 300) are mandatory arguments of the filter and there are some more optional arguments documented. rateBreaker(30, 300) The ingress spec would look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : rateBreaker(30, 300) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Rate Breaker"},{"location":"kubernetes/ingress-usage/#ratelimits","text":"There are two kind of ratelimits: Client side ratelimits are used to slow down login enumeration attacks, that targets your login pages. This is a security protection for DDoS or login attacks. Service or backend side ratelimits are used to protect your services due too much traffic. This can be used in an emergency situation to make sure you calm down ingress traffic or in general if you know how much calls per duration your backend is able to handle. Cluster ratelimits can be enforced either on client or on service side as described above. Ratelimits are enforced per route. More details you will find in ratelimit package and in our ratelimit tutorial .","title":"Ratelimits"},{"location":"kubernetes/ingress-usage/#client-ratelimits","text":"The example shows 20 calls per hour per client, based on X-Forwarded-For header or IP incase there is no X-Forwarded-For header set, are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80 If you need to rate limit service to service communication and you use Authorization headers to protect your backend from your clients, then you can pass a 3 parameter to group clients by \u201cAuthorization Header\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : localRatelimit(20, \"1h\", \"auth\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Client Ratelimits"},{"location":"kubernetes/ingress-usage/#service-ratelimits","text":"The example shows 50 calls per minute are allowed to each skipper instance for the given ingress. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : ratelimit(50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Service Ratelimits"},{"location":"kubernetes/ingress-usage/#cluster-ratelimits","text":"Cluster ratelimits are eventual consistent and require the flag -enable-swarm to be set.","title":"Cluster Ratelimits"},{"location":"kubernetes/ingress-usage/#service","text":"The example shows 50 calls per minute are allowed to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterRatelimit(\"groupSvcApp\", 50, \"1m\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Service"},{"location":"kubernetes/ingress-usage/#client","text":"The example shows 10 calls per hour are allowed per client, X-Forwarded-For header, to pass this ingress rule to the backend. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : clusterClientRatelimit(\"groupSvcApp\", 10, \"1h\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Client"},{"location":"kubernetes/ingress-usage/#shadow-traffic","text":"If you want to test a new replacement of a production service with production load, you can copy incoming requests to your new endpoint and ignore the responses from your new backend. This can be done by the tee() and teenf() filters. apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : teenf(\"https://app-new.example.org\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Shadow Traffic"},{"location":"kubernetes/ingress-usage/#predicates","text":"Predicates are influencing the route matching, which you might want to carefully test before using it in production. This enables you to do feature toggles or time based enabling endpoints. You can use all kinds of predicates with filters together.","title":"Predicates"},{"location":"kubernetes/ingress-usage/#feature-toggle","text":"Feature toggles are often implemented as query string to select a new feature. Normally you would have to implement this in your application, but Skipper can help you with that and you can select routes with an ingress definition. You create 2 ingresses that matches the same route, here host header match to app-default.example.org and one ingress has a defined query parameter to select the route to the alpha version deployment. If the query string in the URL has version=alpha set, for example https://app-default.example.org/mypath?version=alpha , the service alpha-svc will get the traffic, if not prod-svc . alpha-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : QueryParam(\"version\", \"^alpha$\") name : alpha-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : alpha-svc servicePort : 80 prod-svc: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : prod-app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : prod-svc servicePort : 80","title":"Feature Toggle"},{"location":"kubernetes/ingress-usage/#ip-whitelisting","text":"This ingress route will only allow traffic from networks 1.2.3.0/24 and 195.168.0.0/17 apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Source(\"1.2.3.0/24\", \"195.168.0.0/17\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"IP Whitelisting"},{"location":"kubernetes/ingress-usage/#ab-test","text":"Implementing A/B testing is heavy. Skipper can help you to do that. You need to have a traffic split somewhere and have your customers sticky to either A or B flavor of your application. Most likely people would implement using cookies. Skipper can set a cookie with responseCookie() in a response to the client and the cookie predicate can be used to match the route based on the cookie. Like this you can have sticky sessions to either A or B for your clients. This example shows to have 10% traffic using A and the rest using B. 10% choice of setting the Cookie \u201cflavor\u201d to \u201cA\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Traffic(.1, \"flavor\", \"A\") zalando.org/skipper-filter : responseCookie(\"flavor\", \"A\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 Rest is setting Cookie \u201cflavor\u201d to \u201cB\u201d: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-filter : responseCookie(\"flavor, \"B\", 31536000) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80 To be sticky, you have to create 2 ingress with predicate to match routes with the cookie we set before. For \u201cA\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^A$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : a-app-svc servicePort : 80 For \u201cB\u201d this would be: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : b-app-svc servicePort : 80","title":"A/B test"},{"location":"kubernetes/ingress-usage/#blue-green-deployments","text":"To do blue-green deployments you have to have control over traffic switching. Skipper gives you the opportunity to set weights to backend services in your ingress specification. zalando.org/backend-weights is a hash map, which key relates to the serviceName of the backend and the value is the weight of traffic you want to send to the particular backend. It works for more than 2 backends, but for simplicity this example shows 2 backends, which should be the default case for supporting blue-green deployments. In the following example my-app-1 service will get 80% of the traffic and my-app-2 will get 20% of the traffic: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-app labels : application : my-app annotations : zalando.org/backend-weights : | {\"my-app-1\": 80, \"my-app-2\": 20} spec : rules : - host : my-app.example.org http : paths : - backend : serviceName : my-app-1 servicePort : http path : / - backend : serviceName : my-app-2 servicePort : http path : / For more advanced blue-green deployments, check out our stackset-controller .","title":"Blue-Green deployments"},{"location":"kubernetes/ingress-usage/#chaining-filters-and-predicates","text":"You can set multiple filters in a chain similar to the eskip format . apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-predicate : Cookie(\"flavor\", /^B$/) && Source(\"1.2.3.0/24\", \"195.168.0.0/17\") zalando.org/skipper-filter : localRatelimit(50, \"10m\") -> requestCookie(\"test-session\", \"abc\") name : app spec : rules : - host : app-default.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Chaining Filters and Predicates"},{"location":"kubernetes/ingress-usage/#controlling-https-redirect","text":"Skipper Ingress can provide HTTP->HTTPS redirection. Enabling it and setting the status code used by default can be done with the command line options: -kubernetes-https-redirect and -kubernetes-https-redirect-code . By using annotations, this behavior can be overridden from the individual ingress specs for the scope of routes generated based on these ingresses specs. Annotations: zalando.org/skipper-ingress-redirect : the possible values are true or false. When the global HTTPS redirect is disabled, the value true enables it for the current ingress. When the global redirect is enabled, the value false disables it for the current ingress. zalando.org/skipper-ingress-redirect-code : the possible values are integers 300 <= x < 400 . Sets the redirect status code for the current ingress. Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-ingress-redirect : \"true\" zalando.org/skipper-ingress-redirect-code : 301 name : app spec : rules : - host : mobile-api.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Controlling HTTPS redirect"},{"location":"kubernetes/ingress-usage/#load-balancer-algorithm","text":"You can set the loadbalancer algorithm, which is used to find the next endpoint for a given request with the ingress annotation zalando.org/skipper-loadbalancer . For example, for some workloads you might want to have always the same endpoint for the same client. For this use case there is the consistent hash algorithm, that finds for a client detected by the IP or X-Forwarded-For header, the same backend. If the backend is not available it would switch to another one. Annotations: zalando.org/skipper-loadbalancer see available choices Example: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : zalando.org/skipper-loadbalancer : consistentHash name : app spec : rules : - host : websocket.example.org http : paths : - backend : serviceName : app-svc servicePort : 80","title":"Load Balancer Algorithm"},{"location":"kubernetes/routegroup-crd/","text":"RouteGroup CRD Semantics \u00b6 This document contains the semantic definition of the RouteGroup CRD. For more information, see the route group documentation , or see the CRD yaml definition . Concepts \u00b6 RouteGroup \u00b6 A RouteGroup represents a grouped routing specification, with one or more backends, typically a Kubernetes service. The Skipper routes yielded by a route group are handled atomically, meaning that if any problem is detected during processing a route group, none of the generated routes from that group will be applied. Hosts \u00b6 A list of allowed DNS host names that an incoming HTTP request should match in order to be handled by the route group. Hosts are optional. Backend \u00b6 Typically a Kubernetes service, but not necessarily. The routes generated from route groups need to have a backend, therefore at least one backend is mandatory. Default backend \u00b6 A route group can contain multiple routes. If the routes don\u2019t identify the backend, then the default backends are used. There can be multiple default backends, e.g. to support weighted A/B testing. Route \u00b6 Routes describe how a matching HTTP request is handled and where it is forwarded to. Predicate \u00b6 A predicate is used during route lookup to identify which route should handle an incoming request. Route group routes provide dedicated fields for the most common predicates like the path or the HTTP method, but in the predicates list field, it is possible to define and configure any predicate supported by Skipper. See the Predicates section of the reference. Filter \u00b6 A filter is used during handling the request to shape the request flow. In a route group, any filter supported by Skipper is allowed to be used. See the Filters section of the reference. RouteGroup - top level object \u00b6 The route group spec can or must contain the hosts, backends, default backends and routes. Mandatory fields are the backends, and either the defaultBackends or the routes. apiVersion : zalando.org/v1 kind : RouteGroup spec : hosts : - <string> backends : - <backend> defaultBackends : - <backendRef> routes : - <route> Backend \u00b6 The <backend> object defines the type of a backend and the required configuration based on the type. Required fields are the name and the type, while the rest of the fields may be required based on the type. <backend> name : <string> type : <string> one of \"service|shunt|loopback|dynamic|lb|network\" address : <string> optional, required for type=network algorithm : <string> optional, valid for type=lb|service, values=roundRobin|random|consistentHash endpoints : <stringarray> optional, required for type=lb serviceName : <string> optional, required for type=service servicePort : <number> optional, required for type=service See more about Skipper backends in the backend documentation . Backend reference \u00b6 The <backendRef> object references a backend that is defined in the route group\u2019s backends field. The name is a required field, while the weight is optional. If no weight is used at all, then the traffic is split evenly between the referenced backends. One or more backend reference may appear on the route group level as a default backend, or in a route. <backendRef> - backendName : <string> weight : <number> optional Route \u00b6 The <route> object defines the actual routing setup with custom matching rules (predicates), and request flow shaping with filters. <route> path : <string> either path or pathSubtree is allowed pathSubtree : <string> either path or pathSubtree is allowed pathRegexp : <string> optional methods : <stringarray> optional, one of the HTTP methods per entry \"GET|HEAD|PATCH|POST|PUT|DELETE|CONNECT|OPTIONS|TRACE\", defaults to all predicates : <stringarray> optional filters : <stringarray> optional backends : optional, overrides defaults - <backendRef> The path , pathSubtree and pathRegexp fields work the same way as the predicate counterparts on eskip routes. See the reference manual for more details. The methods field defines which methods an incoming request can have in order to match the route. The items in the predicates and filter fields take lists of predicates and filters, respectively, defined in their eskip format. Example: predicates: - Cookie(\"alpha\", \"enabled\") - Header(\"X-Test\", \"true\") filters: - setQuery(\"test\", \"alpha\") - compress() See also: predicates filters The references in the backends field, if present, define which backends a route should use.","title":"RouteGroup CRD Semantics"},{"location":"kubernetes/routegroup-crd/#routegroup-crd-semantics","text":"This document contains the semantic definition of the RouteGroup CRD. For more information, see the route group documentation , or see the CRD yaml definition .","title":"RouteGroup CRD Semantics"},{"location":"kubernetes/routegroup-crd/#concepts","text":"","title":"Concepts"},{"location":"kubernetes/routegroup-crd/#routegroup","text":"A RouteGroup represents a grouped routing specification, with one or more backends, typically a Kubernetes service. The Skipper routes yielded by a route group are handled atomically, meaning that if any problem is detected during processing a route group, none of the generated routes from that group will be applied.","title":"RouteGroup"},{"location":"kubernetes/routegroup-crd/#hosts","text":"A list of allowed DNS host names that an incoming HTTP request should match in order to be handled by the route group. Hosts are optional.","title":"Hosts"},{"location":"kubernetes/routegroup-crd/#backend","text":"Typically a Kubernetes service, but not necessarily. The routes generated from route groups need to have a backend, therefore at least one backend is mandatory.","title":"Backend"},{"location":"kubernetes/routegroup-crd/#default-backend","text":"A route group can contain multiple routes. If the routes don\u2019t identify the backend, then the default backends are used. There can be multiple default backends, e.g. to support weighted A/B testing.","title":"Default backend"},{"location":"kubernetes/routegroup-crd/#route","text":"Routes describe how a matching HTTP request is handled and where it is forwarded to.","title":"Route"},{"location":"kubernetes/routegroup-crd/#predicate","text":"A predicate is used during route lookup to identify which route should handle an incoming request. Route group routes provide dedicated fields for the most common predicates like the path or the HTTP method, but in the predicates list field, it is possible to define and configure any predicate supported by Skipper. See the Predicates section of the reference.","title":"Predicate"},{"location":"kubernetes/routegroup-crd/#filter","text":"A filter is used during handling the request to shape the request flow. In a route group, any filter supported by Skipper is allowed to be used. See the Filters section of the reference.","title":"Filter"},{"location":"kubernetes/routegroup-crd/#routegroup-top-level-object","text":"The route group spec can or must contain the hosts, backends, default backends and routes. Mandatory fields are the backends, and either the defaultBackends or the routes. apiVersion : zalando.org/v1 kind : RouteGroup spec : hosts : - <string> backends : - <backend> defaultBackends : - <backendRef> routes : - <route>","title":"RouteGroup - top level object"},{"location":"kubernetes/routegroup-crd/#backend_1","text":"The <backend> object defines the type of a backend and the required configuration based on the type. Required fields are the name and the type, while the rest of the fields may be required based on the type. <backend> name : <string> type : <string> one of \"service|shunt|loopback|dynamic|lb|network\" address : <string> optional, required for type=network algorithm : <string> optional, valid for type=lb|service, values=roundRobin|random|consistentHash endpoints : <stringarray> optional, required for type=lb serviceName : <string> optional, required for type=service servicePort : <number> optional, required for type=service See more about Skipper backends in the backend documentation .","title":"Backend"},{"location":"kubernetes/routegroup-crd/#backend-reference","text":"The <backendRef> object references a backend that is defined in the route group\u2019s backends field. The name is a required field, while the weight is optional. If no weight is used at all, then the traffic is split evenly between the referenced backends. One or more backend reference may appear on the route group level as a default backend, or in a route. <backendRef> - backendName : <string> weight : <number> optional","title":"Backend reference"},{"location":"kubernetes/routegroup-crd/#route_1","text":"The <route> object defines the actual routing setup with custom matching rules (predicates), and request flow shaping with filters. <route> path : <string> either path or pathSubtree is allowed pathSubtree : <string> either path or pathSubtree is allowed pathRegexp : <string> optional methods : <stringarray> optional, one of the HTTP methods per entry \"GET|HEAD|PATCH|POST|PUT|DELETE|CONNECT|OPTIONS|TRACE\", defaults to all predicates : <stringarray> optional filters : <stringarray> optional backends : optional, overrides defaults - <backendRef> The path , pathSubtree and pathRegexp fields work the same way as the predicate counterparts on eskip routes. See the reference manual for more details. The methods field defines which methods an incoming request can have in order to match the route. The items in the predicates and filter fields take lists of predicates and filters, respectively, defined in their eskip format. Example: predicates: - Cookie(\"alpha\", \"enabled\") - Header(\"X-Test\", \"true\") filters: - setQuery(\"test\", \"alpha\") - compress() See also: predicates filters The references in the backends field, if present, define which backends a route should use.","title":"Route"},{"location":"kubernetes/routegroups/","text":"Route groups \u00b6 Route groups are an alternative to the Kubernetes Ingress format for defining ingress rules. They allow to define Skipper routing in Kubernetes, while providing a straightforward way to configure the routing features supported by Skipper and not defined by the generic Ingress. Skipper as Kubernetes Ingress controller \u00b6 Skipper is an extensible HTTP router with rich route matching, and request flow and traffic shaping capabilities. Through its integration with Kubernetes, it can be used in the role of an ingress controller for forwarding incoming external requests to the right services in a cluster. Kubernetes provides the Ingress specification to define the rules by which an ingress controller should handle the incoming traffic. The specification is simple and generic, but doesn\u2019t offer a straightforward way to benefit from Skipper\u2019s rich HTTP related functionality. RouteGroups \u00b6 A RouteGroup is a custom Kubernetes resource definition. It provides a way to define the ingress routing for Kubernetes services. It allows route matching based on any HTTP request attributes, and provides a clean way for the request flow augmentation and traffic shaping. It supports higher level features like gradual traffic switching, A/B testing, and more. Example: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : backends : - name : variant-a type : service serviceName : service-a servicePort : 80 - name : variant-b type : service serviceName : service-b servicePort : 80 defaultBackends : - backendName : variant-b routes : - pathSubtree : / filters : - responseCookie(\"canary\", \"A\") predicates : - Traffic(.1) backends : - backendName : variant-a - pathSubtree : / filters : - responseCookie(\"canary\", \"B\") - pathSubtree : / predicates : - Cookie(\"canary\", \"A\") backends : - backendName : variant-a - pathSubtree : / predicates : - Cookie(\"canary\", \"B\") (See a more detailed explanation of the above example further down in this document.) Links: RouteGroup semantics CRD definition Requirements \u00b6 External DNS v0.7.0 or higher Kubernetes Ingress Controller for AWS v0.10.0 or higher Installation \u00b6 The definition file of the CRD can be found as part of Skipper\u2019s source code, at: https://github.com/zalando/skipper/blob/master/dataclients/kubernetes/deploy/apply/routegroups_crd.yaml To install it manually in a cluster, assuming the current directory is the root of Skipper\u2019s source, call this command: kubectl apply -f dataclients/kubernetes/deploy/apply/routegroups_crd.yaml This will install a namespaced resource definition, providing the RouteGroup kind: full name: routegroups.zalando.org resource group: zalando.org/v1 resource names: routegroup, routegroups, rg, rgs kind: RouteGroup The route groups, once any is defined, can be displayed then via kubectl as: kubectl get rgs The API URL of the routegroup resources will be: https://kubernetes-api-hostname/apis/zalando.org/v1/routegroups Usage \u00b6 The absolute minimal route group configuration for a Kubernetes service (my-service) looks as follows: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-backend This is equivalent to the ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : backend : serviceName : my-service servicePort : 80 Notice that the route group contains a list of actual backends, and the defined service backend is then referenced as the default backend. This structure plays a role in supporting scenarios like A/B testing and gradual traffic switching, explained below . The backend definition also has a type field, whose values can be service, lb, network, shunt, loopback or dynamic. More details on that below . Creating, updating and deleting route groups happens the same way as with ingress objects. E.g, manually applying a route group definition: kubectl apply -f my-route-group.yaml Hosts \u00b6 Format Hosts contain hostnames that are used to match the requests handled by a given route group. They are also used to update the required DNS entries and load balancer configuration if the cluster is set up that way. Note that it is also possible to use any Skipper predicate in the routes of a route group, with the Host predicate included, but the hostnames defined that way will not serve as input for the DNS configuration. Backends \u00b6 Format General backend reference RouteGroups support different backends. The most typical backend type is the \u2018service\u2019, and it works the same way as in case of ingress definitions. In a RouteGroup, there can be multiple backends and they are listed on the top level of the route group spec, and are referenced from the actual routes or as default backends. type=service \u00b6 This backend resolves to a Kubernetes service. It works the same way as in case of Ingress definitions. Skipper resolves the Services to the available Endpoints belonging to the Service, and generates load balanced routes using them. (This basically means that under the hood, a service backend becomes an lb backend.) type=lb \u00b6 This backend provides load balancing between multiple network endpoints. Keep in mind that the service type backend automatically generates load balanced routes for the service endpoints, so this backend type typically doesn\u2019t need to be used for services. type=network \u00b6 This backend type results in routes that proxy incoming requests to the defined network address, regardless of the Kubernetes semantics, and allows URLs that point somewhere else, potentially outside of the cluster, too. type=shunt, type=loopback, type=dynamic \u00b6 These backend types allow advanced routing setups. Please check the reference manual for more details. Default Backends \u00b6 Format A default backend is a reference to one of the defined backends. When a route doesn\u2019t specify which backend(s) to use, the ones referenced in the default backends will be used. In case there are no individual routes at all in the route group, a default set of routes (one or more) will be generated and will proxy the incoming traffic to the default backends. The reason, why multiple backends can be referenced as default, is that this makes it easy to execute gradual traffic switching between different versions, even more than two, of the same application. See more . Routes \u00b6 Format Routes define where to and how the incoming requests will be proxied. The predicates, including the path, pathSubtree, pathRegexp and methods fields, and any free-form predicate listed under the predicates field, control which requests are matched by a route, the filters can apply changes to the forwarded requests and the returned responses, and the backend refs, if defined, override the default backends, where the requests will be proxied to. If a route group doesn\u2019t contain any explicit routes, but it contains default backends, a default set of routes will be generated for the route group. Important to bear in mind about the path fields, that the plain \u2018path\u2019 means exact path match, while \u2018pathSubtree\u2019 behaves as a path prefix, and so it is more similar to the path in the Ingress specification. See also: predicates filters Gradual traffic switching \u00b6 The weighted backend references allow to split the traffic of a single route and send it to different backends with the ratio defined by the weights of the backend references. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : hosts : - api.example.org backends : - name : api-svc-v1 type : service serviceName : api-service-v1 servicePort : 80 - name : api-svc-v2 type : service serviceName : foo-service-v2 servicePort : 80 routes : - pathSubtree : /api backends : - backendName : api-svc-v1 weight : 80 - backendName : api-svc-v2 weight : 20 In case of the above example, 80% of the requests is sent to api-service-v1 and the rest is sent to api-service-v2. Since this type of weighted traffic switching can be used in combination with the Traffic predicate, it is possible to control the routing of a long running A/B test, while still executing gradual traffic switching independently to deploy a new version of the variants, maybe to deploy a fix only to one variant. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : hosts : - api.example.org backends : - name : variant-a type : service serviceName : service-a servicePort : 80 - name : variant-b type : service serviceName : service-b-v1 servicePort : 80 - name : variant-b-v2 type : service serviceName : service-b-v2 servicePort : 80 defaultBackends : - backendName : variant-b weight : 80 - backendName : variant-b-v2 weight : 20 routes : - filters : - responseCookie(\"canary\", \"A\") predicates : - Traffic(.1) backends : - backendName : variant-a - filters : - responseCookie(\"canary\", \"B\") - predicates : - Cookie(\"canary\", \"A\") backends : - backendName : variant-a - predicates : - Cookie(\"canary\", \"B\") See also: Traffic predicate Mapping from Ingress to RouteGroups \u00b6 RouteGroups are one-way compatible with Ingress, meaning that every Ingress specification can be expressed in the RouteGroup format, as well. In the following, we describe the mapping from Ingress fields to RouteGroup fields. Ingress with default backend \u00b6 Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : backend : serviceName : my-service servicePort : 80 RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-backend Ingress with path rule \u00b6 Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api Ingress with multiple hosts \u00b6 Ingress (we need to define two rules): apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 - host : legacy-name.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 RouteGroup (we just define an additional host): apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org - legacy-name.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api Ingress with multiple hosts, and different routing \u00b6 For those cases when using multiple hostnames in the same ingress with different rules, we need to apply a small workaround for the equivalent route group spec. Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 - host : legacy-name.example.org http : paths : - path : /application backend : serviceName : my-service servicePort : 80 RouteGroup (we need to use additional host predicates): apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org - legacy-name.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api predicates : - Host(\"api.example.org\") - pathSubtree : /application predicates : - Host(\"legacy-name.example.org\") The RouteGroups allow multiple hostnames for each route group, but by default, their union is used during routing. If we want to distinguish between them, then we need to use an additional Host predicate in the routes. Importantly, only the hostnames listed under the hosts field serve as input for the DNS and LB configuration. Mapping Skipper Ingress extensions to RouteGroups \u00b6 Skipper accepts a set of annotations in Ingress objects that give access to certain Skipper features that would not be possible with the native fields of the Ingress spec, e.g. improved path handling or rate limiting. These annotations can be expressed now natively in the RouteGroups. zalando.org/backend-weights \u00b6 Backend weights are now part of the backend references, and they can be controlled for multiple backend sets within the same route group. See Gradual traffic switching . zalando.org/skipper-filter and zalando.org/skipper-predicate \u00b6 Filters and predicates are now part of the route objects, and different set of filters or predicates can be set for different routes. zalando.org/skipper-routes \u00b6 \u201cCustom routes\u201d in a route group are unnecessary, because every route can be configured with predicates, filters and backends without limitations. E.g where an ingress annotation\u2019s metadata may look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress zalando.org/skipper-routes : | Method(\"OPTIONS\") -> status(200) -> <shunt> spec : backend : serviceName : my-service servicePort : 80 the equivalent RouteGroup would look like this: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 - name : options200 type : shunt defaultBackends : - backendName : my-backend routes : - pathSubtree : / - pathSubtree : / methods : OPTIONS filters : - status(200) backends : - options200 zalando.org/ratelimit \u00b6 The ratelimiting can be defined on the route level among the filters, in the same format as in this annotation. zalando.org/skipper-ingress-redirect and zalando.org/skipper-ingress-redirect-code \u00b6 Skipper ingress provides global HTTPS redirect, but it allows individual ingresses to override the global settings: enabling/disabling it and changing the default redirect code. With route groups, this override can be achieved by simply defining an addtional route, with the same matching rules, and therefore the override can be controlled eventually on a route basis. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 - name : redirectShunt type : shunt defaultBackends : - backendName : my-backend routes : - pathSubtree : / - pathSubtree : / predicates : - Header(\"X-Forwarded-Proto\", \"http\") filters : - redirectTo(302, \"https:\") backends : - redirectShunt zalando.org/skipper-loadbalancer \u00b6 Skipper Ingress doesn\u2019t use the ClusterIP of the Service for forwarding the traffic to, but sends it directly to the Endpoints represented by the Service, and balances the load between them with the round-robin algorithm. The algorithm choice can be overridden by this annotation. In case of the RouteGroups, the algorithm is simply an attribute of the backend definition, and it can be set individually for each backend. E.g: backends: - name: my-backend type: service serviceName: my-service servicePort: 80 algorithm: consistentHash See also: Load Balancer backend zalando.org/skipper-ingress-path-mode \u00b6 The route objects support the different path lookup modes, by using the path, pathSubtree or the pathRegexp field. See also the route matching explained for the internals. The mapping is as follows: Ingress: RouteGroup: kubernetes-ingress and /foo pathRegexp: ^/foo path-regexp and /foo pathRegexp: /foo path-prefix and /foo pathSubtree: /foo kubernetes-ingress and /foo$ path: /foo Multiple skipper deployments \u00b6 If you want to split for example internal and public traffic, it might be a good choice to split your RouteGroups. Skipper has the flag --kubernetes-routegroup-class=<string> to only select RouteGroup objects that have the annotation zalando.org/routegroup.class set to <string> . Skipper will only create routes for RouteGroup objects with it\u2019s annotation or RouteGroup objects that do not have this annotation. The default class is skipper , if not set. Example RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group annotations : zalando.org/routegroup.class : internal spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-service","title":"RouteGroups"},{"location":"kubernetes/routegroups/#route-groups","text":"Route groups are an alternative to the Kubernetes Ingress format for defining ingress rules. They allow to define Skipper routing in Kubernetes, while providing a straightforward way to configure the routing features supported by Skipper and not defined by the generic Ingress.","title":"Route groups"},{"location":"kubernetes/routegroups/#skipper-as-kubernetes-ingress-controller","text":"Skipper is an extensible HTTP router with rich route matching, and request flow and traffic shaping capabilities. Through its integration with Kubernetes, it can be used in the role of an ingress controller for forwarding incoming external requests to the right services in a cluster. Kubernetes provides the Ingress specification to define the rules by which an ingress controller should handle the incoming traffic. The specification is simple and generic, but doesn\u2019t offer a straightforward way to benefit from Skipper\u2019s rich HTTP related functionality.","title":"Skipper as Kubernetes Ingress controller"},{"location":"kubernetes/routegroups/#routegroups","text":"A RouteGroup is a custom Kubernetes resource definition. It provides a way to define the ingress routing for Kubernetes services. It allows route matching based on any HTTP request attributes, and provides a clean way for the request flow augmentation and traffic shaping. It supports higher level features like gradual traffic switching, A/B testing, and more. Example: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : backends : - name : variant-a type : service serviceName : service-a servicePort : 80 - name : variant-b type : service serviceName : service-b servicePort : 80 defaultBackends : - backendName : variant-b routes : - pathSubtree : / filters : - responseCookie(\"canary\", \"A\") predicates : - Traffic(.1) backends : - backendName : variant-a - pathSubtree : / filters : - responseCookie(\"canary\", \"B\") - pathSubtree : / predicates : - Cookie(\"canary\", \"A\") backends : - backendName : variant-a - pathSubtree : / predicates : - Cookie(\"canary\", \"B\") (See a more detailed explanation of the above example further down in this document.) Links: RouteGroup semantics CRD definition","title":"RouteGroups"},{"location":"kubernetes/routegroups/#requirements","text":"External DNS v0.7.0 or higher Kubernetes Ingress Controller for AWS v0.10.0 or higher","title":"Requirements"},{"location":"kubernetes/routegroups/#installation","text":"The definition file of the CRD can be found as part of Skipper\u2019s source code, at: https://github.com/zalando/skipper/blob/master/dataclients/kubernetes/deploy/apply/routegroups_crd.yaml To install it manually in a cluster, assuming the current directory is the root of Skipper\u2019s source, call this command: kubectl apply -f dataclients/kubernetes/deploy/apply/routegroups_crd.yaml This will install a namespaced resource definition, providing the RouteGroup kind: full name: routegroups.zalando.org resource group: zalando.org/v1 resource names: routegroup, routegroups, rg, rgs kind: RouteGroup The route groups, once any is defined, can be displayed then via kubectl as: kubectl get rgs The API URL of the routegroup resources will be: https://kubernetes-api-hostname/apis/zalando.org/v1/routegroups","title":"Installation"},{"location":"kubernetes/routegroups/#usage","text":"The absolute minimal route group configuration for a Kubernetes service (my-service) looks as follows: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-backend This is equivalent to the ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : backend : serviceName : my-service servicePort : 80 Notice that the route group contains a list of actual backends, and the defined service backend is then referenced as the default backend. This structure plays a role in supporting scenarios like A/B testing and gradual traffic switching, explained below . The backend definition also has a type field, whose values can be service, lb, network, shunt, loopback or dynamic. More details on that below . Creating, updating and deleting route groups happens the same way as with ingress objects. E.g, manually applying a route group definition: kubectl apply -f my-route-group.yaml","title":"Usage"},{"location":"kubernetes/routegroups/#hosts","text":"Format Hosts contain hostnames that are used to match the requests handled by a given route group. They are also used to update the required DNS entries and load balancer configuration if the cluster is set up that way. Note that it is also possible to use any Skipper predicate in the routes of a route group, with the Host predicate included, but the hostnames defined that way will not serve as input for the DNS configuration.","title":"Hosts"},{"location":"kubernetes/routegroups/#backends","text":"Format General backend reference RouteGroups support different backends. The most typical backend type is the \u2018service\u2019, and it works the same way as in case of ingress definitions. In a RouteGroup, there can be multiple backends and they are listed on the top level of the route group spec, and are referenced from the actual routes or as default backends.","title":"Backends"},{"location":"kubernetes/routegroups/#typeservice","text":"This backend resolves to a Kubernetes service. It works the same way as in case of Ingress definitions. Skipper resolves the Services to the available Endpoints belonging to the Service, and generates load balanced routes using them. (This basically means that under the hood, a service backend becomes an lb backend.)","title":"type=service"},{"location":"kubernetes/routegroups/#typelb","text":"This backend provides load balancing between multiple network endpoints. Keep in mind that the service type backend automatically generates load balanced routes for the service endpoints, so this backend type typically doesn\u2019t need to be used for services.","title":"type=lb"},{"location":"kubernetes/routegroups/#typenetwork","text":"This backend type results in routes that proxy incoming requests to the defined network address, regardless of the Kubernetes semantics, and allows URLs that point somewhere else, potentially outside of the cluster, too.","title":"type=network"},{"location":"kubernetes/routegroups/#typeshunt-typeloopback-typedynamic","text":"These backend types allow advanced routing setups. Please check the reference manual for more details.","title":"type=shunt, type=loopback, type=dynamic"},{"location":"kubernetes/routegroups/#default-backends","text":"Format A default backend is a reference to one of the defined backends. When a route doesn\u2019t specify which backend(s) to use, the ones referenced in the default backends will be used. In case there are no individual routes at all in the route group, a default set of routes (one or more) will be generated and will proxy the incoming traffic to the default backends. The reason, why multiple backends can be referenced as default, is that this makes it easy to execute gradual traffic switching between different versions, even more than two, of the same application. See more .","title":"Default Backends"},{"location":"kubernetes/routegroups/#routes","text":"Format Routes define where to and how the incoming requests will be proxied. The predicates, including the path, pathSubtree, pathRegexp and methods fields, and any free-form predicate listed under the predicates field, control which requests are matched by a route, the filters can apply changes to the forwarded requests and the returned responses, and the backend refs, if defined, override the default backends, where the requests will be proxied to. If a route group doesn\u2019t contain any explicit routes, but it contains default backends, a default set of routes will be generated for the route group. Important to bear in mind about the path fields, that the plain \u2018path\u2019 means exact path match, while \u2018pathSubtree\u2019 behaves as a path prefix, and so it is more similar to the path in the Ingress specification. See also: predicates filters","title":"Routes"},{"location":"kubernetes/routegroups/#gradual-traffic-switching","text":"The weighted backend references allow to split the traffic of a single route and send it to different backends with the ratio defined by the weights of the backend references. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : hosts : - api.example.org backends : - name : api-svc-v1 type : service serviceName : api-service-v1 servicePort : 80 - name : api-svc-v2 type : service serviceName : foo-service-v2 servicePort : 80 routes : - pathSubtree : /api backends : - backendName : api-svc-v1 weight : 80 - backendName : api-svc-v2 weight : 20 In case of the above example, 80% of the requests is sent to api-service-v1 and the rest is sent to api-service-v2. Since this type of weighted traffic switching can be used in combination with the Traffic predicate, it is possible to control the routing of a long running A/B test, while still executing gradual traffic switching independently to deploy a new version of the variants, maybe to deploy a fix only to one variant. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-routes spec : hosts : - api.example.org backends : - name : variant-a type : service serviceName : service-a servicePort : 80 - name : variant-b type : service serviceName : service-b-v1 servicePort : 80 - name : variant-b-v2 type : service serviceName : service-b-v2 servicePort : 80 defaultBackends : - backendName : variant-b weight : 80 - backendName : variant-b-v2 weight : 20 routes : - filters : - responseCookie(\"canary\", \"A\") predicates : - Traffic(.1) backends : - backendName : variant-a - filters : - responseCookie(\"canary\", \"B\") - predicates : - Cookie(\"canary\", \"A\") backends : - backendName : variant-a - predicates : - Cookie(\"canary\", \"B\") See also: Traffic predicate","title":"Gradual traffic switching"},{"location":"kubernetes/routegroups/#mapping-from-ingress-to-routegroups","text":"RouteGroups are one-way compatible with Ingress, meaning that every Ingress specification can be expressed in the RouteGroup format, as well. In the following, we describe the mapping from Ingress fields to RouteGroup fields.","title":"Mapping from Ingress to RouteGroups"},{"location":"kubernetes/routegroups/#ingress-with-default-backend","text":"Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : backend : serviceName : my-service servicePort : 80 RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-backend","title":"Ingress with default backend"},{"location":"kubernetes/routegroups/#ingress-with-path-rule","text":"Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api","title":"Ingress with path rule"},{"location":"kubernetes/routegroups/#ingress-with-multiple-hosts","text":"Ingress (we need to define two rules): apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 - host : legacy-name.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 RouteGroup (we just define an additional host): apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org - legacy-name.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api","title":"Ingress with multiple hosts"},{"location":"kubernetes/routegroups/#ingress-with-multiple-hosts-and-different-routing","text":"For those cases when using multiple hostnames in the same ingress with different rules, we need to apply a small workaround for the equivalent route group spec. Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress spec : rules : - host : api.example.org http : paths : - path : /api backend : serviceName : my-service servicePort : 80 - host : legacy-name.example.org http : paths : - path : /application backend : serviceName : my-service servicePort : 80 RouteGroup (we need to use additional host predicates): apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : hosts : - api.example.org - legacy-name.example.org backends : - name : my-backend type : service serviceName : my-service servicePort : 80 routes : - pathSubtree : /api predicates : - Host(\"api.example.org\") - pathSubtree : /application predicates : - Host(\"legacy-name.example.org\") The RouteGroups allow multiple hostnames for each route group, but by default, their union is used during routing. If we want to distinguish between them, then we need to use an additional Host predicate in the routes. Importantly, only the hostnames listed under the hosts field serve as input for the DNS and LB configuration.","title":"Ingress with multiple hosts, and different routing"},{"location":"kubernetes/routegroups/#mapping-skipper-ingress-extensions-to-routegroups","text":"Skipper accepts a set of annotations in Ingress objects that give access to certain Skipper features that would not be possible with the native fields of the Ingress spec, e.g. improved path handling or rate limiting. These annotations can be expressed now natively in the RouteGroups.","title":"Mapping Skipper Ingress extensions to RouteGroups"},{"location":"kubernetes/routegroups/#zalandoorgbackend-weights","text":"Backend weights are now part of the backend references, and they can be controlled for multiple backend sets within the same route group. See Gradual traffic switching .","title":"zalando.org/backend-weights"},{"location":"kubernetes/routegroups/#zalandoorgskipper-filter-and-zalandoorgskipper-predicate","text":"Filters and predicates are now part of the route objects, and different set of filters or predicates can be set for different routes.","title":"zalando.org/skipper-filter and zalando.org/skipper-predicate"},{"location":"kubernetes/routegroups/#zalandoorgskipper-routes","text":"\u201cCustom routes\u201d in a route group are unnecessary, because every route can be configured with predicates, filters and backends without limitations. E.g where an ingress annotation\u2019s metadata may look like this: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : my-ingress zalando.org/skipper-routes : | Method(\"OPTIONS\") -> status(200) -> <shunt> spec : backend : serviceName : my-service servicePort : 80 the equivalent RouteGroup would look like this: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 - name : options200 type : shunt defaultBackends : - backendName : my-backend routes : - pathSubtree : / - pathSubtree : / methods : OPTIONS filters : - status(200) backends : - options200","title":"zalando.org/skipper-routes"},{"location":"kubernetes/routegroups/#zalandoorgratelimit","text":"The ratelimiting can be defined on the route level among the filters, in the same format as in this annotation.","title":"zalando.org/ratelimit"},{"location":"kubernetes/routegroups/#zalandoorgskipper-ingress-redirect-and-zalandoorgskipper-ingress-redirect-code","text":"Skipper ingress provides global HTTPS redirect, but it allows individual ingresses to override the global settings: enabling/disabling it and changing the default redirect code. With route groups, this override can be achieved by simply defining an addtional route, with the same matching rules, and therefore the override can be controlled eventually on a route basis. E.g: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 - name : redirectShunt type : shunt defaultBackends : - backendName : my-backend routes : - pathSubtree : / - pathSubtree : / predicates : - Header(\"X-Forwarded-Proto\", \"http\") filters : - redirectTo(302, \"https:\") backends : - redirectShunt","title":"zalando.org/skipper-ingress-redirect and zalando.org/skipper-ingress-redirect-code"},{"location":"kubernetes/routegroups/#zalandoorgskipper-loadbalancer","text":"Skipper Ingress doesn\u2019t use the ClusterIP of the Service for forwarding the traffic to, but sends it directly to the Endpoints represented by the Service, and balances the load between them with the round-robin algorithm. The algorithm choice can be overridden by this annotation. In case of the RouteGroups, the algorithm is simply an attribute of the backend definition, and it can be set individually for each backend. E.g: backends: - name: my-backend type: service serviceName: my-service servicePort: 80 algorithm: consistentHash See also: Load Balancer backend","title":"zalando.org/skipper-loadbalancer"},{"location":"kubernetes/routegroups/#zalandoorgskipper-ingress-path-mode","text":"The route objects support the different path lookup modes, by using the path, pathSubtree or the pathRegexp field. See also the route matching explained for the internals. The mapping is as follows: Ingress: RouteGroup: kubernetes-ingress and /foo pathRegexp: ^/foo path-regexp and /foo pathRegexp: /foo path-prefix and /foo pathSubtree: /foo kubernetes-ingress and /foo$ path: /foo","title":"zalando.org/skipper-ingress-path-mode"},{"location":"kubernetes/routegroups/#multiple-skipper-deployments","text":"If you want to split for example internal and public traffic, it might be a good choice to split your RouteGroups. Skipper has the flag --kubernetes-routegroup-class=<string> to only select RouteGroup objects that have the annotation zalando.org/routegroup.class set to <string> . Skipper will only create routes for RouteGroup objects with it\u2019s annotation or RouteGroup objects that do not have this annotation. The default class is skipper , if not set. Example RouteGroup: apiVersion : zalando.org/v1 kind : RouteGroup metadata : name : my-route-group annotations : zalando.org/routegroup.class : internal spec : backends : - name : my-backend type : service serviceName : my-service servicePort : 80 defaultBackends : - backendName : my-service","title":"Multiple skipper deployments"},{"location":"operation/deployment/","text":"Deployments and Data-Clients \u00b6 Edge HTTP Routing \u00b6 Edge HTTP routing is the first hit to your production HTTP loadbalancer. Skipper can serve this well and reliably in production since 2016. On the edge you want to dispatch incoming HTTP requests to your backends, which could be a microservice architecture. In this deployment mode you might have 100k HTTP routes, which are used in production and modified by many parties. To support this scenario we have the etcd dataclient . Etcd is a distributed database. TODO: why we use ETCD for this purpose Kubernetes Ingress \u00b6 Kubernetes Ingress is the component responsible to route traffic into your Kubernetes cluster. As deployer you can define an ingress object and an ingress controller will make sure incoming traffic gets routed to her backend service as defined. Skipper supports this scenario with the Kubernetes dataclient and is used in production since end of 2016. Skipper as ingress controller does not need to have any file configuration or anything external which configures Skipper. Skipper automatically finds Ingress objects and configures routes automatically, without reloading. The only requirement is to target all traffic you want to serve with Kubernetes to a loadbalancer pool of Skippers. This is a clear advantage over other ingress controllers like nginx, haproxy or envoy. Read more about Skipper\u2019s Kubernetes dataclient . Demos / Talks \u00b6 In demos you may want to show arbitrary hello world applications. You can easily describe html or json output on the command line with the route-string dataclient . Simple Routes File \u00b6 The most static deployment that is known from apache, nginx or haproxy is write your routes into a file and start your http server. This is what the Eskip file dataclient is about.","title":"Deployment"},{"location":"operation/deployment/#deployments-and-data-clients","text":"","title":"Deployments and Data-Clients"},{"location":"operation/deployment/#edge-http-routing","text":"Edge HTTP routing is the first hit to your production HTTP loadbalancer. Skipper can serve this well and reliably in production since 2016. On the edge you want to dispatch incoming HTTP requests to your backends, which could be a microservice architecture. In this deployment mode you might have 100k HTTP routes, which are used in production and modified by many parties. To support this scenario we have the etcd dataclient . Etcd is a distributed database. TODO: why we use ETCD for this purpose","title":"Edge HTTP Routing"},{"location":"operation/deployment/#kubernetes-ingress","text":"Kubernetes Ingress is the component responsible to route traffic into your Kubernetes cluster. As deployer you can define an ingress object and an ingress controller will make sure incoming traffic gets routed to her backend service as defined. Skipper supports this scenario with the Kubernetes dataclient and is used in production since end of 2016. Skipper as ingress controller does not need to have any file configuration or anything external which configures Skipper. Skipper automatically finds Ingress objects and configures routes automatically, without reloading. The only requirement is to target all traffic you want to serve with Kubernetes to a loadbalancer pool of Skippers. This is a clear advantage over other ingress controllers like nginx, haproxy or envoy. Read more about Skipper\u2019s Kubernetes dataclient .","title":"Kubernetes Ingress"},{"location":"operation/deployment/#demos-talks","text":"In demos you may want to show arbitrary hello world applications. You can easily describe html or json output on the command line with the route-string dataclient .","title":"Demos / Talks"},{"location":"operation/deployment/#simple-routes-file","text":"The most static deployment that is known from apache, nginx or haproxy is write your routes into a file and start your http server. This is what the Eskip file dataclient is about.","title":"Simple Routes File"},{"location":"operation/operation/","text":"Operations \u00b6 This is the work in progress operations guide for showing information, which are relevant for production use. Skipper is proven to scale with number of routes beyond 300.000 routes per instance. Skipper is running with peaks to 65.000 http requests per second using multiple instances. Connection Options \u00b6 Skipper\u2019s connection options are allowing you to set Go\u2019s http.Server Options on the client side and http.Transport on the backend side. \u201cIt is recommended to read this blog post about net http timeouts in order to better understand the impact of these settings. Backend \u00b6 Backend is the side skipper opens a client connection to. Closing idle connections is required for DNS failover, because Go\u2019s http.Transport caches DNS lookups and needs to create new connections for doing so. Skipper will start a goroutine and use the specified time.Duration to call CloseIdleConnections() on that http.Transport . -close-idle-conns-period string period of closing all idle connections in seconds or as a duration string. Not closing when less than 0 (default \"20\") This will set MaxIdleConnsPerHost on the http.Transport to limit the number of idle connections per backend such that we do not run out of sockets. -idle-conns-num int maximum idle connections per backend host (default 64) This will set MaxIdleConns on the http.Transport to limit the number for all backends such that we do not run out of sockets. -disable-http-keepalives bool forces backend to always create a new connection This will set DisableKeepAlives on the http.Transport to disable HTTP keep-alives and to only use the connection for single request. -max-idle-connection-backend int sets the maximum idle connections for all backend connections This will set TLSHandshakeTimeout on the http.Transport to have timeouts based on TLS connections. -tls-timeout-backend duration sets the TLS handshake timeout for backend connections (default 1m0s) This will set Timeout on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -timeout-backend duration sets the TCP client connection timeout for backend connections (default 1m0s) This will set KeepAlive on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -keepalive-backend duration sets the keepalive for backend connections (default 30s) This will set DualStack (IPv4 and IPv6) on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -enable-dualstack-backend enables DualStack for backend connections (default true) Client \u00b6 Client is the side skipper gets incoming calls from. Here we can set timeouts in different parts of the http connection. This will set ReadTimeout in http.Server handling incoming calls from your clients. -read-timeout-server duration set ReadTimeout for http server connections (default 5m0s) This will set ReadHeaderTimeout in http.Server handling incoming calls from your clients. -read-header-timeout-server duration set ReadHeaderTimeout for http server connections (default 1m0s) This will set WriteTimeout in http.Server handling incoming calls from your clients. -write-timeout-server duration set WriteTimeout for http server connections (default 1m0s) This will set IdleTimeout in http.Server handling incoming calls from your clients. If you have another loadbalancer layer in front of your Skipper http routers, for example AWS Application Load Balancers , you should make sure, that Skipper\u2019s idle-timeout-server setting is bigger than the idle timeout from the loadbalancer in front. Wrong combinations of idle timeouts can lead to a few unexpected HTTP 502. -idle-timeout-server duration maximum idle connections per backend host (default 1m0s) This will set MaxHeaderBytes in http.Server to limit the size of the http header from your clients. -max-header-bytes int set MaxHeaderBytes for http server connections (default 1048576) TCP LIFO \u00b6 Skipper implements now controlling the maximum incoming TCP client connections. This is an experimental feature. The purpose of the mechanism is to prevent Skipper requesting more memory than available in case of too many concurrent connections, especially in an autoscaling deployment setup, in those case when the scaling is not fast enough to follow sudden connection spikes. This solution relies on a listener implementation combined with a LIFO queue. It allows only a limited number of connections being handled concurrently, defined by the max concurrency configuration. When the max concurrency limit is reached, the new incoming client connections are stored in a queue. When an active (accepted) connection is closed, the most recent pending connection from the queue will be accepted. When the queue is full, the oldest pending connection is closed and dropped, and the new one is inserted into the queue. The feature can be enabled with the -enable-tcp-queue flag. The maximum concurrency can bet set with the -max-tcp-listener-concurrency flag, or, if this flag is not set, then Skipper tries to infer the maximum accepted concurrency from the system by reading the /sys/fs/cgroup/memory/memory.limit_in_bytes file. In this case, it uses the average expected per request memory requirement, which can be set with the -expected-bytes-per-request flag. Note that the automatically inferred limit may not work as expected in an environment other than cgroups v1. OAuth2 Tokeninfo \u00b6 OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokeninfo-timeout=<OAuthTokeninfoTimeout> . OAuth2 Tokenintrospection RFC7662 \u00b6 OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokenintrospect-timeout=<OAuthTokenintrospectionTimeout> . Monitoring \u00b6 Monitoring is one of the most important things you need to run in production and skipper has a godoc page for the metrics package , describing options and most keys you will find in the metrics handler endpoint. The default is listening on :9911/metrics . You can modify the listen port with the -support-listener flag. Metrics can exposed using formats Codahale (json) or Prometheus and be configured by -metrics-flavour= , which defaults to codahale . To expose both formats you can use a comma separated list: -metrics-flavour=codahale,prometheus . Prometheus \u00b6 In case you want to get metrics in Prometheus format exposed, use this option to enable it: -metrics-flavour=prometheus It will return Prometheus metrics on the common metrics endpoint :9911/metrics. To monitor skipper we recommend the following queries: P99 backend latency: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{}[1m])) by (le)) HTTP 2xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"2.*\"}[1m])) by (le) ) HTTP 4xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"4.*\"}[1m])) by (le) ) HTTP 5xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"52.*\"}[1m])) by (le) ) Max goroutines (depends on label selector): max(go_goroutines{application=\"skipper-ingress\"}) Max threads (depends on label selector): max(go_threads{application=\"skipper-ingress\"}) max heap memory in use in MB (depends on label selector): max(go_memstats_heap_inuse_bytes{application=\"skipper-ingress\"}) / 1024 / 1000 Max number of heap objects (depends on label selector): max(go_memstats_heap_objects{application=\"skipper-ingress\"}) Max of P75 Go GC runtime in ms (depends on label selector): max(go_gc_duration_seconds{application=\"skipper-ingress\",quantile=\"0.75\"}) * 1000 * 1000 P99 request filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_request_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) P99 response filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_response_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) If you use Kubernetes limits or Linux cgroup CFS quotas (depends on label selector): sum(rate(container_cpu_cfs_throttled_periods_total{container_name=\"skipper-ingress\"}[1m])) Connection metrics \u00b6 This option will enable known loadbalancer connections metrics, like counters for active and new connections. This feature sets a metrics callback on http.Server and uses a counter to collect http.ConnState . -enable-connection-metrics enables connection metrics for http server connections It will expose them in /metrics, for example json structure looks like this example: { \"counters\": { \"skipper.lb-conn-active\": { \"count\": 6 }, \"skipper.lb-conn-closed\": { \"count\": 6 }, \"skipper.lb-conn-idle\": { \"count\": 6 }, \"skipper.lb-conn-new\": { \"count\": 6 } }, /* stripped a lot of metrics here */ } LIFO metrics \u00b6 When enabled in the routes, LIFO queues can control the maximum concurrency level proxied to the backends and mitigate the impact of traffic spikes. The current level of concurrency and the size of the queue can be monitored with gauges per each route using one of the lifo filters. To enable monitoring for the lifo filters, use the command line option: -enable-route-lifo-metrics When queried, it will return metrics like: { \"gauges\": { \"skipper.lifo.routeXYZ.active\": { \"value\": 245 }, \"skipper.lifo.routeXYZ.queued\": { \"value\": 27 } } } Application metrics \u00b6 Application metrics for your proxied applications you can enable with the option: -serve-host-metrics enables reporting total serve time metrics for each host This will make sure you will get stats for each \u201cHost\u201d header as \u201ctimers\u201d: \"timers\": { \"skipper.servehost.app1_example_com.GET.200\": { \"15m.rate\": 0.06830666203045982, \"1m.rate\": 2.162612637718806e-06, \"5m.rate\": 0.008312609284452856, \"75%\": 236603815, \"95%\": 236603815, \"99%\": 236603815, \"99.9%\": 236603815, \"count\": 3, \"max\": 236603815, \"mean\": 116515451.66666667, \"mean.rate\": 0.0030589345776699827, \"median\": 91273391, \"min\": 21669149, \"stddev\": 89543653.71950394 }, \"skipper.servehost.app1_example_com.GET.304\": { \"15m.rate\": 0.3503336738177459, \"1m.rate\": 0.07923086447313292, \"5m.rate\": 0.27019839341602214, \"75%\": 99351895.25, \"95%\": 105381847, \"99%\": 105381847, \"99.9%\": 105381847, \"count\": 4, \"max\": 105381847, \"mean\": 47621612, \"mean.rate\": 0.03087161486272533, \"median\": 41676170.5, \"min\": 1752260, \"stddev\": 46489302.203724876 }, \"skipper.servehost.app1_example_com.GET.401\": { \"15m.rate\": 0.16838468990057648, \"1m.rate\": 0.01572861413072501, \"5m.rate\": 0.1194724817779537, \"75%\": 91094832, \"95%\": 91094832, \"99%\": 91094832, \"99.9%\": 91094832, \"count\": 2, \"max\": 91094832, \"mean\": 58090623, \"mean.rate\": 0.012304914018033056, \"median\": 58090623, \"min\": 25086414, \"stddev\": 33004209 } }, To change the sampling type of how metrics are handled from uniform to exponential decay , you can use the following option, which is better for not so huge utilized applications (less than 100 requests per second): -metrics-exp-decay-sample use exponentially decaying sample in metrics Go metrics \u00b6 Metrics from the go runtime memstats are exposed from skipper to the metrics endpoint, default listener :9911, on path /metrics : \"gauges\": { \"skipper.runtime.MemStats.Alloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.BuckHashSys\": { \"value\": 1452675 }, \"skipper.runtime.MemStats.DebugGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.EnableGC\": { \"value\": 1 }, \"skipper.runtime.MemStats.Frees\": { \"value\": 121 }, \"skipper.runtime.MemStats.HeapAlloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.HeapIdle\": { \"value\": 778240 }, \"skipper.runtime.MemStats.HeapInuse\": { \"value\": 4988928 }, \"skipper.runtime.MemStats.HeapObjects\": { \"value\": 24005 }, \"skipper.runtime.MemStats.HeapReleased\": { \"value\": 0 }, \"skipper.runtime.MemStats.HeapSys\": { \"value\": 5767168 }, \"skipper.runtime.MemStats.LastGC\": { \"value\": 1516098381155094500 }, \"skipper.runtime.MemStats.Lookups\": { \"value\": 2 }, \"skipper.runtime.MemStats.MCacheInuse\": { \"value\": 6944 }, \"skipper.runtime.MemStats.MCacheSys\": { \"value\": 16384 }, \"skipper.runtime.MemStats.MSpanInuse\": { \"value\": 77368 }, \"skipper.runtime.MemStats.MSpanSys\": { \"value\": 81920 }, \"skipper.runtime.MemStats.Mallocs\": { \"value\": 1459 }, \"skipper.runtime.MemStats.NextGC\": { \"value\": 4194304 }, \"skipper.runtime.MemStats.NumGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.PauseTotalNs\": { \"value\": 683352 }, \"skipper.runtime.MemStats.StackInuse\": { \"value\": 524288 }, \"skipper.runtime.MemStats.StackSys\": { \"value\": 524288 }, \"skipper.runtime.MemStats.Sys\": { \"value\": 9246968 }, \"skipper.runtime.MemStats.TotalAlloc\": { \"value\": 35127624 }, \"skipper.runtime.NumCgoCall\": { \"value\": 0 }, \"skipper.runtime.NumGoroutine\": { \"value\": 11 }, \"skipper.runtime.NumThread\": { \"value\": 9 } }, \"histograms\": { \"skipper.runtime.MemStats.PauseNs\": { \"75%\": 82509.25, \"95%\": 132609, \"99%\": 132609, \"99.9%\": 132609, \"count\": 12, \"max\": 132609, \"mean\": 56946, \"median\": 39302.5, \"min\": 28749, \"stddev\": 31567.015005117817 } } OpenTracing \u00b6 Skipper has support for different OpenTracing API vendors, including jaeger , lightstep and instana . You can configure tracing implementations with a flag and pass information and tags to the tracer: -opentracing=<vendor> component-name=skipper-ingress ... tag=cluster=mycluster ... The best tested tracer is the lightstep tracer, because we use it in our setup. In case you miss something for your chosen tracer, please open an issue or pull request in our repository . Skipper creates up to 5 different spans : Some Tag details are added to all spans. Ingress span \u00b6 The Ingress span is active from getting the request in Skipper\u2019s main http handler, until we served the response to the client of the request. Tags: component: skipper hostname: ip-10-149-64-142 http.host: hostname.example.org http.method: GET http.path: / http.remote_addr: 10.149.66.207:14574 http.url: / span.kind: server Proxy span \u00b6 The Proxy span starts just before executing the backend call. Tags: component: skipper hostname: ip-10-149-65-70 http.host: hostname.example.org http.method: GET http.path: / http.remote_addr: http.status_code: 200 http.url: http://10.2.0.11:9090/ skipper.route_id: kube_default__example_ingress_hostname_example_org____example_backend span.kind: client Proxy span has logs to measure connect ( dial_context ), http roundtrip ( http_roundtrip ), stream headers from backend to client ( stream_Headers ) and stream body from backend to client ( streamBody.byte ). Request filters span \u00b6 The request filters span logs shows start and end values for each filter applied. Response filters span \u00b6 The response filters span logs shows start and end values for each filter applied. Auth filters span \u00b6 Auth filters are special, because they might call an authorization endpoint, which should be also visible in the trace. This span can have the name \u201ctokeninfo\u201d, \u201ctokenintrospection\u201d or \u201cwebhook\u201d depending on the filter used by the matched route. Tags: - http.url: https://auth.example.org The auth filters have trace log values start and end for DNS, TCP connect, TLS handshake and connection pool: Dataclient \u00b6 Dataclients poll some kind of data source for routes. To change the timeout for calls that polls a dataclient, which could be the Kubernetes API, use the following option: -source-poll-timeout int polling timeout of the routing data sources, in milliseconds (default 3000) Routing table information \u00b6 Skipper allows you to get some runtime insights. You can get the current routing table from skipper with in the eskip file format : curl localhost:9911/routes * -> \"http://localhost:12345/\" You also can get the number of routes X-Count and the UNIX timestamp of the last route table update X-Timestamp , using a HEAD request: curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1517777628 Date: Sun, 04 Feb 2018 20:54:31 GMT The number of routes given is limited (1024 routes by default). In order to control this limits, there are two parameters: limit and offset . The limit defines the number of routes to get and offset where to start the list. Thanks to this, it\u2019s possible to get the results paginated or getting all of them at the same time. curl localhost:9911/routes?offset=200&limit=100 Memory consumption \u00b6 While Skipper is generally not memory bound, some features may require some attention and planning regarding the memory consumption. Potentially high memory consumers: Metrics Filters Slow Backends and chatty clients Make sure you monitor backend latency, request and error rates. Additionally use Go metrics for the number of goroutines and threads, GC pause times should be less than 1ms in general, route lookup time, request and response filter times and heap memory. Metrics \u00b6 Memory consumption of metrics are dependent on enabled command line flags. Make sure to monitor Go metrics. If you use -metrics-flavour=codahale,prometheus you enable both storage backends. If you use the Prometheus histogram buckets -histogram-metric-buckets . If you enable route based -route-backend-metrics -route-response-metrics -serve-route-metrics , error codes -route-response-metrics and host -serve-host-metrics based metrics it can count up. Please check the support listener endpoint (default 9911) to understand the usage: % curl localhost:9911/metrics Filters \u00b6 Ratelimit filter clusterClientRatelimit implementation using the swim based protocol, consumes roughly 15MB per filter for 100.000 individual clients and 10 maximum hits. Make sure you monitor Go metrics. Ratelimit filter clusterClientRatelimit implementation using the Redis ring based solution, adds 2 additional roundtrips to redis per hit. Make sure you monitor redis closely, because skipper will fallback to allow traffic if redis can not be reached. Slow Backends \u00b6 Skipper has to keep track of all active connections and http Requests. Slow Backends can pile up in number of connections, that will consume each a little memory per request. If you have high traffic per instance and a backend times out it can start to increase your memory consumption. Make sure you monitor backend latency, request and error rates. Default Filters \u00b6 Default filters will be applied to all routes created or updated. Global Default Filters \u00b6 Global default filters can be specified via two different command line flags -default-filters-prepend and -default-filters-append . Filters passed to these command line flags will be applied to all routes. The difference prepend and append is where in the filter chain these default filters are applied. For example a user specified the route: r: * -> setPath(\"/foo\") If you run skipper with -default-filters-prepend=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") -> setPath(\"/foo\") . If you run skipper with -default-filters-append=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> setPath(\"/foo\") -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") . Kubernetes Default Filters \u00b6 Kubernetes dataclient supports default filters. You can enable this feature by specifying default-filters-dir . The defined directory must contain per-service filter configurations, with file name following the pattern ${service}.${namespace} . The content of the files is the actual filter configurations. These filters are then prepended to the filters already defined in Ingresses. The default filters are supposed to be used only if the filters of the same kind are not configured on the Ingress resource. Otherwise, it can and will lead to potentially contradicting filter configurations and race conditions, i.e. you should specify a specific filter either on the Ingress resource or as a default filter. Scheduler \u00b6 HTTP request schedulers change the queuing behavior of in-flight requests. A queue has two generic properties: a limit of requests and a concurrency level. The limit of request can be unlimited (unbounded queue), or limited (bounded queue). The concurrency level is either limited or unlimited. The default scheduler is an unbounded first in first out (FIFO) queue, that is provided by Go\u2019s standard library. Skipper provides 2 last in first out (LIFO) filters to change the scheduling behavior. On failure conditions, Skipper will return HTTP status code: 503 if the queue is full, which is expected on the route with a failing backend 502 if queue access times out, because the queue access was not fast enough 500 on unknown errors, please create an issue The problem \u00b6 Why should you use boundaries to limit concurrency level and limit the queue? The short answer is resiliency. If you have one route, that is timing out, the request queue of skipper will pile up and consume much more memory, than before. This can lead to out of memory kill, which will affect all other routes. In this comment you can see the memory usage increased in Go\u2019s standard library bufio package. Why LIFO queue instead of FIFO queue? In normal cases the queue should not contain many requests. Skipper is able to process many requests concurrently without letting the queue piling up. In overrun situations you might want to process at least some fraction of requests instead of timing out all requests. LIFO would not time out all requests within the queue, if the backend is capable of responding some requests fast enough. A solution \u00b6 Skipper has two filters lifo() and lifoGroup() , that can limit the number of requests for a route. A documented load test shows the behavior with an enabled lifo(100,100,\"10s\") filter for all routes, that was added by default. You can do this, if you pass the following flag to skipper: -default-filters-prepend=lifo(100,100,\"10s\") . Both LIFO filters will, use a last in first out queue to handle most requests fast. If skipper is in an overrun mode, it will serve some requests fast and some will timeout. The idea is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . Skipper\u2019s scheduler implementation makes sure, that one route will not interfere with other routes, if these routes are not in the same scheduler group. LifoGroup has a user chosen scheduler group and lifo() will get a per route unique scheduler group. URI standards interpretation \u00b6 Considering the following request path: /foo%2Fbar, Skipper can handle it in two different ways. The current default way is that when the request is parsed purely relying on the Go stdlib url package, this path becomes /foo/bar. According to RFC 2616 and RFC 3986, this may be considered wrong, and this path should be parsed as /foo%2Fbar. This is possible to achieve centrally, when Skipper is started with the -rfc-patch-path flag. It is also possible to allow the default behavior and only force the alternative interpretation on a per-route basis with the rfcPath() filter. See rfcPath() . If the second interpretation gets considered the right way, and the other one a bug, then the default value for this flag may become to be on. Debugging Requests \u00b6 Skipper provides filters , that can change HTTP requests. You might want to inspect how the request was changed, during the route processing and check the request that would be made to the backend. Luckily with -debug-listener=:9922 , Skipper can provide you this information. For example you have the following route: kube_default__foo__foo_teapot_example_org_____foo : Host (/^ foo [.] teapot [.] example [.] org$ /) && PathSubtree(\"/ \") -> setRequestHeader(\" X - Foo \", \" hello - world \") -> <roundRobin, \" http :// 10.2 . 0.225 : 9090 \", \" http :// 10.2 . 1.244 : 9090 \" >; If you sent now a request to the debug listener, that will be matched by the route, Skipper will respond with information that show you the matched route, the incoming request, the transformed request and all predicates and filters involved in the route processing: % curl -s http://127.0.0.1:9922/ -H\"Host: foo.teapot.example.org\" | jq . { \" route_id \" : \" kube_default__foo__foo_teapot_example_org_____foo \" , \" route \" : \" Host ( / ^ foo [.] teapot [.] example [.] org $ / ) && PathSubtree ( \\ \" /\\ \" ) -> setRequestHeader ( \\ \" X - Foo \\ \" , \\ \" hello - world \\ \" ) -> < roundRobin , \\ \" http : // 10.2 . 0.225 : 9090 \\ \" , \\ \" http : // 10.2 . 1.244 : 9090 \\ \" > \" , \" incoming \" : { \" method \" : \" GET \" , \" uri \" : \" / \" , \" proto \" : \" HTTP / 1.1 \" , \" header \" : { \" Accept \" : [ \" */* \" ], \" User - Agent \" : [ \" curl / 7.49 . 0 \" ] }, \" host \" : \" foo . teapot . example . org \" , \" remote_address \" : \" 127.0 . 0.1 : 32992 \" }, \" outgoing \" : { \" method \" : \" GET \" , \" uri \" : \"\" , \" proto \" : \" HTTP / 1.1 \" , \" header \" : { \" Accept \" : [ \" */* \" ], \" User - Agent \" : [ \" curl / 7.49 . 0 \" ], \" X - Foo \" : [ \" hello - world \" ] }, \" host \" : \" foo . teapot . example . org \" }, \" response_mod \" : { \" header \" : { \" Server \" : [ \" Skipper \" ] } }, \" filters \" : [ { \" name \" : \" setRequestHeader \" , \" args \" : [ \" X - Foo \" , \" hello - world \" ] } ], \" predicates \" : [ { \" name \" : \" PathSubtree \" , \" args \" : [ \" / \" ] } ] }","title":"Operation"},{"location":"operation/operation/#operations","text":"This is the work in progress operations guide for showing information, which are relevant for production use. Skipper is proven to scale with number of routes beyond 300.000 routes per instance. Skipper is running with peaks to 65.000 http requests per second using multiple instances.","title":"Operations"},{"location":"operation/operation/#connection-options","text":"Skipper\u2019s connection options are allowing you to set Go\u2019s http.Server Options on the client side and http.Transport on the backend side. \u201cIt is recommended to read this blog post about net http timeouts in order to better understand the impact of these settings.","title":"Connection Options"},{"location":"operation/operation/#backend","text":"Backend is the side skipper opens a client connection to. Closing idle connections is required for DNS failover, because Go\u2019s http.Transport caches DNS lookups and needs to create new connections for doing so. Skipper will start a goroutine and use the specified time.Duration to call CloseIdleConnections() on that http.Transport . -close-idle-conns-period string period of closing all idle connections in seconds or as a duration string. Not closing when less than 0 (default \"20\") This will set MaxIdleConnsPerHost on the http.Transport to limit the number of idle connections per backend such that we do not run out of sockets. -idle-conns-num int maximum idle connections per backend host (default 64) This will set MaxIdleConns on the http.Transport to limit the number for all backends such that we do not run out of sockets. -disable-http-keepalives bool forces backend to always create a new connection This will set DisableKeepAlives on the http.Transport to disable HTTP keep-alives and to only use the connection for single request. -max-idle-connection-backend int sets the maximum idle connections for all backend connections This will set TLSHandshakeTimeout on the http.Transport to have timeouts based on TLS connections. -tls-timeout-backend duration sets the TLS handshake timeout for backend connections (default 1m0s) This will set Timeout on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -timeout-backend duration sets the TCP client connection timeout for backend connections (default 1m0s) This will set KeepAlive on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -keepalive-backend duration sets the keepalive for backend connections (default 30s) This will set DualStack (IPv4 and IPv6) on net.Dialer that is the implementation of DialContext, which is the TCP connection pool used in the http.Transport . -enable-dualstack-backend enables DualStack for backend connections (default true)","title":"Backend"},{"location":"operation/operation/#client","text":"Client is the side skipper gets incoming calls from. Here we can set timeouts in different parts of the http connection. This will set ReadTimeout in http.Server handling incoming calls from your clients. -read-timeout-server duration set ReadTimeout for http server connections (default 5m0s) This will set ReadHeaderTimeout in http.Server handling incoming calls from your clients. -read-header-timeout-server duration set ReadHeaderTimeout for http server connections (default 1m0s) This will set WriteTimeout in http.Server handling incoming calls from your clients. -write-timeout-server duration set WriteTimeout for http server connections (default 1m0s) This will set IdleTimeout in http.Server handling incoming calls from your clients. If you have another loadbalancer layer in front of your Skipper http routers, for example AWS Application Load Balancers , you should make sure, that Skipper\u2019s idle-timeout-server setting is bigger than the idle timeout from the loadbalancer in front. Wrong combinations of idle timeouts can lead to a few unexpected HTTP 502. -idle-timeout-server duration maximum idle connections per backend host (default 1m0s) This will set MaxHeaderBytes in http.Server to limit the size of the http header from your clients. -max-header-bytes int set MaxHeaderBytes for http server connections (default 1048576)","title":"Client"},{"location":"operation/operation/#tcp-lifo","text":"Skipper implements now controlling the maximum incoming TCP client connections. This is an experimental feature. The purpose of the mechanism is to prevent Skipper requesting more memory than available in case of too many concurrent connections, especially in an autoscaling deployment setup, in those case when the scaling is not fast enough to follow sudden connection spikes. This solution relies on a listener implementation combined with a LIFO queue. It allows only a limited number of connections being handled concurrently, defined by the max concurrency configuration. When the max concurrency limit is reached, the new incoming client connections are stored in a queue. When an active (accepted) connection is closed, the most recent pending connection from the queue will be accepted. When the queue is full, the oldest pending connection is closed and dropped, and the new one is inserted into the queue. The feature can be enabled with the -enable-tcp-queue flag. The maximum concurrency can bet set with the -max-tcp-listener-concurrency flag, or, if this flag is not set, then Skipper tries to infer the maximum accepted concurrency from the system by reading the /sys/fs/cgroup/memory/memory.limit_in_bytes file. In this case, it uses the average expected per request memory requirement, which can be set with the -expected-bytes-per-request flag. Note that the automatically inferred limit may not work as expected in an environment other than cgroups v1.","title":"TCP LIFO"},{"location":"operation/operation/#oauth2-tokeninfo","text":"OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokeninfo-timeout=<OAuthTokeninfoTimeout> .","title":"OAuth2 Tokeninfo"},{"location":"operation/operation/#oauth2-tokenintrospection-rfc7662","text":"OAuth2 filters integrate with external services and have their own connection handling. Outgoing calls to these services have a default timeout of 2s, which can be changed by the flag -oauth2-tokenintrospect-timeout=<OAuthTokenintrospectionTimeout> .","title":"OAuth2 Tokenintrospection RFC7662"},{"location":"operation/operation/#monitoring","text":"Monitoring is one of the most important things you need to run in production and skipper has a godoc page for the metrics package , describing options and most keys you will find in the metrics handler endpoint. The default is listening on :9911/metrics . You can modify the listen port with the -support-listener flag. Metrics can exposed using formats Codahale (json) or Prometheus and be configured by -metrics-flavour= , which defaults to codahale . To expose both formats you can use a comma separated list: -metrics-flavour=codahale,prometheus .","title":"Monitoring"},{"location":"operation/operation/#prometheus","text":"In case you want to get metrics in Prometheus format exposed, use this option to enable it: -metrics-flavour=prometheus It will return Prometheus metrics on the common metrics endpoint :9911/metrics. To monitor skipper we recommend the following queries: P99 backend latency: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{}[1m])) by (le)) HTTP 2xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"2.*\"}[1m])) by (le) ) HTTP 4xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"4.*\"}[1m])) by (le) ) HTTP 5xx rate: histogram_quantile(0.99, sum(rate(skipper_serve_host_duration_seconds_bucket{code =~ \"52.*\"}[1m])) by (le) ) Max goroutines (depends on label selector): max(go_goroutines{application=\"skipper-ingress\"}) Max threads (depends on label selector): max(go_threads{application=\"skipper-ingress\"}) max heap memory in use in MB (depends on label selector): max(go_memstats_heap_inuse_bytes{application=\"skipper-ingress\"}) / 1024 / 1000 Max number of heap objects (depends on label selector): max(go_memstats_heap_objects{application=\"skipper-ingress\"}) Max of P75 Go GC runtime in ms (depends on label selector): max(go_gc_duration_seconds{application=\"skipper-ingress\",quantile=\"0.75\"}) * 1000 * 1000 P99 request filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_request_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) P99 response filter duration (depends on label selector): histogram_quantile(0.99, sum(rate(skipper_filter_response_duration_seconds_bucket{application=\"skipper-ingress\"}[1m])) by (le) ) If you use Kubernetes limits or Linux cgroup CFS quotas (depends on label selector): sum(rate(container_cpu_cfs_throttled_periods_total{container_name=\"skipper-ingress\"}[1m]))","title":"Prometheus"},{"location":"operation/operation/#connection-metrics","text":"This option will enable known loadbalancer connections metrics, like counters for active and new connections. This feature sets a metrics callback on http.Server and uses a counter to collect http.ConnState . -enable-connection-metrics enables connection metrics for http server connections It will expose them in /metrics, for example json structure looks like this example: { \"counters\": { \"skipper.lb-conn-active\": { \"count\": 6 }, \"skipper.lb-conn-closed\": { \"count\": 6 }, \"skipper.lb-conn-idle\": { \"count\": 6 }, \"skipper.lb-conn-new\": { \"count\": 6 } }, /* stripped a lot of metrics here */ }","title":"Connection metrics"},{"location":"operation/operation/#lifo-metrics","text":"When enabled in the routes, LIFO queues can control the maximum concurrency level proxied to the backends and mitigate the impact of traffic spikes. The current level of concurrency and the size of the queue can be monitored with gauges per each route using one of the lifo filters. To enable monitoring for the lifo filters, use the command line option: -enable-route-lifo-metrics When queried, it will return metrics like: { \"gauges\": { \"skipper.lifo.routeXYZ.active\": { \"value\": 245 }, \"skipper.lifo.routeXYZ.queued\": { \"value\": 27 } } }","title":"LIFO metrics"},{"location":"operation/operation/#application-metrics","text":"Application metrics for your proxied applications you can enable with the option: -serve-host-metrics enables reporting total serve time metrics for each host This will make sure you will get stats for each \u201cHost\u201d header as \u201ctimers\u201d: \"timers\": { \"skipper.servehost.app1_example_com.GET.200\": { \"15m.rate\": 0.06830666203045982, \"1m.rate\": 2.162612637718806e-06, \"5m.rate\": 0.008312609284452856, \"75%\": 236603815, \"95%\": 236603815, \"99%\": 236603815, \"99.9%\": 236603815, \"count\": 3, \"max\": 236603815, \"mean\": 116515451.66666667, \"mean.rate\": 0.0030589345776699827, \"median\": 91273391, \"min\": 21669149, \"stddev\": 89543653.71950394 }, \"skipper.servehost.app1_example_com.GET.304\": { \"15m.rate\": 0.3503336738177459, \"1m.rate\": 0.07923086447313292, \"5m.rate\": 0.27019839341602214, \"75%\": 99351895.25, \"95%\": 105381847, \"99%\": 105381847, \"99.9%\": 105381847, \"count\": 4, \"max\": 105381847, \"mean\": 47621612, \"mean.rate\": 0.03087161486272533, \"median\": 41676170.5, \"min\": 1752260, \"stddev\": 46489302.203724876 }, \"skipper.servehost.app1_example_com.GET.401\": { \"15m.rate\": 0.16838468990057648, \"1m.rate\": 0.01572861413072501, \"5m.rate\": 0.1194724817779537, \"75%\": 91094832, \"95%\": 91094832, \"99%\": 91094832, \"99.9%\": 91094832, \"count\": 2, \"max\": 91094832, \"mean\": 58090623, \"mean.rate\": 0.012304914018033056, \"median\": 58090623, \"min\": 25086414, \"stddev\": 33004209 } }, To change the sampling type of how metrics are handled from uniform to exponential decay , you can use the following option, which is better for not so huge utilized applications (less than 100 requests per second): -metrics-exp-decay-sample use exponentially decaying sample in metrics","title":"Application metrics"},{"location":"operation/operation/#go-metrics","text":"Metrics from the go runtime memstats are exposed from skipper to the metrics endpoint, default listener :9911, on path /metrics : \"gauges\": { \"skipper.runtime.MemStats.Alloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.BuckHashSys\": { \"value\": 1452675 }, \"skipper.runtime.MemStats.DebugGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.EnableGC\": { \"value\": 1 }, \"skipper.runtime.MemStats.Frees\": { \"value\": 121 }, \"skipper.runtime.MemStats.HeapAlloc\": { \"value\": 3083680 }, \"skipper.runtime.MemStats.HeapIdle\": { \"value\": 778240 }, \"skipper.runtime.MemStats.HeapInuse\": { \"value\": 4988928 }, \"skipper.runtime.MemStats.HeapObjects\": { \"value\": 24005 }, \"skipper.runtime.MemStats.HeapReleased\": { \"value\": 0 }, \"skipper.runtime.MemStats.HeapSys\": { \"value\": 5767168 }, \"skipper.runtime.MemStats.LastGC\": { \"value\": 1516098381155094500 }, \"skipper.runtime.MemStats.Lookups\": { \"value\": 2 }, \"skipper.runtime.MemStats.MCacheInuse\": { \"value\": 6944 }, \"skipper.runtime.MemStats.MCacheSys\": { \"value\": 16384 }, \"skipper.runtime.MemStats.MSpanInuse\": { \"value\": 77368 }, \"skipper.runtime.MemStats.MSpanSys\": { \"value\": 81920 }, \"skipper.runtime.MemStats.Mallocs\": { \"value\": 1459 }, \"skipper.runtime.MemStats.NextGC\": { \"value\": 4194304 }, \"skipper.runtime.MemStats.NumGC\": { \"value\": 0 }, \"skipper.runtime.MemStats.PauseTotalNs\": { \"value\": 683352 }, \"skipper.runtime.MemStats.StackInuse\": { \"value\": 524288 }, \"skipper.runtime.MemStats.StackSys\": { \"value\": 524288 }, \"skipper.runtime.MemStats.Sys\": { \"value\": 9246968 }, \"skipper.runtime.MemStats.TotalAlloc\": { \"value\": 35127624 }, \"skipper.runtime.NumCgoCall\": { \"value\": 0 }, \"skipper.runtime.NumGoroutine\": { \"value\": 11 }, \"skipper.runtime.NumThread\": { \"value\": 9 } }, \"histograms\": { \"skipper.runtime.MemStats.PauseNs\": { \"75%\": 82509.25, \"95%\": 132609, \"99%\": 132609, \"99.9%\": 132609, \"count\": 12, \"max\": 132609, \"mean\": 56946, \"median\": 39302.5, \"min\": 28749, \"stddev\": 31567.015005117817 } }","title":"Go metrics"},{"location":"operation/operation/#opentracing","text":"Skipper has support for different OpenTracing API vendors, including jaeger , lightstep and instana . You can configure tracing implementations with a flag and pass information and tags to the tracer: -opentracing=<vendor> component-name=skipper-ingress ... tag=cluster=mycluster ... The best tested tracer is the lightstep tracer, because we use it in our setup. In case you miss something for your chosen tracer, please open an issue or pull request in our repository . Skipper creates up to 5 different spans : Some Tag details are added to all spans.","title":"OpenTracing"},{"location":"operation/operation/#ingress-span","text":"The Ingress span is active from getting the request in Skipper\u2019s main http handler, until we served the response to the client of the request. Tags: component: skipper hostname: ip-10-149-64-142 http.host: hostname.example.org http.method: GET http.path: / http.remote_addr: 10.149.66.207:14574 http.url: / span.kind: server","title":"Ingress span"},{"location":"operation/operation/#proxy-span","text":"The Proxy span starts just before executing the backend call. Tags: component: skipper hostname: ip-10-149-65-70 http.host: hostname.example.org http.method: GET http.path: / http.remote_addr: http.status_code: 200 http.url: http://10.2.0.11:9090/ skipper.route_id: kube_default__example_ingress_hostname_example_org____example_backend span.kind: client Proxy span has logs to measure connect ( dial_context ), http roundtrip ( http_roundtrip ), stream headers from backend to client ( stream_Headers ) and stream body from backend to client ( streamBody.byte ).","title":"Proxy span"},{"location":"operation/operation/#request-filters-span","text":"The request filters span logs shows start and end values for each filter applied.","title":"Request filters span"},{"location":"operation/operation/#response-filters-span","text":"The response filters span logs shows start and end values for each filter applied.","title":"Response filters span"},{"location":"operation/operation/#auth-filters-span","text":"Auth filters are special, because they might call an authorization endpoint, which should be also visible in the trace. This span can have the name \u201ctokeninfo\u201d, \u201ctokenintrospection\u201d or \u201cwebhook\u201d depending on the filter used by the matched route. Tags: - http.url: https://auth.example.org The auth filters have trace log values start and end for DNS, TCP connect, TLS handshake and connection pool:","title":"Auth filters span"},{"location":"operation/operation/#dataclient","text":"Dataclients poll some kind of data source for routes. To change the timeout for calls that polls a dataclient, which could be the Kubernetes API, use the following option: -source-poll-timeout int polling timeout of the routing data sources, in milliseconds (default 3000)","title":"Dataclient"},{"location":"operation/operation/#routing-table-information","text":"Skipper allows you to get some runtime insights. You can get the current routing table from skipper with in the eskip file format : curl localhost:9911/routes * -> \"http://localhost:12345/\" You also can get the number of routes X-Count and the UNIX timestamp of the last route table update X-Timestamp , using a HEAD request: curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1517777628 Date: Sun, 04 Feb 2018 20:54:31 GMT The number of routes given is limited (1024 routes by default). In order to control this limits, there are two parameters: limit and offset . The limit defines the number of routes to get and offset where to start the list. Thanks to this, it\u2019s possible to get the results paginated or getting all of them at the same time. curl localhost:9911/routes?offset=200&limit=100","title":"Routing table information"},{"location":"operation/operation/#memory-consumption","text":"While Skipper is generally not memory bound, some features may require some attention and planning regarding the memory consumption. Potentially high memory consumers: Metrics Filters Slow Backends and chatty clients Make sure you monitor backend latency, request and error rates. Additionally use Go metrics for the number of goroutines and threads, GC pause times should be less than 1ms in general, route lookup time, request and response filter times and heap memory.","title":"Memory consumption"},{"location":"operation/operation/#metrics","text":"Memory consumption of metrics are dependent on enabled command line flags. Make sure to monitor Go metrics. If you use -metrics-flavour=codahale,prometheus you enable both storage backends. If you use the Prometheus histogram buckets -histogram-metric-buckets . If you enable route based -route-backend-metrics -route-response-metrics -serve-route-metrics , error codes -route-response-metrics and host -serve-host-metrics based metrics it can count up. Please check the support listener endpoint (default 9911) to understand the usage: % curl localhost:9911/metrics","title":"Metrics"},{"location":"operation/operation/#filters","text":"Ratelimit filter clusterClientRatelimit implementation using the swim based protocol, consumes roughly 15MB per filter for 100.000 individual clients and 10 maximum hits. Make sure you monitor Go metrics. Ratelimit filter clusterClientRatelimit implementation using the Redis ring based solution, adds 2 additional roundtrips to redis per hit. Make sure you monitor redis closely, because skipper will fallback to allow traffic if redis can not be reached.","title":"Filters"},{"location":"operation/operation/#slow-backends","text":"Skipper has to keep track of all active connections and http Requests. Slow Backends can pile up in number of connections, that will consume each a little memory per request. If you have high traffic per instance and a backend times out it can start to increase your memory consumption. Make sure you monitor backend latency, request and error rates.","title":"Slow Backends"},{"location":"operation/operation/#default-filters","text":"Default filters will be applied to all routes created or updated.","title":"Default Filters"},{"location":"operation/operation/#global-default-filters","text":"Global default filters can be specified via two different command line flags -default-filters-prepend and -default-filters-append . Filters passed to these command line flags will be applied to all routes. The difference prepend and append is where in the filter chain these default filters are applied. For example a user specified the route: r: * -> setPath(\"/foo\") If you run skipper with -default-filters-prepend=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") -> setPath(\"/foo\") . If you run skipper with -default-filters-append=enableAccessLog(4,5) -> lifo(100,100,\"10s\") , the actual route will look like this: r: * -> setPath(\"/foo\") -> enableAccessLog(4,5) -> lifo(100,100,\"10s\") .","title":"Global Default Filters"},{"location":"operation/operation/#kubernetes-default-filters","text":"Kubernetes dataclient supports default filters. You can enable this feature by specifying default-filters-dir . The defined directory must contain per-service filter configurations, with file name following the pattern ${service}.${namespace} . The content of the files is the actual filter configurations. These filters are then prepended to the filters already defined in Ingresses. The default filters are supposed to be used only if the filters of the same kind are not configured on the Ingress resource. Otherwise, it can and will lead to potentially contradicting filter configurations and race conditions, i.e. you should specify a specific filter either on the Ingress resource or as a default filter.","title":"Kubernetes Default Filters"},{"location":"operation/operation/#scheduler","text":"HTTP request schedulers change the queuing behavior of in-flight requests. A queue has two generic properties: a limit of requests and a concurrency level. The limit of request can be unlimited (unbounded queue), or limited (bounded queue). The concurrency level is either limited or unlimited. The default scheduler is an unbounded first in first out (FIFO) queue, that is provided by Go\u2019s standard library. Skipper provides 2 last in first out (LIFO) filters to change the scheduling behavior. On failure conditions, Skipper will return HTTP status code: 503 if the queue is full, which is expected on the route with a failing backend 502 if queue access times out, because the queue access was not fast enough 500 on unknown errors, please create an issue","title":"Scheduler"},{"location":"operation/operation/#the-problem","text":"Why should you use boundaries to limit concurrency level and limit the queue? The short answer is resiliency. If you have one route, that is timing out, the request queue of skipper will pile up and consume much more memory, than before. This can lead to out of memory kill, which will affect all other routes. In this comment you can see the memory usage increased in Go\u2019s standard library bufio package. Why LIFO queue instead of FIFO queue? In normal cases the queue should not contain many requests. Skipper is able to process many requests concurrently without letting the queue piling up. In overrun situations you might want to process at least some fraction of requests instead of timing out all requests. LIFO would not time out all requests within the queue, if the backend is capable of responding some requests fast enough.","title":"The problem"},{"location":"operation/operation/#a-solution","text":"Skipper has two filters lifo() and lifoGroup() , that can limit the number of requests for a route. A documented load test shows the behavior with an enabled lifo(100,100,\"10s\") filter for all routes, that was added by default. You can do this, if you pass the following flag to skipper: -default-filters-prepend=lifo(100,100,\"10s\") . Both LIFO filters will, use a last in first out queue to handle most requests fast. If skipper is in an overrun mode, it will serve some requests fast and some will timeout. The idea is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . Skipper\u2019s scheduler implementation makes sure, that one route will not interfere with other routes, if these routes are not in the same scheduler group. LifoGroup has a user chosen scheduler group and lifo() will get a per route unique scheduler group.","title":"A solution"},{"location":"operation/operation/#uri-standards-interpretation","text":"Considering the following request path: /foo%2Fbar, Skipper can handle it in two different ways. The current default way is that when the request is parsed purely relying on the Go stdlib url package, this path becomes /foo/bar. According to RFC 2616 and RFC 3986, this may be considered wrong, and this path should be parsed as /foo%2Fbar. This is possible to achieve centrally, when Skipper is started with the -rfc-patch-path flag. It is also possible to allow the default behavior and only force the alternative interpretation on a per-route basis with the rfcPath() filter. See rfcPath() . If the second interpretation gets considered the right way, and the other one a bug, then the default value for this flag may become to be on.","title":"URI standards interpretation"},{"location":"operation/operation/#debugging-requests","text":"Skipper provides filters , that can change HTTP requests. You might want to inspect how the request was changed, during the route processing and check the request that would be made to the backend. Luckily with -debug-listener=:9922 , Skipper can provide you this information. For example you have the following route: kube_default__foo__foo_teapot_example_org_____foo : Host (/^ foo [.] teapot [.] example [.] org$ /) && PathSubtree(\"/ \") -> setRequestHeader(\" X - Foo \", \" hello - world \") -> <roundRobin, \" http :// 10.2 . 0.225 : 9090 \", \" http :// 10.2 . 1.244 : 9090 \" >; If you sent now a request to the debug listener, that will be matched by the route, Skipper will respond with information that show you the matched route, the incoming request, the transformed request and all predicates and filters involved in the route processing: % curl -s http://127.0.0.1:9922/ -H\"Host: foo.teapot.example.org\" | jq . { \" route_id \" : \" kube_default__foo__foo_teapot_example_org_____foo \" , \" route \" : \" Host ( / ^ foo [.] teapot [.] example [.] org $ / ) && PathSubtree ( \\ \" /\\ \" ) -> setRequestHeader ( \\ \" X - Foo \\ \" , \\ \" hello - world \\ \" ) -> < roundRobin , \\ \" http : // 10.2 . 0.225 : 9090 \\ \" , \\ \" http : // 10.2 . 1.244 : 9090 \\ \" > \" , \" incoming \" : { \" method \" : \" GET \" , \" uri \" : \" / \" , \" proto \" : \" HTTP / 1.1 \" , \" header \" : { \" Accept \" : [ \" */* \" ], \" User - Agent \" : [ \" curl / 7.49 . 0 \" ] }, \" host \" : \" foo . teapot . example . org \" , \" remote_address \" : \" 127.0 . 0.1 : 32992 \" }, \" outgoing \" : { \" method \" : \" GET \" , \" uri \" : \"\" , \" proto \" : \" HTTP / 1.1 \" , \" header \" : { \" Accept \" : [ \" */* \" ], \" User - Agent \" : [ \" curl / 7.49 . 0 \" ], \" X - Foo \" : [ \" hello - world \" ] }, \" host \" : \" foo . teapot . example . org \" }, \" response_mod \" : { \" header \" : { \" Server \" : [ \" Skipper \" ] } }, \" filters \" : [ { \" name \" : \" setRequestHeader \" , \" args \" : [ \" X - Foo \" , \" hello - world \" ] } ], \" predicates \" : [ { \" name \" : \" PathSubtree \" , \" args \" : [ \" / \" ] } ] }","title":"Debugging Requests"},{"location":"reference/architecture/","text":"Architecture \u00b6 Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example static routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target url can be set dynamically by a filter (e.g. setDynamicBackendUrl ). Opentracing API is supported via skipper-plugins . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can be exported in Prometheus format. Route processing \u00b6 Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. Routing mechanism \u00b6 The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response. Route matching \u00b6 Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the highest weight is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one.","title":"Architecture"},{"location":"reference/architecture/#architecture","text":"Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example static routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target url can be set dynamically by a filter (e.g. setDynamicBackendUrl ). Opentracing API is supported via skipper-plugins . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can be exported in Prometheus format.","title":"Architecture"},{"location":"reference/architecture/#route-processing","text":"Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request.","title":"Route processing"},{"location":"reference/architecture/#routing-mechanism","text":"The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response.","title":"Routing mechanism"},{"location":"reference/architecture/#route-matching","text":"Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the highest weight is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one.","title":"Route matching"},{"location":"reference/backends/","text":"A backend is the last part of a route and will define the backend to call for a given request that match the route. Generic route example: routeID : Predicate1 && Predicate2 -> filter1 -> filter2 -> < backend >; Network backend \u00b6 A network backend is an arbitrary HTTP or HTTPS URL, that will be called by the proxy. Route example with a network backend \"https://www.zalando.de/\" : r0 : Method ( \"GET\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> \"https://www.zalando.de/\" ; Proxy example with request in access log ./ bin / skipper -inline-routes 'r0: Method(\"GET\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] TLS settings not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings , reset , route : r0 : Method ( \"GET\" ) - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied :: 1 - - [ 05 / Feb / 2019 : 14 : 31 : 05 + 0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 457 localhost : 9090 - - Client example with request and response headers: $ curl -v localhost:9090 >/dev/null * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 13 :31:38 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Set-Cookie: ... ; Path = / ; Domain = zalando.de ; Expires = Sun, 04 Aug 2019 13 :31:38 GMT ; Max-Age = 15552000 ; HttpOnly ; Secure < Vary: Accept-Encoding < Transfer-Encoding: chunked < { [ 3205 bytes data ] Shunt backend \u00b6 A shunt backend, <shunt> , will not call a backend, but reply directly from the proxy itself. This can be used to shortcut, for example have a default that replies with 404 or use skipper as a backend serving static content in demos. Route Example proxying to \"https://www.zalando.de/\" in case Host header is set to \"zalando\" and rest will be served HTTP status code 404 with the body \"no matching route\" : r0 : Host ( \"zalando\" ) -> \"https://www.zalando.de/\" ; rest : * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> < shunt >; Proxy configured as defined above with access log showing 404: $ ./bin/skipper -inline-routes 'r0: Host(\"zalando\") -> \"https://www.zalando.de/\"; rest: * -> status(404) -> inlineContent(\"no matching route\") -> \"http://localhost:9999/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: Host ( /zalando/ ) -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings, reset, route: rest: * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> \"http://localhost:9999/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:14:39:26 +0100 ] \"GET / HTTP/1.1\" 404 17 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090 * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Length: 17 < Content-Type: text/plain ; charset = utf-8 < Server: Skipper < Date: Tue, 05 Feb 2019 13 :37:27 GMT < * Connection #0 to host localhost left intact no matching route Loopback backend \u00b6 The loopback backend, <loopback> , will lookup again the routing table to a better matching route after processing the current route. Like this you can add some headers or change the request path for some specific matching requests. Example: Route r0 is a route with loopback backend that will be matched for requests with paths that start with /api . The route will modify the http request removing /api in the path of the incoming request. In the second step of the routing the modified request will be matched by route r1 . Route r1 is a default route with a network backend to call \"https://www.zalando.de/\" r0 : PathSubtree ( \"/api\" ) -> modPath ( \"^/api\" , \"\" ) -> < loopback >; r1 : * -> \"https://www.zalando.de/\" ; Proxy configured as defined above with access logs showing 404 for the first call and 200 for the second: $ ./bin/skipper -inline-routes 'r0: PathSubtree(\"/api\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> modPath(/^\\/api/, \"\") -> <loopback>; r1: * -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: PathSubtree ( \"/api\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> modPath ( \"^/api\" , \"\" ) -> <loopback> [ APP ] INFO [ 0000 ] route settings, reset, route: r1: * -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP ::1 - - [ 05 /Feb/2019:14:54:14 +0100 ] \"GET /api/foo HTTP/1.1\" 404 98348 \"-\" \"curl/7.49.0\" 562 localhost:9090 - - ::1 - - [ 05 /Feb/2019:14:54:28 +0100 ] \"GET /api HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 120 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/api/foo >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api/foo HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Language: de-DE < Content-Type: text/html ; charset = UTF-8 < Date: Tue, 05 Feb 2019 14 :00:33 GMT < Transfer-Encoding: chunked < { [ 2669 bytes data ] * Connection #0 to host localhost left intact $ curl -sv localhost:9090/api >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :00:44 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Transfer-Encoding: chunked < { [ 3491 bytes data ] If the request processing reaches the maximum number of loopbacks (by default max=9), the routing will result in an error. Dynamic backend \u00b6 The dynamic backend, <dynamic> , will get the backend to call by data provided by filters. This allows skipper as library users to do proxy calls to a certain target from their own implementation dynamically looked up by their filters. Example shows how to set a target by a provided filter, which would be similar to a network backend: r0 : * - > setDynamicBackendUrl ( \"https://www.zalando.de\" ) - > < dynamic >; Proxy configured as defined above with access logs showing 200 for the call: $ ./bin/skipper -inline-routes 'r0: * -> setDynamicBackendUrl(\"https://www.zalando.de\") -> <dynamic>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> setDynamicBackendUrl ( \"https://www.zalando.de\" ) -> <dynamic> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:09:34 +0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 132 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/ >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :09:34 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Transfer-Encoding: chunked < { [ 3491 bytes data ] * Connection #0 to host localhost left intact When no filters modifying the target are set (e.g. r0: * -> <dynamic>; ), the target host defaults to either the Host header or the host name given in the URL, and the target scheme defaults to either https when TLS is configured or http when TLS is not configured. Load Balancer backend \u00b6 The loadbalancer backend, <$algorithm, \"backend1\", \"backend2\"> , will balance the load across all given backends using the algorithm set in $algorithm . If $algorithm is not specified it will use the default algorithm set by Skipper at start. Current implemented algorithms: roundRobin : backend is chosen by the round robin algorithm, starting with a random selected backend to spread across all backends from the beginning random : backend is chosen at random consistentHash : backend is chosen by a consistent hashing algorithm with the client X-Forwarded-For header with remote IP as the fallback as input to the hash function TODO : https://github.com/zalando/skipper/issues/557 Route example with 2 backends and the roundRobin algorithm: r0 : * - > < roundRobin , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the random algorithm: r0 : * - > < random , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the consistentHash algorithm: r0 : * - > < consistentHash , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Proxy with roundRobin loadbalancer and two backends: $ ./bin/skipper -inline-routes 'r0: * -> <roundRobin, \"http://127.0.0.1:9998\", \"http://127.0.0.1:9997\">;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> <roundRobin, \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" > [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 3 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Backend1 returns \u201cA\u201d in the body: $ ./bin/skipper -address = \":9998\" -inline-routes 'r0: * -> inlineContent(\"A\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9998 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"A\" ) -> <shunt> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - Backend2 returns \u201cB\u201d in the body: $ ./bin/skipper -address = \":9997\" -inline-routes 'r0: * -> inlineContent(\"B\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9997 [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"B\" ) -> <shunt> [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - Client: $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B Backend Protocols \u00b6 Current implemented protocols: http : (default) http protocol fastcgi : ( experimental ) directly connect Skipper with a FastCGI backend like PHP FPM. Route example that uses FastCGI ( experimental ): php : * - > setFastCgiFilename ( \"index.php\" ) - > \"fastcgi://127.0.0.1:9000\" ; php_lb : * - > setFastCgiFilename ( \"index.php\" ) - > < roundRobin , \"fastcgi://127.0.0.1:9000\" , \"fastcgi://127.0.0.1:9001\" >;","title":"Backends"},{"location":"reference/backends/#network-backend","text":"A network backend is an arbitrary HTTP or HTTPS URL, that will be called by the proxy. Route example with a network backend \"https://www.zalando.de/\" : r0 : Method ( \"GET\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> \"https://www.zalando.de/\" ; Proxy example with request in access log ./ bin / skipper -inline-routes 'r0: Method(\"GET\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] TLS settings not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings , reset , route : r0 : Method ( \"GET\" ) - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied :: 1 - - [ 05 / Feb / 2019 : 14 : 31 : 05 + 0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 457 localhost : 9090 - - Client example with request and response headers: $ curl -v localhost:9090 >/dev/null * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 13 :31:38 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Set-Cookie: ... ; Path = / ; Domain = zalando.de ; Expires = Sun, 04 Aug 2019 13 :31:38 GMT ; Max-Age = 15552000 ; HttpOnly ; Secure < Vary: Accept-Encoding < Transfer-Encoding: chunked < { [ 3205 bytes data ]","title":"Network backend"},{"location":"reference/backends/#shunt-backend","text":"A shunt backend, <shunt> , will not call a backend, but reply directly from the proxy itself. This can be used to shortcut, for example have a default that replies with 404 or use skipper as a backend serving static content in demos. Route Example proxying to \"https://www.zalando.de/\" in case Host header is set to \"zalando\" and rest will be served HTTP status code 404 with the body \"no matching route\" : r0 : Host ( \"zalando\" ) -> \"https://www.zalando.de/\" ; rest : * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> < shunt >; Proxy configured as defined above with access log showing 404: $ ./bin/skipper -inline-routes 'r0: Host(\"zalando\") -> \"https://www.zalando.de/\"; rest: * -> status(404) -> inlineContent(\"no matching route\") -> \"http://localhost:9999/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: Host ( /zalando/ ) -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings, reset, route: rest: * -> status ( 404 ) -> inlineContent ( \"no matching route\" ) -> \"http://localhost:9999/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:14:39:26 +0100 ] \"GET / HTTP/1.1\" 404 17 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090 * Rebuilt URL to: localhost:9090/ * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Length: 17 < Content-Type: text/plain ; charset = utf-8 < Server: Skipper < Date: Tue, 05 Feb 2019 13 :37:27 GMT < * Connection #0 to host localhost left intact no matching route","title":"Shunt backend"},{"location":"reference/backends/#loopback-backend","text":"The loopback backend, <loopback> , will lookup again the routing table to a better matching route after processing the current route. Like this you can add some headers or change the request path for some specific matching requests. Example: Route r0 is a route with loopback backend that will be matched for requests with paths that start with /api . The route will modify the http request removing /api in the path of the incoming request. In the second step of the routing the modified request will be matched by route r1 . Route r1 is a default route with a network backend to call \"https://www.zalando.de/\" r0 : PathSubtree ( \"/api\" ) -> modPath ( \"^/api\" , \"\" ) -> < loopback >; r1 : * -> \"https://www.zalando.de/\" ; Proxy configured as defined above with access logs showing 404 for the first call and 200 for the second: $ ./bin/skipper -inline-routes 'r0: PathSubtree(\"/api\") -> setRequestHeader(\"X-Passed-Skipper\", \"true\") -> modPath(/^\\/api/, \"\") -> <loopback>; r1: * -> \"https://www.zalando.de/\";' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: PathSubtree ( \"/api\" ) -> setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) -> modPath ( \"^/api\" , \"\" ) -> <loopback> [ APP ] INFO [ 0000 ] route settings, reset, route: r1: * -> \"https://www.zalando.de/\" [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP ::1 - - [ 05 /Feb/2019:14:54:14 +0100 ] \"GET /api/foo HTTP/1.1\" 404 98348 \"-\" \"curl/7.49.0\" 562 localhost:9090 - - ::1 - - [ 05 /Feb/2019:14:54:28 +0100 ] \"GET /api HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 120 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/api/foo >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api/foo HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 404 Not Found < Content-Language: de-DE < Content-Type: text/html ; charset = UTF-8 < Date: Tue, 05 Feb 2019 14 :00:33 GMT < Transfer-Encoding: chunked < { [ 2669 bytes data ] * Connection #0 to host localhost left intact $ curl -sv localhost:9090/api >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET /api HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :00:44 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Transfer-Encoding: chunked < { [ 3491 bytes data ] If the request processing reaches the maximum number of loopbacks (by default max=9), the routing will result in an error.","title":"Loopback backend"},{"location":"reference/backends/#dynamic-backend","text":"The dynamic backend, <dynamic> , will get the backend to call by data provided by filters. This allows skipper as library users to do proxy calls to a certain target from their own implementation dynamically looked up by their filters. Example shows how to set a target by a provided filter, which would be similar to a network backend: r0 : * - > setDynamicBackendUrl ( \"https://www.zalando.de\" ) - > < dynamic >; Proxy configured as defined above with access logs showing 200 for the call: $ ./bin/skipper -inline-routes 'r0: * -> setDynamicBackendUrl(\"https://www.zalando.de\") -> <dynamic>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> setDynamicBackendUrl ( \"https://www.zalando.de\" ) -> <dynamic> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:09:34 +0100 ] \"GET / HTTP/1.1\" 200 164408 \"-\" \"curl/7.49.0\" 132 localhost:9090 - - Client example with request and response headers: $ curl -sv localhost:9090/ >/dev/null * Trying ::1... * Connected to localhost ( ::1 ) port 9090 ( #0) > GET / HTTP/1.1 > Host: localhost:9090 > User-Agent: curl/7.49.0 > Accept: */* > < HTTP/1.1 200 OK < Cache-Control: no-cache, no-store, must-revalidate < Content-Type: text/html < Date: Tue, 05 Feb 2019 14 :09:34 GMT < Link: <https://mosaic01.ztat.net/base-assets/require-2.1.22.min.js> ; rel = \"preload\" ; as = \"script\" ; nopush ; crossorigin < Pragma: no-cache < Server: Skipper < Transfer-Encoding: chunked < { [ 3491 bytes data ] * Connection #0 to host localhost left intact When no filters modifying the target are set (e.g. r0: * -> <dynamic>; ), the target host defaults to either the Host header or the host name given in the URL, and the target scheme defaults to either https when TLS is configured or http when TLS is not configured.","title":"Dynamic backend"},{"location":"reference/backends/#load-balancer-backend","text":"The loadbalancer backend, <$algorithm, \"backend1\", \"backend2\"> , will balance the load across all given backends using the algorithm set in $algorithm . If $algorithm is not specified it will use the default algorithm set by Skipper at start. Current implemented algorithms: roundRobin : backend is chosen by the round robin algorithm, starting with a random selected backend to spread across all backends from the beginning random : backend is chosen at random consistentHash : backend is chosen by a consistent hashing algorithm with the client X-Forwarded-For header with remote IP as the fallback as input to the hash function TODO : https://github.com/zalando/skipper/issues/557 Route example with 2 backends and the roundRobin algorithm: r0 : * - > < roundRobin , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the random algorithm: r0 : * - > < random , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Route example with 2 backends and the consistentHash algorithm: r0 : * - > < consistentHash , \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" >; Proxy with roundRobin loadbalancer and two backends: $ ./bin/skipper -inline-routes 'r0: * -> <roundRobin, \"http://127.0.0.1:9998\", \"http://127.0.0.1:9997\">;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> <roundRobin, \"http://127.0.0.1:9998\" , \"http://127.0.0.1:9997\" > [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] proxy listener on :9090 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings applied ::1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 3 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - ::1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 localhost:9090 - - Backend1 returns \u201cA\u201d in the body: $ ./bin/skipper -address = \":9998\" -inline-routes 'r0: * -> inlineContent(\"A\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9998 [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"A\" ) -> <shunt> [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:06 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:08 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9998 - - Backend2 returns \u201cB\u201d in the body: $ ./bin/skipper -address = \":9997\" -inline-routes 'r0: * -> inlineContent(\"B\") -> <shunt>;' [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on :9911 [ APP ] INFO [ 0000 ] proxy listener on :9997 [ APP ] INFO [ 0000 ] route settings, reset, route: r0: * -> inlineContent ( \"B\" ) -> <shunt> [ APP ] INFO [ 0000 ] TLS settings not found, defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied 127 .0.0.1 - - [ 05 /Feb/2019:15:39:07 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - 127 .0.0.1 - - [ 05 /Feb/2019:15:39:09 +0100 ] \"GET / HTTP/1.1\" 200 1 \"-\" \"curl/7.49.0\" 0 127 .0.0.1:9997 - - Client: $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B $ curl -s http://localhost:9090/ A $ curl -s http://localhost:9090/ B","title":"Load Balancer backend"},{"location":"reference/backends/#backend-protocols","text":"Current implemented protocols: http : (default) http protocol fastcgi : ( experimental ) directly connect Skipper with a FastCGI backend like PHP FPM. Route example that uses FastCGI ( experimental ): php : * - > setFastCgiFilename ( \"index.php\" ) - > \"fastcgi://127.0.0.1:9000\" ; php_lb : * - > setFastCgiFilename ( \"index.php\" ) - > < roundRobin , \"fastcgi://127.0.0.1:9000\" , \"fastcgi://127.0.0.1:9001\" >;","title":"Backend Protocols"},{"location":"reference/development/","text":"How to develop a Filter \u00b6 A filter is part of a route and can change arbitary http data in the http.Request and http.Response path of a proxy. The filter example shows a non trivial diff of a filter implementation, that implements an authnz webhook. It shows global settings passed via flags, user documentation, developer documentation for library users, the filter implementation and some test cases. Tests should test the actual filter implementation in a proxy setup. How to pass options to your filter \u00b6 Set a default and a Usage string as const. Add a var to hold the value and put the flag to the category, that makes the most sense. If a filter, predicate or dataclient need Options passed from flags, then you should register the filter in skipper.go , the main library entrypoint. In case you do not need options from flags, use MakeRegistry() in ./filters/builtin/builtin.go to register your filter. diff --git a/cmd/skipper/main.go b/cmd/skipper/main.go index 28f18f9..4530b85 100644 --- a/cmd/skipper/main.go +++ b/cmd/skipper/main.go @@ -59,9 +59,10 @@ const ( defaultOAuthTokeninfoTimeout = 2 * time.Second defaultOAuthTokenintrospectionTimeout = 2 * time.Second + defaultWebhookTimeout = 2 * time.Second // generic: addressUsage = \"network address that skipper should listen on\" @@ -141,6 +142,8 @@ const ( oauth2TokeninfoURLUsage = \"sets the default tokeninfo URL to query information about an incoming OAuth2 token in oauth2Tokeninfo filters\" oauth2TokeninfoTimeoutUsage = \"sets the default tokeninfo request timeout duration to 2000ms\" oauth2TokenintrospectionTimeoutUsage = \"sets the default tokenintrospection request timeout duration to 2000ms\" + webhookTimeoutUsage = \"sets the webhook request timeout duration, defaults to 2s\" + // connections, timeouts: idleConnsPerHostUsage = \"maximum idle connections per backend host\" closeIdleConnsPeriodUsage = \"period of closing all idle connections in seconds or as a duration string. Not closing when less than 0\" @@ -243,13 +246,14 @@ var ( oauth2TokeninfoURL string oauth2TokeninfoTimeout time.Duration oauth2TokenintrospectionTimeout time.Duration + webhookTimeout time.Duration // connections, timeouts: idleConnsPerHost int @@ -351,13 +355,14 @@ func init() { flag.DurationVar(&oauth2TokeninfoTimeout, \"oauth2-tokeninfo-timeout\", defaultOAuthTokeninfoTimeout, oauth2TokeninfoTimeoutUsage) flag.DurationVar(&oauth2TokenintrospectionTimeout, \"oauth2-tokenintrospect-timeout\", defaultOAuthTokenintrospectionTimeout, oauth2TokenintrospectionTimeoutUsage) + flag.DurationVar(&webhookTimeout, \"webhook-timeout\", defaultWebhookTimeout, webhookTimeoutUsage) // connections, timeouts: flag.IntVar(&idleConnsPerHost, \"idle-conns-num\", proxy.DefaultIdleConnsPerHost, idleConnsPerHostUsage) @@ -536,13 +541,14 @@ func main() { OAuthTokeninfoURL: oauth2TokeninfoURL, OAuthTokeninfoTimeout: oauth2TokeninfoTimeout, OAuthTokenintrospectionTimeout: oauth2TokenintrospectionTimeout, + WebhookTimeout: webhookTimeout, // connections, timeouts: IdleConnectionsPerHost: idleConnsPerHost, diff --git a/skipper.go b/skipper.go index 10d5769..da46fe0 100644 --- a/skipper.go +++ b/skipper.go @@ -443,6 +443,9 @@ type Options struct { // OAuthTokenintrospectionTimeout sets timeout duration while calling oauth tokenintrospection service OAuthTokenintrospectionTimeout time.Duration + // WebhookTimeout sets timeout duration while calling a custom webhook auth service + WebhookTimeout time.Duration + // MaxAuditBody sets the maximum read size of the body read by the audit log filter MaxAuditBody int } @@ -677,7 +680,8 @@ func Run(o Options) error { auth.NewOAuthTokenintrospectionAnyClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAllClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAnyKV(o.OAuthTokenintrospectionTimeout), - auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout)) + auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout), + auth.NewWebhook(o.WebhookTimeout)) // create a filter registry with the available filter specs registered, // and register the custom filters User documentation \u00b6 Documentation for users should be done in docs/ . diff --git a/docs/filters.md b/docs/filters.md index d3bb872..a877062 100644 --- a/docs/filters.md +++ b/docs/filters.md @@ -382,6 +382,24 @@ basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") ``` +## webhook + +The `webhook` filter makes it possible to have your own authentication and +authorization endpoint as a filter. + +Headers from the incoming request will be copied into the request that +is being done to the webhook endpoint. Responses from the webhook with +status code less than 300 will be authorized, rest unauthorized. + +Examples: + +``` +webhook(\"https://custom-webhook.example.org/auth\") +``` + +The webhook timeout has a default of 2 seconds and can be globally +changed, if skipper is started with `-webhook-timeout=2s` flag. + ## oauthTokeninfoAnyScope If skipper is started with `-oauth2-tokeninfo-url` flag, you can use Add godoc \u00b6 Godoc is meant for developers using skipper as library, use doc.go of the package to document generic functionality, usage and library usage. diff --git a/filters/auth/doc.go b/filters/auth/doc.go index 696d3fd..1d6e3a8 100644 --- a/filters/auth/doc.go +++ b/filters/auth/doc.go @@ -318,5 +318,12 @@ filter after the auth filter. a: Path(\"/only-allowed-audit-log\") -> oauthTokeninfoAnyScope(\"bar-w\") -> auditLog() -> \"https://internal.example.org/\"; b: Path(\"/all-access-requests-audit-log\") -> auditLog() -> oauthTokeninfoAnyScope(\"foo-r\") -> \"https://internal.example.org/\"; +Webhook - webhook() filter + +The filter webhook allows you to have a custom authentication and +authorization endpoint for a route. + + a: Path(\"/only-allowed-by-webhook\") -> webhook(\"https://custom-webhook.example.org/auth\") -> \"https://protected-backend.example.org/\"; + */ package auth Filter implementation \u00b6 A filter can modify the incoming http.Request before calling the backend and the outgoing http.Response from the backend to the client. A filter consists of at least two types a spec and a filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. diff --git a/filters/auth/webhook.go b/filters/auth/webhook.go new file mode 100644 index 0000000..f0632a6 --- /dev/null +++ b/filters/auth/webhook.go @@ -0,0 +1,84 @@ +package auth + +import ( + \"net/http\" + \"time\" + + \"github.com/zalando/skipper/filters\" +) + +const ( + WebhookName = \"webhook\" +) + +type ( + webhookSpec struct { + Timeout time.Duration + } + webhookFilter struct { + authClient *authClient + } +) + +// NewWebhook creates a new auth filter specification +// to validate authorization for requests. +func NewWebhook(d time.Duration) filters.Spec { + return &webhookSpec{Timeout: d} +} + +func (*webhookSpec) Name() string { + return WebhookName +} + +// CreateFilter creates an auth filter. The first argument is an URL +// string. +// +// s.CreateFilter(\"https://my-auth-service.example.org/auth\") +// +func (ws *webhookSpec) CreateFilter(args []interface{}) (filters.Filter, error) { + if l := len(args); l == 0 || l > 2 { + return nil, filters.ErrInvalidFilterParameters + } + + s, ok := args[0].(string) + if !ok { + return nil, filters.ErrInvalidFilterParameters + } + + ac, err := newAuthClient(s, ws.Timeout) + if err != nil { + return nil, filters.ErrInvalidFilterParameters + } + + return &webhookFilter{authClient: ac}, nil +} + +func copyHeader(to, from http.Header) { + for k, v := range from { + to[http.CanonicalHeaderKey(k)] = v + } +} + +func (f *webhookFilter) Request(ctx filters.FilterContext) { + statusCode, err := f.authClient.getWebhook(ctx.Request()) + if err != nil { + unauthorized(ctx, WebhookName, authServiceAccess, f.authClient.url.Hostname()) + } + // redirects, auth errors, webhook errors + if statusCode >= 300 { + unauthorized(ctx, WebhookName, invalidAccess, f.authClient.url.Hostname()) + } + authorized(ctx, WebhookName) +} + +func (*webhookFilter) Response(filters.FilterContext) {} + +// Close cleans-up the quit channel used for this filter +func (f *webhookFilter) Close() { + f.authClient.mu.Lock() + if f.authClient.quit != nil { + close(f.authClient.quit) + f.authClient.quit = nil + } + f.authClient.mu.Unlock() +} Writing tests \u00b6 Skipper uses normal table driven Go tests without frameworks. This example filter test creates a backend, an auth service to be called by our filter, and a filter configured by our table driven test. In general we use real backends with dynamic port allocations. We call these and inspect the http.Response to check, if we get expected results for invalid and valid data. Skipper has some helpers to create the test proxy in the proxytest package. Backends can be created with httptest.NewServer as in the example below. diff --git a/filters/auth/webhook_test.go b/filters/auth/webhook_test.go new file mode 100644 index 0000000..d43c4ea --- /dev/null +++ b/filters/auth/webhook_test.go @@ -0,0 +1,128 @@ +package auth + +import ( + \"fmt\" + \"io\" + \"net/http\" + \"net/http/httptest\" + \"net/url\" + \"testing\" + \"time\" + + \"github.com/zalando/skipper/eskip\" + \"github.com/zalando/skipper/filters\" + \"github.com/zalando/skipper/proxy/proxytest\" +) + +func TestWebhook(t *testing.T) { + for _, ti := range []struct { + msg string + token string + expected int + authorized bool + timeout bool + }{{ + msg: \"invalid-token-should-be-unauthorized\", + token: \"invalid-token\", + expected: http.StatusUnauthorized, + authorized: false, + }, { + msg: \"valid-token-should-be-authorized\", + token: testToken, + expected: http.StatusOK, + authorized: true, + }, { + msg: \"webhook-timeout-should-be-unauthorized\", + token: testToken, + expected: http.StatusUnauthorized, + authorized: false, + timeout: true, + }} { + t.Run(ti.msg, func(t *testing.T) { + backend := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) { + w.WriteHeader(http.StatusOK) + io.WriteString(w, \"Hello from backend\") + return + })) + defer backend.Close() + + authServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { + if ti.timeout { + time.Sleep(time.Second + time.Millisecond) + } + + if r.Method != \"GET\" { + w.WriteHeader(489) + io.WriteString(w, \"FAIL - not a GET request\") + return + } + + tok := r.Header.Get(authHeaderName) + tok = tok[len(authHeaderPrefix):len(tok)] + switch tok { + case testToken: + w.WriteHeader(200) + fmt.Fprintln(w, \"OK - Got token: \"+tok) + return + } + w.WriteHeader(402) //http.StatusUnauthorized) + fmt.Fprintln(w, \"Unauthorized - Got token: \") //+tok) + })) + defer authServer.Close() + + spec := NewWebhook(time.Second) + + args := []interface{}{ + \"http://\" + authServer.Listener.Addr().String(), + } + f, err := spec.CreateFilter(args) + if err != nil { + t.Errorf(\"error in creating filter for %s: %v\", ti.msg, err) + return + } + + f2 := f.(*webhookFilter) + defer f2.Close() + + fr := make(filters.Registry) + fr.Register(spec) + r := &eskip.Route{Filters: []*eskip.Filter{{Name: spec.Name(), Args: args}}, Backend: backend.URL} + + proxy := proxytest.New(fr, r) + defer proxy.Close() + + reqURL, err := url.Parse(proxy.URL) + if err != nil { + t.Errorf(\"Failed to parse url %s: %v\", proxy.URL, err) + return + } + + req, err := http.NewRequest(\"GET\", reqURL.String(), nil) + if err != nil { + t.Errorf(\"failed to create request %v\", err) + return + } + req.Header.Set(authHeaderName, authHeaderPrefix+ti.token) + + rsp, err := http.DefaultClient.Do(req) + if err != nil { + t.Errorf(\"failed to get response: %v\", err) + return + } + defer rsp.Body.Close() + + buf := make([]byte, 128) + var n int + if n, err = rsp.Body.Read(buf); err != nil && err != io.EOF { + t.Errorf(\"Could not read response body: %v\", err) + return + } + + t.Logf(\"%d %d\", rsp.StatusCode, ti.expected) + if rsp.StatusCode != ti.expected { + t.Errorf(\"unexpected status code: %v != %v %d %s\", rsp.StatusCode, ti.expected, n, buf) + return + } + }) + } +} Using a debugger \u00b6 Skipper supports plugins and to offer this support it uses the plugin library. Due to a bug in the Go compiler as reported here a debugger cannot be used. This issue will be fixed in Go 1.12 but until then the only workaround is to remove references to the plugin library. The following patch can be used for debugging. diff --git a/plugins.go b/plugins.go index 837b6cf..aa69f09 100644 --- a/plugins.go +++ b/plugins.go @@ -1,5 +1,6 @@ package skipper +/* import ( \"fmt\" \"io/ioutil\" @@ -13,8 +14,13 @@ import ( \"github.com/zalando/skipper/filters\" \"github.com/zalando/skipper/routing\" ) +*/ func (o *Options) findAndLoadPlugins() error { + return nil +} + +/* found := make(map[string]string) done := make(map[string][]string) @@ -366,3 +372,4 @@ func readPluginConfig(plugin string) (conf []string, err error) { } return conf, nil } +*/ The patch can be applied with the git apply $PATCH_FILE command. Please do not commit the modified plugins.go along with your changes.","title":"Development"},{"location":"reference/development/#how-to-develop-a-filter","text":"A filter is part of a route and can change arbitary http data in the http.Request and http.Response path of a proxy. The filter example shows a non trivial diff of a filter implementation, that implements an authnz webhook. It shows global settings passed via flags, user documentation, developer documentation for library users, the filter implementation and some test cases. Tests should test the actual filter implementation in a proxy setup.","title":"How to develop a Filter"},{"location":"reference/development/#how-to-pass-options-to-your-filter","text":"Set a default and a Usage string as const. Add a var to hold the value and put the flag to the category, that makes the most sense. If a filter, predicate or dataclient need Options passed from flags, then you should register the filter in skipper.go , the main library entrypoint. In case you do not need options from flags, use MakeRegistry() in ./filters/builtin/builtin.go to register your filter. diff --git a/cmd/skipper/main.go b/cmd/skipper/main.go index 28f18f9..4530b85 100644 --- a/cmd/skipper/main.go +++ b/cmd/skipper/main.go @@ -59,9 +59,10 @@ const ( defaultOAuthTokeninfoTimeout = 2 * time.Second defaultOAuthTokenintrospectionTimeout = 2 * time.Second + defaultWebhookTimeout = 2 * time.Second // generic: addressUsage = \"network address that skipper should listen on\" @@ -141,6 +142,8 @@ const ( oauth2TokeninfoURLUsage = \"sets the default tokeninfo URL to query information about an incoming OAuth2 token in oauth2Tokeninfo filters\" oauth2TokeninfoTimeoutUsage = \"sets the default tokeninfo request timeout duration to 2000ms\" oauth2TokenintrospectionTimeoutUsage = \"sets the default tokenintrospection request timeout duration to 2000ms\" + webhookTimeoutUsage = \"sets the webhook request timeout duration, defaults to 2s\" + // connections, timeouts: idleConnsPerHostUsage = \"maximum idle connections per backend host\" closeIdleConnsPeriodUsage = \"period of closing all idle connections in seconds or as a duration string. Not closing when less than 0\" @@ -243,13 +246,14 @@ var ( oauth2TokeninfoURL string oauth2TokeninfoTimeout time.Duration oauth2TokenintrospectionTimeout time.Duration + webhookTimeout time.Duration // connections, timeouts: idleConnsPerHost int @@ -351,13 +355,14 @@ func init() { flag.DurationVar(&oauth2TokeninfoTimeout, \"oauth2-tokeninfo-timeout\", defaultOAuthTokeninfoTimeout, oauth2TokeninfoTimeoutUsage) flag.DurationVar(&oauth2TokenintrospectionTimeout, \"oauth2-tokenintrospect-timeout\", defaultOAuthTokenintrospectionTimeout, oauth2TokenintrospectionTimeoutUsage) + flag.DurationVar(&webhookTimeout, \"webhook-timeout\", defaultWebhookTimeout, webhookTimeoutUsage) // connections, timeouts: flag.IntVar(&idleConnsPerHost, \"idle-conns-num\", proxy.DefaultIdleConnsPerHost, idleConnsPerHostUsage) @@ -536,13 +541,14 @@ func main() { OAuthTokeninfoURL: oauth2TokeninfoURL, OAuthTokeninfoTimeout: oauth2TokeninfoTimeout, OAuthTokenintrospectionTimeout: oauth2TokenintrospectionTimeout, + WebhookTimeout: webhookTimeout, // connections, timeouts: IdleConnectionsPerHost: idleConnsPerHost, diff --git a/skipper.go b/skipper.go index 10d5769..da46fe0 100644 --- a/skipper.go +++ b/skipper.go @@ -443,6 +443,9 @@ type Options struct { // OAuthTokenintrospectionTimeout sets timeout duration while calling oauth tokenintrospection service OAuthTokenintrospectionTimeout time.Duration + // WebhookTimeout sets timeout duration while calling a custom webhook auth service + WebhookTimeout time.Duration + // MaxAuditBody sets the maximum read size of the body read by the audit log filter MaxAuditBody int } @@ -677,7 +680,8 @@ func Run(o Options) error { auth.NewOAuthTokenintrospectionAnyClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAllClaims(o.OAuthTokenintrospectionTimeout), auth.NewOAuthTokenintrospectionAnyKV(o.OAuthTokenintrospectionTimeout), - auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout)) + auth.NewOAuthTokenintrospectionAllKV(o.OAuthTokenintrospectionTimeout), + auth.NewWebhook(o.WebhookTimeout)) // create a filter registry with the available filter specs registered, // and register the custom filters","title":"How to pass options to your filter"},{"location":"reference/development/#user-documentation","text":"Documentation for users should be done in docs/ . diff --git a/docs/filters.md b/docs/filters.md index d3bb872..a877062 100644 --- a/docs/filters.md +++ b/docs/filters.md @@ -382,6 +382,24 @@ basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") ``` +## webhook + +The `webhook` filter makes it possible to have your own authentication and +authorization endpoint as a filter. + +Headers from the incoming request will be copied into the request that +is being done to the webhook endpoint. Responses from the webhook with +status code less than 300 will be authorized, rest unauthorized. + +Examples: + +``` +webhook(\"https://custom-webhook.example.org/auth\") +``` + +The webhook timeout has a default of 2 seconds and can be globally +changed, if skipper is started with `-webhook-timeout=2s` flag. + ## oauthTokeninfoAnyScope If skipper is started with `-oauth2-tokeninfo-url` flag, you can use","title":"User documentation"},{"location":"reference/development/#add-godoc","text":"Godoc is meant for developers using skipper as library, use doc.go of the package to document generic functionality, usage and library usage. diff --git a/filters/auth/doc.go b/filters/auth/doc.go index 696d3fd..1d6e3a8 100644 --- a/filters/auth/doc.go +++ b/filters/auth/doc.go @@ -318,5 +318,12 @@ filter after the auth filter. a: Path(\"/only-allowed-audit-log\") -> oauthTokeninfoAnyScope(\"bar-w\") -> auditLog() -> \"https://internal.example.org/\"; b: Path(\"/all-access-requests-audit-log\") -> auditLog() -> oauthTokeninfoAnyScope(\"foo-r\") -> \"https://internal.example.org/\"; +Webhook - webhook() filter + +The filter webhook allows you to have a custom authentication and +authorization endpoint for a route. + + a: Path(\"/only-allowed-by-webhook\") -> webhook(\"https://custom-webhook.example.org/auth\") -> \"https://protected-backend.example.org/\"; + */ package auth","title":"Add godoc"},{"location":"reference/development/#filter-implementation","text":"A filter can modify the incoming http.Request before calling the backend and the outgoing http.Response from the backend to the client. A filter consists of at least two types a spec and a filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. diff --git a/filters/auth/webhook.go b/filters/auth/webhook.go new file mode 100644 index 0000000..f0632a6 --- /dev/null +++ b/filters/auth/webhook.go @@ -0,0 +1,84 @@ +package auth + +import ( + \"net/http\" + \"time\" + + \"github.com/zalando/skipper/filters\" +) + +const ( + WebhookName = \"webhook\" +) + +type ( + webhookSpec struct { + Timeout time.Duration + } + webhookFilter struct { + authClient *authClient + } +) + +// NewWebhook creates a new auth filter specification +// to validate authorization for requests. +func NewWebhook(d time.Duration) filters.Spec { + return &webhookSpec{Timeout: d} +} + +func (*webhookSpec) Name() string { + return WebhookName +} + +// CreateFilter creates an auth filter. The first argument is an URL +// string. +// +// s.CreateFilter(\"https://my-auth-service.example.org/auth\") +// +func (ws *webhookSpec) CreateFilter(args []interface{}) (filters.Filter, error) { + if l := len(args); l == 0 || l > 2 { + return nil, filters.ErrInvalidFilterParameters + } + + s, ok := args[0].(string) + if !ok { + return nil, filters.ErrInvalidFilterParameters + } + + ac, err := newAuthClient(s, ws.Timeout) + if err != nil { + return nil, filters.ErrInvalidFilterParameters + } + + return &webhookFilter{authClient: ac}, nil +} + +func copyHeader(to, from http.Header) { + for k, v := range from { + to[http.CanonicalHeaderKey(k)] = v + } +} + +func (f *webhookFilter) Request(ctx filters.FilterContext) { + statusCode, err := f.authClient.getWebhook(ctx.Request()) + if err != nil { + unauthorized(ctx, WebhookName, authServiceAccess, f.authClient.url.Hostname()) + } + // redirects, auth errors, webhook errors + if statusCode >= 300 { + unauthorized(ctx, WebhookName, invalidAccess, f.authClient.url.Hostname()) + } + authorized(ctx, WebhookName) +} + +func (*webhookFilter) Response(filters.FilterContext) {} + +// Close cleans-up the quit channel used for this filter +func (f *webhookFilter) Close() { + f.authClient.mu.Lock() + if f.authClient.quit != nil { + close(f.authClient.quit) + f.authClient.quit = nil + } + f.authClient.mu.Unlock() +}","title":"Filter implementation"},{"location":"reference/development/#writing-tests","text":"Skipper uses normal table driven Go tests without frameworks. This example filter test creates a backend, an auth service to be called by our filter, and a filter configured by our table driven test. In general we use real backends with dynamic port allocations. We call these and inspect the http.Response to check, if we get expected results for invalid and valid data. Skipper has some helpers to create the test proxy in the proxytest package. Backends can be created with httptest.NewServer as in the example below. diff --git a/filters/auth/webhook_test.go b/filters/auth/webhook_test.go new file mode 100644 index 0000000..d43c4ea --- /dev/null +++ b/filters/auth/webhook_test.go @@ -0,0 +1,128 @@ +package auth + +import ( + \"fmt\" + \"io\" + \"net/http\" + \"net/http/httptest\" + \"net/url\" + \"testing\" + \"time\" + + \"github.com/zalando/skipper/eskip\" + \"github.com/zalando/skipper/filters\" + \"github.com/zalando/skipper/proxy/proxytest\" +) + +func TestWebhook(t *testing.T) { + for _, ti := range []struct { + msg string + token string + expected int + authorized bool + timeout bool + }{{ + msg: \"invalid-token-should-be-unauthorized\", + token: \"invalid-token\", + expected: http.StatusUnauthorized, + authorized: false, + }, { + msg: \"valid-token-should-be-authorized\", + token: testToken, + expected: http.StatusOK, + authorized: true, + }, { + msg: \"webhook-timeout-should-be-unauthorized\", + token: testToken, + expected: http.StatusUnauthorized, + authorized: false, + timeout: true, + }} { + t.Run(ti.msg, func(t *testing.T) { + backend := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, _ *http.Request) { + w.WriteHeader(http.StatusOK) + io.WriteString(w, \"Hello from backend\") + return + })) + defer backend.Close() + + authServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { + if ti.timeout { + time.Sleep(time.Second + time.Millisecond) + } + + if r.Method != \"GET\" { + w.WriteHeader(489) + io.WriteString(w, \"FAIL - not a GET request\") + return + } + + tok := r.Header.Get(authHeaderName) + tok = tok[len(authHeaderPrefix):len(tok)] + switch tok { + case testToken: + w.WriteHeader(200) + fmt.Fprintln(w, \"OK - Got token: \"+tok) + return + } + w.WriteHeader(402) //http.StatusUnauthorized) + fmt.Fprintln(w, \"Unauthorized - Got token: \") //+tok) + })) + defer authServer.Close() + + spec := NewWebhook(time.Second) + + args := []interface{}{ + \"http://\" + authServer.Listener.Addr().String(), + } + f, err := spec.CreateFilter(args) + if err != nil { + t.Errorf(\"error in creating filter for %s: %v\", ti.msg, err) + return + } + + f2 := f.(*webhookFilter) + defer f2.Close() + + fr := make(filters.Registry) + fr.Register(spec) + r := &eskip.Route{Filters: []*eskip.Filter{{Name: spec.Name(), Args: args}}, Backend: backend.URL} + + proxy := proxytest.New(fr, r) + defer proxy.Close() + + reqURL, err := url.Parse(proxy.URL) + if err != nil { + t.Errorf(\"Failed to parse url %s: %v\", proxy.URL, err) + return + } + + req, err := http.NewRequest(\"GET\", reqURL.String(), nil) + if err != nil { + t.Errorf(\"failed to create request %v\", err) + return + } + req.Header.Set(authHeaderName, authHeaderPrefix+ti.token) + + rsp, err := http.DefaultClient.Do(req) + if err != nil { + t.Errorf(\"failed to get response: %v\", err) + return + } + defer rsp.Body.Close() + + buf := make([]byte, 128) + var n int + if n, err = rsp.Body.Read(buf); err != nil && err != io.EOF { + t.Errorf(\"Could not read response body: %v\", err) + return + } + + t.Logf(\"%d %d\", rsp.StatusCode, ti.expected) + if rsp.StatusCode != ti.expected { + t.Errorf(\"unexpected status code: %v != %v %d %s\", rsp.StatusCode, ti.expected, n, buf) + return + } + }) + } +}","title":"Writing tests"},{"location":"reference/development/#using-a-debugger","text":"Skipper supports plugins and to offer this support it uses the plugin library. Due to a bug in the Go compiler as reported here a debugger cannot be used. This issue will be fixed in Go 1.12 but until then the only workaround is to remove references to the plugin library. The following patch can be used for debugging. diff --git a/plugins.go b/plugins.go index 837b6cf..aa69f09 100644 --- a/plugins.go +++ b/plugins.go @@ -1,5 +1,6 @@ package skipper +/* import ( \"fmt\" \"io/ioutil\" @@ -13,8 +14,13 @@ import ( \"github.com/zalando/skipper/filters\" \"github.com/zalando/skipper/routing\" ) +*/ func (o *Options) findAndLoadPlugins() error { + return nil +} + +/* found := make(map[string]string) done := make(map[string][]string) @@ -366,3 +372,4 @@ func readPluginConfig(plugin string) (conf []string, err error) { } return conf, nil } +*/ The patch can be applied with the git apply $PATCH_FILE command. Please do not commit the modified plugins.go along with your changes.","title":"Using a debugger"},{"location":"reference/egress/","text":"Egress Proxy \u00b6 Disclaimer : Egress features are probably not feature complete. Please create Github Issues to show your ideas about this topic. The picture below shows an authentication use case with Bearer token injection, to show the egress traffic flow: Skipper has some features, which are egress specific. Some features, for example dropRequestHeader or ratelimit , might also be used, but are not listed here: circuit breaker filters consecutiveBreaker rateBreaker disableBreaker bearerinjector filter, that injects tokens for an app The secrets module that does automated secrets rotation read from files used by bearerinjector filter dynamic secrets lookup used by bearerinjector filter encryption and decryption used by OpenID Connect filters Secrets Module \u00b6 Disclaimer : the specified features might be changed to make use cases work in the future. Automated Secrets rotation \u00b6 Secrets are read from files. Files can be rewritten by third party tools to integrate whatever provider you want. In Kubernetes you can write Secrets with an API and read them using a rotated, mounted files from skipper for example. To specify files or directories to find secrets, you can use -credentials-paths command line flag. Filenames are used to define the name of the secret, which will be used as a lookup key. The files need to be created before skipper is started, and as of today skipper doesn\u2019t find new files automatically. This might change in the future. To change the default update interval, which defaults to 10m , you can use the -credentials-update-interval command line flag. Example bearer injection \u00b6 Create file /tmp/secrets/mytoken , that contains mytoken : mkdir /tmp/secrets; echo mytoken >/tmp/secrets/mytoken`. start fake service nc -l 8080 start skipper proxy skipper -inline-routes='Host(\"host1\") -> bearerinjector(\"/tmp/secrets/mytoken\") -> \"http://127.0.0.1:8080/\"' -credentials-paths=/tmp/secrets -credentials-update-interval=10s .. [APP]INFO[0004] Updated secret file: /tmp/secrets/mytoken .. Client calls skipper proxy % curl -H\"Host: host1\" localhost:9090/foo ^ C fake service shows GET /foo HTTP / 1.1 Host : 127.0.0.1:8080 User-Agent : curl/7.49.0 Accept : */* Authorization : Bearer mytoken Accept-Encoding : gzip Change the secret: echo changedtoken >/tmp/secrets/mytoken . Wait until skipper logs: [APP]INFO[0010] update secret file: /tmp/secrets/mytoken Restart fake service (CTRL-c to stop) nc -l 8080 Client calls skipper proxy retry: % curl -H\"Host: host1\" localhost:9090/foo ^ C fake service shows GET /foo HTTP / 1.1 Host : 127.0.0.1:8080 User-Agent : curl/7.49.0 Accept : */* Authorization : Bearer changedtoken Accept-Encoding : gzip This example showed bearer injection with secrets rotation. Reach multiple services \u00b6 Often your service wants to reach multiple services, so you need to differentiate these routes, somehow. For example your service needs to access a.example.com and b.example.com . One example is to use .localhost domain, so a.localhost and b.localhost in your application and in skipper routes you would have: a : Host ( \"a.localhost\" ) -> bearerinjector ( \"/tmp/secrets/mytoken\" ) -> \"https://a.example.com\" b : Host ( \"b.localhost\" ) -> bearerinjector ( \"/tmp/secrets/mytoken\" ) -> \"https://b.example.com\" You can also use host aliases, in Linux /etc/hosts , or in Kubernetes hostAliases : Pod spec: spec : hostAliases : - ip : 127.0 . 0.1 hostnames : - a . local - b . local Future - TODOs \u00b6 We want to experiment in how to best use skipper as egress proxy. One idea is to implement forward proxy via HTTP CONNECT and being able to use the routing to inject the right Authorization headers with the bearerinjector filter , for example. If you have ideas please add your thoughts in one of the issues , that match your idea or create a new one.","title":"Egress"},{"location":"reference/egress/#egress-proxy","text":"Disclaimer : Egress features are probably not feature complete. Please create Github Issues to show your ideas about this topic. The picture below shows an authentication use case with Bearer token injection, to show the egress traffic flow: Skipper has some features, which are egress specific. Some features, for example dropRequestHeader or ratelimit , might also be used, but are not listed here: circuit breaker filters consecutiveBreaker rateBreaker disableBreaker bearerinjector filter, that injects tokens for an app The secrets module that does automated secrets rotation read from files used by bearerinjector filter dynamic secrets lookup used by bearerinjector filter encryption and decryption used by OpenID Connect filters","title":"Egress Proxy"},{"location":"reference/egress/#secrets-module","text":"Disclaimer : the specified features might be changed to make use cases work in the future.","title":"Secrets Module"},{"location":"reference/egress/#automated-secrets-rotation","text":"Secrets are read from files. Files can be rewritten by third party tools to integrate whatever provider you want. In Kubernetes you can write Secrets with an API and read them using a rotated, mounted files from skipper for example. To specify files or directories to find secrets, you can use -credentials-paths command line flag. Filenames are used to define the name of the secret, which will be used as a lookup key. The files need to be created before skipper is started, and as of today skipper doesn\u2019t find new files automatically. This might change in the future. To change the default update interval, which defaults to 10m , you can use the -credentials-update-interval command line flag.","title":"Automated Secrets rotation"},{"location":"reference/egress/#example-bearer-injection","text":"Create file /tmp/secrets/mytoken , that contains mytoken : mkdir /tmp/secrets; echo mytoken >/tmp/secrets/mytoken`. start fake service nc -l 8080 start skipper proxy skipper -inline-routes='Host(\"host1\") -> bearerinjector(\"/tmp/secrets/mytoken\") -> \"http://127.0.0.1:8080/\"' -credentials-paths=/tmp/secrets -credentials-update-interval=10s .. [APP]INFO[0004] Updated secret file: /tmp/secrets/mytoken .. Client calls skipper proxy % curl -H\"Host: host1\" localhost:9090/foo ^ C fake service shows GET /foo HTTP / 1.1 Host : 127.0.0.1:8080 User-Agent : curl/7.49.0 Accept : */* Authorization : Bearer mytoken Accept-Encoding : gzip Change the secret: echo changedtoken >/tmp/secrets/mytoken . Wait until skipper logs: [APP]INFO[0010] update secret file: /tmp/secrets/mytoken Restart fake service (CTRL-c to stop) nc -l 8080 Client calls skipper proxy retry: % curl -H\"Host: host1\" localhost:9090/foo ^ C fake service shows GET /foo HTTP / 1.1 Host : 127.0.0.1:8080 User-Agent : curl/7.49.0 Accept : */* Authorization : Bearer changedtoken Accept-Encoding : gzip This example showed bearer injection with secrets rotation.","title":"Example bearer injection"},{"location":"reference/egress/#reach-multiple-services","text":"Often your service wants to reach multiple services, so you need to differentiate these routes, somehow. For example your service needs to access a.example.com and b.example.com . One example is to use .localhost domain, so a.localhost and b.localhost in your application and in skipper routes you would have: a : Host ( \"a.localhost\" ) -> bearerinjector ( \"/tmp/secrets/mytoken\" ) -> \"https://a.example.com\" b : Host ( \"b.localhost\" ) -> bearerinjector ( \"/tmp/secrets/mytoken\" ) -> \"https://b.example.com\" You can also use host aliases, in Linux /etc/hosts , or in Kubernetes hostAliases : Pod spec: spec : hostAliases : - ip : 127.0 . 0.1 hostnames : - a . local - b . local","title":"Reach multiple services"},{"location":"reference/egress/#future-todos","text":"We want to experiment in how to best use skipper as egress proxy. One idea is to implement forward proxy via HTTP CONNECT and being able to use the routing to inject the right Authorization headers with the bearerinjector filter , for example. If you have ideas please add your thoughts in one of the issues , that match your idea or create a new one.","title":"Future - TODOs"},{"location":"reference/filters/","text":"Skipper Filters \u00b6 The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a regular expression, surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Filters are a generic tool and can change HTTP header and body in the request and response path. Filter can be chained using the arrow operator -> . Example route with a match all, 2 filters and a backend: all : * - > filter1 - > filter2 - > \"http://127.0.0.1:1234/\" ; backendIsProxy \u00b6 Notifies the proxy that the backend handling this request is also a proxy. The proxy type is based in the URL scheme which can be either http , https or socks5 . Keep in mind that Skipper currently cannot handle CONNECT requests by tunneling the traffic to the target destination, however, the CONNECT requests can be forwarded to a different proxy using this filter. Example: foo1 : * - > backendIsProxy () - > \"http://proxy.example.com\" ; foo2 : * - > backendIsProxy () - > < roundRobin , \"http://proxy1.example.com\" , \"http://proxy2.example.com\" >; foo3 : * - > setDynamicBackendUrl ( \"http://proxy.example.com\" ) - > backendIsProxy () - > < dynamic >; modRequestHeader \u00b6 Replace all matched regex expressions in the given header. Parameters: header name (string) the expression to match (regex) the replacement (string) Example: enforce_www : * - > modRequestHeader ( \"Host\" , \"^zalando\\.(\\w+)$\" , \"www.zalando.$1\" ) - > redirectTo ( 301 ); setRequestHeader \u00b6 Set headers for requests. Parameters: header name (string) header value (string) Example: foo : * - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://backend.example.org\" ; appendRequestHeader \u00b6 Same as setRequestHeader , but appends the provided value to the already existing ones. dropRequestHeader \u00b6 Removes a header from the request Parameters: header name (string) Example: foo : * - > dropRequestHeader ( \"User-Agent\" ) - > \"https://backend.example.org\" ; setResponseHeader \u00b6 Same as setRequestHeader , only for responses appendResponseHeader \u00b6 Same as appendRequestHeader , only for responses dropResponseHeader \u00b6 Same as dropRequestHeader but for responses from the backend setContextRequestHeader \u00b6 Set headers for requests using values from the filter context (state bag). If the provided key (second parameter) cannot be found in the state bag, then it doesn\u2019t set the header. Parameters: header name (string) key in the state bag (string) The the route in the following example checkes whether the request is authorized with the oauthTokeninfoAllScope() filter. This filter stores the authenticated user with \u201cauth-user\u201d key in the context, and the setContextRequestHeader() filter in the next step stores it in the header of the outgoing request with the X-Uid name: foo : * - > oauthTokeninfoAllScope ( \"address_service.all\" ) - > setContextRequestHeader ( \"X-Uid\" , \"auth-user\" ) - > \"https://backend.example.org\" ; appendContextRequestHeader \u00b6 Same as setContextRequestHeader , but appends the provided value to the already existing ones. setContextResponseHeader \u00b6 Same as setContextRequestHeader , except for responses. appendContextResponseHeader \u00b6 Same as appendContextRequestHeader , except for responses. modPath \u00b6 Replace all matched regex expressions in the path. Parameters: the expression to match (regex) the replacement (string) Example: rm_api : Path ( \"/api\" ) -> modPath ( \"/api\" , \"/\" ) -> \"https://backend.example.org\" ; append_bar : Path ( \"/foo\" ) -> modPath ( \"/foo\" , \"/foo/bar\" ) -> \"https://backend.example.org\" ; new_base : PathSubtree ( \"/base\" ) -> modPath ( \"/base\" , \"/new/base) -> \" https :// backend . example . org \"; rm_api_regex: Path(\" /api\") -> modPath(\"^/api/(.*)/v2$\", \"/$1\") -> \"https:// backend . example . org \" ; setPath \u00b6 Replace the path of the original request to the replacement. Parameters: the replacement (string) redirectTo \u00b6 Creates an HTTP redirect response. Parameters: redirect status code (int) location (string) - optional Example: redirect1 : PathRegexp (/^\\/ foo \\/ bar /) -> redirectTo(302, \"/foo/ newBar \" ) -> < shunt >; redirect2 : * -> redirectTo ( 301 ) -> < shunt >; Route redirect1 will do a redirect with status code 302 to https with new path /foo/newBar for requests, that match the path /foo/bar . Route redirect2 will do a https redirect with status code 301 for all incoming requests that match no other route see also redirect-handling redirectToLower \u00b6 Same as redirectTo , but replaces all strings to lower case. static \u00b6 Serves static content from the filesystem. Parameters: Request path to strip (string) Target base path in the filesystem (string) Example: This serves files from /srv/www/dehydrated when requested via /.well-known/acme-challenge/ , e.g. the request GET /.well-known/acme-challenge/foo will serve the file /srv/www/dehydrated/foo . acme : Host (/./) && Method ( \"GET\" ) && Path ( \"/.well-known/acme-challenge/*\" ) -> static ( \"/.well-known/acme-challenge/\" , \"/srv/www/dehydrated\" ) -> < shunt >; Notes: redirects to the directory when a file index.html exists and it is requested, i.e. GET /foo/index.html redirects to /foo/ which serves then the /foo/index.html serves the content of the index.html when a directory is requested does a simple directory listing of files / directories when no index.html is present stripQuery \u00b6 Removes the query parameter from the request URL, and if the first filter parameter is \"true\" , preserves the query parameter in the form of x-query-param-<queryParamName>: <queryParamValue> headers, so that ?foo=bar becomes x-query-param-foo: bar Example: * - > stripQuery () - > \"http://backend.example.org\" ; * - > stripQuery ( \"true\" ) - > \"http://backend.example.org\" ; preserveHost \u00b6 Sets the incoming Host: header on the outgoing backend connection. It can be used to override the proxyPreserveHost behavior for individual routes. Parameters: \u201ctrue\u201d or \u201cfalse\u201d \u201ctrue\u201d - use the Host header from the incoming request \u201cfalse\u201d - use the host from the backend address Example: route1 : * - > preserveHost ( \"true\" ) - > \"http://backend.example.org\" ; status \u00b6 Sets the response status code to the given value, with no regards to the backend response. Parameters: status code (int) Example: route1 : Host (/^ all401 \\. example \\. org$ /) -> status ( 401 ) -> < shunt >; compress \u00b6 The filter, when executed on the response path, checks if the response entity can be compressed. To decide, it checks the Content-Encoding, the Cache-Control and the Content-Type headers. It doesn\u2019t compress the content if the Content-Encoding is set to other than identity, or the Cache-Control applies the no-transform pragma, or the Content-Type is set to an unsupported value. The default supported content types are: text/plain , text/html , application/json , application/javascript , application/x-javascript , text/javascript , text/css , image/svg+xml , application/octet-stream . The default set of MIME types can be reset or extended by passing in the desired types as filter arguments. When extending the defaults, the first argument needs to be \"...\" . E.g. to compress tiff in addition to the defaults: * -> compress(\"...\", \"image/tiff\") -> \"https://www.example.org\" To reset the supported types, e.g. to compress only HTML, the \u201c\u2026\u201d argument needs to be omitted: * -> compress(\"text/html\") -> \"https://www.example.org\" It is possible to control the compression level, by setting it as the first filter argument, in front of the MIME types. The default compression level is best-speed. The possible values are integers between 0 and 9 (inclusive), where 0 means no-compression, 1 means best-speed and 9 means best-compression. Example: * -> compress(9, \"image/tiff\") -> \"https://www.example.org\" The filter also checks the incoming request, if it accepts the supported encodings, explicitly stated in the Accept-Encoding header. The filter currently supports gzip and deflate . It does not assume that the client accepts any encoding if the Accept-Encoding header is not set. It ignores * in the Accept-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, sets the Content-Encoding to the selected encoding and sets the Vary: Accept-Encoding header, if missing. The compression happens in a streaming way, using only a small internal buffer. decompress \u00b6 The filter, when executed on the response path, checks if the response entity is compressed by a supported algorithm. To decide, it checks the Content-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, deletes the Content-Encoding and the Vary headers, if set. The decompression happens in a streaming way, using only a small internal buffer. Example: * -> decompress() -> \"https://www.example.org\" setQuery \u00b6 Set the query string ?k=v in the request to the backend to a given value. Parameters: key (string) value (string) Example: setQuery(\"k\", \"v\") dropQuery \u00b6 Delete the query string ?k=v in the request to the backend for a given key. Parameters: key (string) Example: dropQuery(\"k\") inlineContent \u00b6 Returns arbitrary content in the HTTP body. Parameters: content (string) content type (string) - optional Example: * -> inlineContent(\" <h1> Hello </h1> \") -> <shunt> * -> inlineContent(\"[1,2,3]\", \"application/json\") -> <shunt> Content type will be automatically detected when not provided. Note inlineContent filter is special and must be the last in the filter chain. inlineContentIfStatus \u00b6 Returns arbitrary content in the HTTP body, if the response has the specified status code. Parameters: status code (int) content (string) content type (string) - optional Example: * -> inlineContentIfStatus(404, \" <p class= \\\"problem\\\" > We don't have what you're looking for. </p> \") -> \"https://www.example.org\" * -> inlineContentIfStatus(401, \"{\\\"error\\\": \\\"unauthorized\\\"}\", \"application/json\") -> \"https://www.example.org\" The content type will be automatically detected when not provided. flowId \u00b6 Sets an X-Flow-Id header, if it\u2019s not already in the request. This allows you to have a trace in your logs, that traces from the incoming request on the edge to all backend services. Flow IDs must be in a certain format to be reusable in skipper. Valid formats depend on the generator used in skipper. Default generator creates IDs of length 16 matching the following regex: ^[0-9a-zA-Z+-]+$ Parameters: no parameter: resets always the X-Flow-Id header to a new value \"reuse\" : only create X-Flow-Id header if not already set or if the value is invalid in the request Example: * - > flowId () - > \"https://some-backend.example.org\" ; * - > flowId ( \"reuse\" ) - > \"https://some-backend.example.org\" ; xforward \u00b6 Standard proxy headers. Appends the client remote IP to the X-Forwarded-For and sets the X-Forwarded-Host header. xforwardFirst \u00b6 Same as xforward , but instead of appending the last remote IP, it prepends it to comply with the approach of certain LB implementations. randomContent \u00b6 Generate response with random text of specified length. Parameters: length of data (int) Example: * -> randomContent(42) -> <shunt>; latency \u00b6 Enable adding artificial latency Parameters: latency in milliseconds (int) Example: * - > latency ( 120 ) - > \"https://www.example.org\" ; bandwidth \u00b6 Enable bandwidth throttling. Parameters: bandwidth in kb/s (int) Example: * - > bandwidth ( 30 ) - > \"https://www.example.org\" ; chunks \u00b6 Enables adding chunking responses with custom chunk size with artificial delays in between response chunks. To disable delays, set the second parameter to \u201c0\u201d. Parameters: byte length (int) time duration (time.Duration) Example: * - > chunks ( 1024 , \"120ms\" ) - > \"https://www.example.org\" ; * - > chunks ( 1024 , \"0\" ) - > \"https://www.example.org\" ; backendLatency \u00b6 Same as latency filter , but on the request path and not on the response path. backendBandwidth \u00b6 Same as bandwidth filter , but on the request path and not on the response path. backendChunks \u00b6 Same as chunks filter , but on the request path and not on the response path. absorb \u00b6 The absorb filter reads and discards the payload of the incoming requests. It logs with INFO level and a unique ID per request: the event of receiving the request partial and final events for consuming request payload and total consumed byte count the finishing event of the request any read errors other than EOF logHeader \u00b6 The logHeader filter prints the request line and the header, but not the body, to stderr. Note that this filter should be used only in diagnostics setup and with care, since the request headers may contain sensitive data, and they also can explode the amount of logs. Authorization headers will be truncated in request and response header logs. You can log request or response headers, which defaults for backwards compatibility to request headers. Parameters: no arg, similar to: \u201crequest\u201d \u201crequest\u201d or \u201cresponse\u201d (string varargs) Example: * - > logHeader () - > \"https://www.example.org\" ; * - > logHeader ( \"request\" ) - > \"https://www.example.org\" ; * - > logHeader ( \"response\" ) - > \"https://www.example.org\" ; * - > logHeader ( \"request\" , \"response\" ) - > \"https://www.example.org\" ; tee \u00b6 Provides a unix-like tee feature for routing. Using this filter, the request will be sent to a \u201cshadow\u201d backend in addition to the main backend of the route. Example: * - > tee ( \"https://audit-logging.example.org\" ) - > \"https://foo.example.org\" ; This will send an identical request for foo.example.org to audit-logging.example.org. Another use case could be using it for benchmarking a new backend with some real traffic. This we call \u201cshadow traffic\u201d. The above route will forward the request to https://foo.example.org as it normally would do, but in addition to that, it will send an identical request to https://audit-logging.example.org . The request sent to https://audit-logging.example.org will receive the same method and headers, and a copy of the body stream. The tee response is ignored for this shadow backend. It is possible to change the path of the tee request, in a similar way to the modPath filter: Path ( \"/api/v1\" ) - > tee ( \"https://api.example.org\" , \"^/v1\" , \"/v2\" ) - > \"http://api.example.org\" ; In the above example, one can test how a new version of an API would behave on incoming requests. teenf \u00b6 The same as tee filter , but does not follow redirects from the backend. teeLoopback \u00b6 This filter provides a unix-like tee feature for routing, but unlike the tee , this filter feeds the copied request to the start of the routing, including the route lookup and executing the filters on the matched route. It is recommended to use this solution instead of the tee filter, because the same routing facilities are used for the outgoing tee requests as for the normal requests, and all the filters and backend types are supported. To ensure that the right route, or one of the right set of routes, is matched after the loopback, use the filter together with the Tee predicate, however, this is not mandatory if the request is changed via other filters, such that other predicates ensure matching the right route. To avoid infinite looping, the number of requests spawn from a single incoming request is limited similarly as in case of the loopback backend . Parameters: tee group (string): a label identifying which routes should match the loopback request, marked with the Tee predicate Example, generate shadow traffic from 10% of the production traffic: main : * - > \"https://main-backend.example.org; main-split: Traffic(.1) -> teeLoopback(\" test-A \") -> \" https :// main-backend . example . org \"; shadow: Tee(\" test-A \") && True() -> \" https :// test-backend . example . org \" ; See also: Tee predicate Shadow Traffic Tutorial sed \u00b6 The filter sed replaces all occurences of a pattern with a replacement string in the response body. Example: editorRoute : * - > sed ( \"foo\" , \"bar\" ) - > \"https://www.example.org\" ; Example with larger max buffer: editorRoute : * - > sed ( \"foo\" , \"bar\" , 64000000 ) - > \"https://www.example.org\" ; This filter expects a regexp pattern and a replacement string as arguments. During the streaming of the response body, every occurence of the pattern will be replaced with the replacement string. The editing doesn\u2019t happen right when the filter is executed, only later when the streaming normally happens, after all response filters were called. The sed() filter accepts two optional arguments, the max editor buffer size in bytes, and max buffer handling flag. The max buffer size, when set, defines how much data can be buffered at a given time by the editor. The default value is 2MiB. The max buffer handling flag can take one of two values: \u201cabort\u201d or \u201cbest-effort\u201d (default). Setting \u201cabort\u201d means that the stream will be aborted when reached the limit. Setting \u201cbest-effort\u201d, will run the replacement on the available content, in case of certain patterns, this may result in content that is different from one that would have been edited in a single piece. See more details below. The filter uses the go regular expression implementation: https://github.com/google/re2/wiki/Syntax . Due to the streaming nature, matches with zero length are ignored. Memory handling and limitations \u00b6 In order to avoid unbound buffering of unprocessed data, the sed* filters need to apply some limitations. Some patterns, e.g. .* would allow to match the complete payload, and it could result in trying to buffer it all and potentially causing running out of available memory. Similarly, in case of certain expressions, when they don\u2019t match, it\u2019s impossible to tell if they would match without reading more data from the source, and so would potentially need to buffer the entire payload. To prevent too high memory usage, the max buffer size is limited in case of each variant of the filter, by default to 2MiB, which is the same limit as the one we apply when reading the request headers by default. When the limit is reached, and the buffered content matches the pattern, then it is processed by replacing it, when it doesn\u2019t match the pattern, then it is forwarded unchanged. This way, e.g. sed(\".*\", \"\") can be used safely to consume and discard the payload. As a result of this, with large payloads, it is possible that the resulting content will be different than if we had run the replacement on the entire content at once. If we have enough preliminary knowledge about the payload, then it may be better to use the delimited variant of the filters, e.g. for line based editing. If the max buffer handling is set to \u201cabort\u201d, then the stream editing is stopped and the rest of the payload is dropped. sedDelim \u00b6 Like sed() , but it expects an additional argument, before the optional max buffer size argument, that is used to delimit chunks to be processed at once. The pattern replacement is executed only within the boundaries of the chunks defined by the delimiter, and matches across the chunk boundaries are not considered. Example: editorRoute : * - > sedDelim ( \"foo\" , \"bar\" , \"\\n\" ) - > \"https://www.example.org\" ; sedRequest \u00b6 Like sed() , but for the request content. Example: editorRoute : * - > sedRequest ( \"foo\" , \"bar\" ) - > \"https://www.example.org\" ; sedRequestDelim \u00b6 Like sedDelim() , but for the request content. Example: editorRoute : * - > sedRequestDelim ( \"foo\" , \"bar\" , \"\\n\" ) - > \"https://www.example.org\" ; basicAuth \u00b6 Enable Basic Authentication The filter accepts two parameters, the first mandatory one is the path to the htpasswd file usually used with Apache or nginx. The second one is the optional realm name that will be displayed in the browser. MD5, SHA1 and BCrypt are supported for Basic authentication password storage, see also the http-auth module page . Examples: basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\") webhook \u00b6 The webhook filter makes it possible to have your own authentication and authorization endpoint as a filter. Headers from the incoming request will be copied into the request that is being done to the webhook endpoint. It is possible to copy headers from the webhook response into the continuing request by specifying the headers to copy as an optional second argument to the filter. Responses from the webhook with status code less than 300 will be authorized, the rest will be unauthorized. Examples: webhook(\"https://custom-webhook.example.org/auth\") webhook(\"https://custom-webhook.example.org/auth\", \"X-Copy-Webhook-Header,X-Copy-Another-Header\") The webhook timeout has a default of 2 seconds and can be globally changed, if skipper is started with -webhook-timeout=2s flag. oauthTokeninfoAnyScope \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured scopes from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyScope(\"s1\", \"s2\", \"s3\") oauthTokeninfoAllScope \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured scopes from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllScope(\"s1\", \"s2\", \"s3\") oauthTokeninfoAnyKV \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured key value pairs from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k1\", \"v2\") oauthTokeninfoAllKV \u00b6 If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured key value pairs from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokenintrospectionAnyClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyClaims(\"c1\", \"c2\", \"c3\") oauthTokenintrospectionAllClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllClaims(\"c1\", \"c2\", \"c3\") oauthTokenintrospectionAnyKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k1\", \"v2\") oauthTokenintrospectionAllKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllKV(\"k1\", \"v1\", \"k2\", \"v2\") secureOauthTokenintrospectionAnyClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\") secureOauthTokenintrospectionAllClaims \u00b6 The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\") secureOauthTokenintrospectionAnyKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\") secureOauthTokenintrospectionAllKV \u00b6 The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\") forwardToken \u00b6 The filter takes the (string) header name as its first argument. The result of token info or token introspection is added to this header when the request is passed to the backend. If there are additional arguments, these values are treated as a whitelisted set of JSON keys to be included in the header payload when forwarding to the backend service. If this filter is used when there is no token introspection or token info data then it does not have any effect. Examples: forwardToken(\"X-Tokeninfo-Forward\") forwardToken(\"X-Tokeninfo-Forward\", \"access_token\") oauthOidcUserInfo \u00b6 oauthOidcUserInfo(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims The claims which should be present in the token returned by the provider. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON . oauthOidcAnyClaims \u00b6 oauthOidcAnyClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed as long as at least one of them is present. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON . oauthOidcAllClaims \u00b6 oauthOidcAllClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed only when all claims are present. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON . requestCookie \u00b6 Append a cookie to the request header. Parameters: cookie name (string) cookie value (string) Example: requestCookie(\"test-session\", \"abc\") oidcClaimsQuery \u00b6 oidcClaimsQuery(\"<path>:[<query>]\", ...) The filter is chained after oauthOidc* authentication as it parses the ID token that has been saved in the internal StateBag for this request. It validates access control of the requested path against the defined query. It accepts one or more arguments, thats is a path prefix which is granted access to when the query definition evaluates positive. It supports exact matches of keys, key-value pairs, introspecting of arrays or exact and wildcard matching of nested structures. The query definition can be one or more queries per path, space delimited. The query syntax is GJSON with a convenience modifier of @_ which unfolds to [@this].#(\"+arg+\") Given following example ID token: { \"email\" : \"someone@example.org\" , \"groups\" : [ \"CD-xyz\" , \"appX-Test-Users\" \"Purchasing-Department\" , ], \"name\" : \"Some One\" } Access to path / would be granted to everyone in example.org , however path /login only to those being member of group \"appX-Tester\" : oauthOidcAnyClaims(...) -> oidcClaimsQuery(\"/login:groups.#[==\\\"appX-Tester\\\"]\", \"/:@_:email%\\\"*@example.org\\\"\") For above ID token following query definitions would also be positive: oidcClaimsQuery(\"/:email\") oidcClaimsQuery(\"/another/path:groups.#[%\\\"CD-*\\\"]\") oidcClaimsQuery(\"/:name%\\\"*One\\\"\", \"/path:groups.#[%\\\"*-Test-Users\\\"] groups.#[==\\\"Purchasing-Department\\\"]\") As of now there is no negative/deny rule possible. The first matching path is evaluated against the defined query/queries and if positive, permitted. responseCookie \u00b6 Appends cookies to responses in the \u201cSet-Cookie\u201d header. The response cookie accepts an optional argument to control the max-age property of the cookie, of type int , in seconds. The response cookie accepts an optional fourth argument, \u201cchange-only\u201d, to control if the cookie should be set on every response, or only if the request does not contain a cookie with the provided name and value. Example: responseCookie(\"test-session\", \"abc\") responseCookie(\"test-session\", \"abc\", 31536000), responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\") jsCookie \u00b6 The JS cookie behaves exactly as the response cookie, but it does not set the HttpOnly directive, so these cookies will be accessible from JS code running in web browsers. Example: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\") consecutiveBreaker \u00b6 This breaker opens when the proxy could not connect to a backend or received a >=500 status code at least N times in a row. When open, the proxy returns 503 - Service Unavailable response during the breaker timeout. After this timeout, the breaker goes into half-open state, in which it expects that M number of requests succeed. The requests in the half-open state are accepted concurrently. If any of the requests during the half-open state fails, the breaker goes back to open state. If all succeed, it goes to closed state again. Parameters: number of consecutive failures to open (int) timeout (time string, parseable by time.Duration ) - optional half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . Can be used as egress feature. rateBreaker \u00b6 The \u201crate breaker\u201d works similar to the consecutiveBreaker , but instead of considering N consecutive failures for going open, it maintains a sliding window of the last M events, both successes and failures, and opens only when the number of failures reaches N within the window. This way the sliding window is not time based and allows the same breaker characteristics for low and high rate traffic. Parameters: number of consecutive failures to open (int) sliding window (time string, parseable by time.Duration ) half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . Can be used as egress feature. disableBreaker \u00b6 Change (or set) the breaker configurations for an individual route and disable for another, in eskip: updates : Method ( \"POST\" ) && Host ( \"foo.example.org\" ) -> consecutiveBreaker ( 9 ) -> \"https://foo.backend.net\" ; backendHealthcheck : Path ( \"/healthcheck\" ) -> disableBreaker () -> \"https://foo.backend.net\" ; See also the circuit breaker docs . Can be used as egress feature. ~~localRatelimit~~ \u00b6 DEPRECATED use clientRatelimit with the same settings instead. clientRatelimit \u00b6 Per skipper instance calculated ratelimit, that allows number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional third parameter. If the third parameter is set skipper will use the defined HTTP header to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flag -enable-ratelimits . Skipper will consume roughly 15 MB per filter for 100.000 clients. Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header, in case the provided string contains , , it will combine all these headers (string) clientRatelimit(3, \"1m\") clientRatelimit(3, \"1m\", \"Authorization\") clientRatelimit(3, \"1m\", \"X-Foo,Authorization,X-Bar\") See also the ratelimit docs . ratelimit \u00b6 Per skipper instance calculated ratelimit, that allows forwarding a number of requests to the backend group. You need to run skipper with command line flag -enable-ratelimits . Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) ratelimit(20, \"1m\") ratelimit(300, \"1h\") See also the ratelimit docs . clusterClientRatelimit \u00b6 This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional fourth parameter. If the fourth parameter is set skipper will use the HTTP header defined by this to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header, in case the provided string contains , , it will combine all these headers (string) clusterClientRatelimit(\"groupA\", 10, \"1h\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"Authorization\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"X-Forwarded-For,Authorization,User-Agent\") See also the ratelimit docs . clusterRatelimit \u00b6 This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests to a backend. You need to have run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) clusterRatelimit(\"groupB\", 20, \"1m\") clusterRatelimit(\"groupB\", 300, \"1h\") See also the ratelimit docs . lua \u00b6 See the scripts page corsOrigin \u00b6 The filter accepts an optional variadic list of acceptable origin parameters. If the input argument list is empty, the header will always be set to * which means any origin is acceptable. Otherwise the header is only set if the request contains an Origin header and its value matches one of the elements in the input list. The header is only set on the response. Parameters: url (variadic string) Examples: corsOrigin() corsOrigin(\"https://www.example.org\") corsOrigin(\"https://www.example.org\", \"http://localhost:9001\") headerToQuery \u00b6 Filter which assigns the value of a given header from the incoming Request to a given query param Parameters: The name of the header to pick from request The name of the query param key to add to request Examples: headerToQuery(\"X-Foo-Header\", \"foo-query-param\") The above filter will set foo-query-param query param respectively to the X-Foo-Header header and will override the value if the queryparam exists already queryToHeader \u00b6 Filter which assigns the value of a given query param from the incoming Request to a given Header with optional format string value. Parameters: The name of the query param key to pick from request The name of the header to add to request The format string used to create the header value, which gets the value from the query value as before Examples: queryToHeader(\"foo-query-param\", \"X-Foo-Header\") queryToHeader(\"access_token\", \"Authorization\", \"Bearer %s\") The first filter will set X-Foo-Header header respectively to the foo-query-param query param and will not override the value if the header exists already. The second filter will set Authorization header to the access_token query param with a prefix value Bearer and will not override the value if the header exists already. ~~accessLogDisabled~~ \u00b6 Deprecated: use disableAccessLog or enableAccessLog The accessLogDisabled filter overrides global Skipper AccessLogDisabled setting for a specific route, which allows to either turn-off the access log for specific route while access log, in general, is enabled or vice versa. Example: accessLogDisabled(\"false\") disableAccessLog \u00b6 Filter overrides global Skipper AccessLogDisabled setting and allows to turn-off the access log for specific route while access log, in general, is enabled. It is also possible to disable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: disableAccessLog() disableAccessLog(1, 301, 40) This disables logs of all requests with status codes 1xxs , 301 and all 40xs . enableAccessLog \u00b6 Filter overrides global Skipper AccessLogDisabled setting and allows to turn-on the access log for specific route while access log, in general, is disabled. It is also possible to enable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: enableAccessLog() enableAccessLog(1, 301, 20) This enables logs of all requests with status codes 1xxs , 301 and all 20xs . auditLog \u00b6 Filter auditLog() logs the request and N bytes of the body into the log file. N defaults to 1024 and can be overidden with -max-audit-body=<int> . N=0 omits logging the body. Example: auditLog() unverifiedAuditLog \u00b6 Filter unverifiedAuditLog() adds a Header, X-Unverified-Audit , to the request, the content of which, will also be written to the log file. By default, the value of the audit header will be equal to the value of the sub key, from the Authorization token. This can be changed by providing a string input to the filter which matches another key from the token. N.B. It is important to note that, if the content of the X-Unverified-Audit header does not match the following regex, then a default value of invalid-sub will be populated in the header instead: ^[a-zA-z0-9_/:?=&%@.#-]*$ Examples: unverifiedAuditLog() unverifiedAuditLog(\"azp\") setDynamicBackendHostFromHeader \u00b6 Filter sets the backend host for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl filters, the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendHostFromHeader ( \"X-Forwarded-Host\" ) - > < dynamic >; setDynamicBackendSchemeFromHeader \u00b6 Filter sets the backend scheme for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendSchemeFromHeader ( \"X-Forwarded-Proto\" ) - > < dynamic >; setDynamicBackendUrlFromHeader \u00b6 Filter sets the backend url for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Parameters: header name (string) Example: foo : * - > setDynamicBackendUrlFromHeader ( \"X-Custom-Url\" ) - > < dynamic >; setDynamicBackendHost \u00b6 Filter sets the backend host for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: host (string) Example: foo : * - > setDynamicBackendHost ( \"example.com\" ) - > < dynamic >; setDynamicBackendScheme \u00b6 Filter sets the backend scheme for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: scheme (string) Example: foo : * - > setDynamicBackendScheme ( \"https\" ) - > < dynamic >; setDynamicBackendUrl \u00b6 Filter sets the backend url for a route. Can be used only with <dynamic> backend. Parameters: url (string) Example: foo : * - > setDynamicBackendUrl ( \"https://example.com\" ) - > < dynamic >; apiUsageMonitoring \u00b6 The apiUsageMonitoring filter adds API related metrics to the Skipper monitoring. It is by default not activated. Activate it by providing the -enable-api-usage-monitoring flag at Skipper startup. In its deactivated state, it is still registered as a valid filter (allowing route configurations to specify it), but will perform no operation. That allows, per instance, production environments to use it and testing environments not to while keeping the same route configuration for all environments. For the client based metrics, additional flags need to be specified. Flag Description api-usage-monitoring-realm-keys Name of the property in the JWT JSON body that contains the name of the realm . api-usage-monitoring-client-keys Name of the property in the JWT JSON body that contains the name of the client . api-usage-monitoring-realms-tracking-pattern RegEx of realms to be monitored. Defaults to \u2018services\u2019. NOTE: Make sure to activate the metrics flavour proper to your environment using the metrics-flavour flag in order to get those metrics. Example: skipper -metrics-flavour prometheus -enable-api-usage-monitoring -api-usage-monitoring-realm-keys = \"realm\" -api-usage-monitoring-client-keys = \"managed-id\" api-usage-monitoring-realms-tracking-pattern = \"services,users\" The structure of the metrics is all of those elements, separated by . dots: Part Description apiUsageMonitoring.custom Every filter metrics starts with the name of the filter followed by custom . This part is constant. Application ID Identifier of the application, configured in the filter under app_id . Tag Tag of the application (e.g. staging), configured in the filter under tag . API ID Identifier of the API, configured in the filter under api_id . Method The request\u2019s method (verb), capitalized (ex: GET , POST , PUT , DELETE ). Path The request\u2019s path, in the form of the path template configured in the filter under path_templates . Realm The realm in which the client is authenticated. Client Identifier under which the client is authenticated. Metric Name Name (or key) of the metric being tracked. Available Metrics \u00b6 Endpoint Related Metrics \u00b6 Those metrics are not identifying the realm and client. They always have * in their place. Example: + Realm | apiUsageMonitoring.custom.orders-backend.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count | | | + Metric Name + Client The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Histogram latency time between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response ) Client Related Metrics \u00b6 Those metrics are not identifying endpoint (path) and HTTP verb. They always have * as their place. Example: + HTTP Verb | + Path Template + Metric Name | | | apiUsageMonitoring.custom.orders-backend.staging.orders-api.*.*.users.mmustermann.http_count | | | + Client + Realm The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Counter latency_sum sum of seconds (in decimal form) between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response ) Filter Configuration \u00b6 Endpoints can be monitored using the apiUsageMonitoring filter in the route. It accepts JSON objects (as strings) of the format mentioned below. In case any of the required parameters is missing, no-op filter is created, i.e. no metrics are captured, but the creation of the route does not fail. api-usage-monitoring-configuration : type : object required : - application_id - api_id - path_templates properties : application_id : type : string description : ID of the application example : order-service tag : type : string description : tag of the application example : staging api_id : type : string description : ID of the API example : orders-api path_templates : description : Endpoints to be monitored. type : array minLength : 1 items : type : string description : > Path template in /articles/{article-id} (OpenAPI 3) or in /articles/:article-id format. NOTE: They will be normalized to the :this format for metrics naming. example : /orders/{order-id} client_tracking_pattern : description : > The pattern that matches client id in form of a regular expression. By default (if undefined), it is set to `.*`. An empty string disables the client metrics completely. type : string examples : all_services : summary : All services are tracked (for all activated realms). value : \".*\" just_some_services : summary : Only services `orders-service` and `shipment-service` are tracked. value : \"(orders \\ -service|shipment \\ -service)\" Configuration Example: apiUsageMonitoring(` { \"application_id\": \"my-app\", \"tag\": \"staging\", \"api_id\": \"orders-api\", \"path_templates\": [ \"foo/orders\", \"foo/orders/:order-id\", \"foo/orders/:order-id/order_item/{order-item-id}\" ], \"client_tracking_pattern\": \"(shipping\\-service|payment\\-service)\" }`,`{ \"application_id\": \"my-app\", \"api_id\": \"customers-api\", \"path_templates\": [ \"/foo/customers/\", \"/foo/customers/{customer-id}/\" ] } `) Based on the previous configuration, here is an example of a counter metric. apiUsageMonitoring.custom.my-app.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count Note that a missing tag in the configuration will be replaced by {no-tag} in the metric: apiUsageMonitoring.custom.my-app.{no-tag}.customers-api.GET.foo/customers.*.*.http_count Here is the Prometheus query to obtain it. sum(rate(skipper_custom_total{key=\"apiUsageMonitoring.custom.my-app.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count\"}[60s])) by (key) Here is an example of a histogram metric. apiUsageMonitoring.custom.my_app.staging.orders-api.POST.foo/orders.latency Here is the Prometheus query to obtain it. histogram_quantile(0.5, sum(rate(skipper_custom_duration_seconds_bucket{key=\"apiUsageMonitoring.custom.my-app.staging.orders-api.POST.foo/orders.*.*.latency\"}[60s])) by (le, key)) NOTE: Non configured paths will be tracked with {unknown} Application ID, Tag, API ID and path template. However, if all application_id s of your configuration refer to the same application, the filter assume that also non configured paths will be directed to this application. E.g.: apiUsageMonitoring.custom.my-app.{unknown}.{unknown}.GET.{no-match}.*.*.http_count lifo \u00b6 This Filter changes skipper to handle the route with a bounded last in first out queue (LIFO), instead of an unbounded first in first out queue (FIFO). The default skipper scheduler is based on Go net/http package, which provides an unbounded FIFO request handling. If you enable this filter the request scheduling will change to a LIFO. The idea of a LIFO queue is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . All bounded scheduler filters will respond requests with server status error codes in case of overrun. All scheduler filters return HTTP status code: 502, if the specified timeout is reached, because a request could not be scheduled fast enough 503, if the queue is full Parameters: MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxQueueSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifo(100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxQueueSize to 150 and Timeout to 10 seconds. When multiple lifo filters are set in a route, only one of them will be applied. It is undefined which one. lifoGroup \u00b6 This filter is similar to the lifo filter. Parameters: GroupName to group multiple one or many routes to the same queue, which have to have the same settings (string) MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxQueueSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifoGroup(\"mygroup\", 100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxQueueSize to 150 and Timeout to 10 seconds for the lifoGroup \u201cmygroup\u201d, that can be shared between multiple routes. It is enough to set the concurrency, queue size and timeout parameters for one instance of the filter in the group, and only the group name for the rest. Setting these values for multiple instances is fine, too. While only one of them will be used as the source for the applied settings, if there is accidentally a difference between the settings in the same group, a warning will be logged. It is possible to use the lifoGroup filter together with the single lifo filter, e.g. if a route belongs to a group, but needs to have additional stricter settings then the whole group. rfcPath \u00b6 This filter forces an alternative interpretation of the RFC 2616 and RFC 3986 standards, where paths containing reserved characters will have these characters unescaped when the incoming request also has them unescaped. Example: Path(\"/api/*id) -> rfcPath() -> \"http://api-backend\" In the above case, if the incoming request has something like foo%2Fbar in the id position, the api-backend service will also receive it in the format foo%2Fbar, while without the rfcPath() filter the outgoing request path will become /api/foo/bar. In case we want to use the id while routing the request, we can use the backend. Example: api : Path ( \"/api/:id\" ) -> setPath ( \"/api/${id}/summary\" ) -> \"http://api-backend\" ; patch : Path ( \"/api/*id\" ) -> rfcPath () -> < loopback >; In the above case, if the incoming request path is /api/foo%2Fbar, it will match the \u2018patch\u2019 route, and then the patched request will match the api route, and the api-backend service will receive a request with the path /api/foo%2Fbar/summary. It is also possible to enable this behavior centrally for a Skipper instance with the -rfc-patch-path flag. See URI standards interpretation . bearerinjector \u00b6 This filter injects Bearer tokens into Authorization headers read from file providing the token as content. This is only for use cases using skipper as sidecar to inject tokens for the application on the egress path, if it\u2019s used in the ingress path you likely create a security issue for your application. This filter should be used as an egress only feature. Example: egress1 : Method ( \"POST\" ) && Host ( \"api.example.com\" ) -> bearerinjector ( \"write-token\" ) -> \"https://api.example.com/shoes\" ; egress2 : Method ( \"GET\" ) && Host ( \"api.example.com\" ) -> bearerinjector ( \"read-token\" ) -> \"https://api.example.com/shoes\" ; To integrate with the bearerinjector filter you need to run skipper with -credentials-paths=/tmp/secrets and specify an update interval -credentials-update-interval=10s . Files in the credentials path can be a directory, which will be able to find all files within this directory, but it won\u2019t walk subtrees. For the example case, there have to be filenames write-token and read-token within the specified credential paths /tmp/secrets/ , resulting in /tmp/secrets/write-token and /tmp/secrets/read-token . tracingBaggageToTag \u00b6 This filter adds an opentracing tag for a given baggage item in the trace. Syntax: tracingBaggageToTag(\"<baggage_item_name>\", \"<tag_name>\") Example: If a trace consists of baggage item named foo with a value bar . Adding below filter will add a tag named baz with value bar tracingBaggageToTag(\"foo\", \"baz\") tracingTag \u00b6 This filter adds an opentracing tag. Syntax: tracingTag(\"<tag_name>\", \"<tag_value>\") Example: Adding the below filter will add a tag named foo with the value bar . tracingTag(\"foo\", \"bar\") originMarker \u00b6 This filter is used to measure the time it took to create a route. Other than that, it\u2019s a no-op. You can include the same origin marker when you re-create the route. As long as the origin and id are the same, the route creation time will not be measured again. If there are multiple origin markers with the same origin, the earliest timestamp will be used. Parameters: the name of the origin the ID of the object that is the logical source for the route the creation timestamp (rfc3339) Example: originMarker(\"apiUsageMonitoring\", \"deployment1\", \"2019-08-30T09:55:51Z\")","title":"Filters"},{"location":"reference/filters/#skipper-filters","text":"The parameters can be strings, regex or float64 / int string is a string surrounded by double quotes ( \" ) regex is a regular expression, surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ int / float64 are usual (decimal) numbers like 401 or 1.23456 time is a string in double quotes, parseable by time.Duration ) Filters are a generic tool and can change HTTP header and body in the request and response path. Filter can be chained using the arrow operator -> . Example route with a match all, 2 filters and a backend: all : * - > filter1 - > filter2 - > \"http://127.0.0.1:1234/\" ;","title":"Skipper Filters"},{"location":"reference/filters/#backendisproxy","text":"Notifies the proxy that the backend handling this request is also a proxy. The proxy type is based in the URL scheme which can be either http , https or socks5 . Keep in mind that Skipper currently cannot handle CONNECT requests by tunneling the traffic to the target destination, however, the CONNECT requests can be forwarded to a different proxy using this filter. Example: foo1 : * - > backendIsProxy () - > \"http://proxy.example.com\" ; foo2 : * - > backendIsProxy () - > < roundRobin , \"http://proxy1.example.com\" , \"http://proxy2.example.com\" >; foo3 : * - > setDynamicBackendUrl ( \"http://proxy.example.com\" ) - > backendIsProxy () - > < dynamic >;","title":"backendIsProxy"},{"location":"reference/filters/#modrequestheader","text":"Replace all matched regex expressions in the given header. Parameters: header name (string) the expression to match (regex) the replacement (string) Example: enforce_www : * - > modRequestHeader ( \"Host\" , \"^zalando\\.(\\w+)$\" , \"www.zalando.$1\" ) - > redirectTo ( 301 );","title":"modRequestHeader"},{"location":"reference/filters/#setrequestheader","text":"Set headers for requests. Parameters: header name (string) header value (string) Example: foo : * - > setRequestHeader ( \"X-Passed-Skipper\" , \"true\" ) - > \"https://backend.example.org\" ;","title":"setRequestHeader"},{"location":"reference/filters/#appendrequestheader","text":"Same as setRequestHeader , but appends the provided value to the already existing ones.","title":"appendRequestHeader"},{"location":"reference/filters/#droprequestheader","text":"Removes a header from the request Parameters: header name (string) Example: foo : * - > dropRequestHeader ( \"User-Agent\" ) - > \"https://backend.example.org\" ;","title":"dropRequestHeader"},{"location":"reference/filters/#setresponseheader","text":"Same as setRequestHeader , only for responses","title":"setResponseHeader"},{"location":"reference/filters/#appendresponseheader","text":"Same as appendRequestHeader , only for responses","title":"appendResponseHeader"},{"location":"reference/filters/#dropresponseheader","text":"Same as dropRequestHeader but for responses from the backend","title":"dropResponseHeader"},{"location":"reference/filters/#setcontextrequestheader","text":"Set headers for requests using values from the filter context (state bag). If the provided key (second parameter) cannot be found in the state bag, then it doesn\u2019t set the header. Parameters: header name (string) key in the state bag (string) The the route in the following example checkes whether the request is authorized with the oauthTokeninfoAllScope() filter. This filter stores the authenticated user with \u201cauth-user\u201d key in the context, and the setContextRequestHeader() filter in the next step stores it in the header of the outgoing request with the X-Uid name: foo : * - > oauthTokeninfoAllScope ( \"address_service.all\" ) - > setContextRequestHeader ( \"X-Uid\" , \"auth-user\" ) - > \"https://backend.example.org\" ;","title":"setContextRequestHeader"},{"location":"reference/filters/#appendcontextrequestheader","text":"Same as setContextRequestHeader , but appends the provided value to the already existing ones.","title":"appendContextRequestHeader"},{"location":"reference/filters/#setcontextresponseheader","text":"Same as setContextRequestHeader , except for responses.","title":"setContextResponseHeader"},{"location":"reference/filters/#appendcontextresponseheader","text":"Same as appendContextRequestHeader , except for responses.","title":"appendContextResponseHeader"},{"location":"reference/filters/#modpath","text":"Replace all matched regex expressions in the path. Parameters: the expression to match (regex) the replacement (string) Example: rm_api : Path ( \"/api\" ) -> modPath ( \"/api\" , \"/\" ) -> \"https://backend.example.org\" ; append_bar : Path ( \"/foo\" ) -> modPath ( \"/foo\" , \"/foo/bar\" ) -> \"https://backend.example.org\" ; new_base : PathSubtree ( \"/base\" ) -> modPath ( \"/base\" , \"/new/base) -> \" https :// backend . example . org \"; rm_api_regex: Path(\" /api\") -> modPath(\"^/api/(.*)/v2$\", \"/$1\") -> \"https:// backend . example . org \" ;","title":"modPath"},{"location":"reference/filters/#setpath","text":"Replace the path of the original request to the replacement. Parameters: the replacement (string)","title":"setPath"},{"location":"reference/filters/#redirectto","text":"Creates an HTTP redirect response. Parameters: redirect status code (int) location (string) - optional Example: redirect1 : PathRegexp (/^\\/ foo \\/ bar /) -> redirectTo(302, \"/foo/ newBar \" ) -> < shunt >; redirect2 : * -> redirectTo ( 301 ) -> < shunt >; Route redirect1 will do a redirect with status code 302 to https with new path /foo/newBar for requests, that match the path /foo/bar . Route redirect2 will do a https redirect with status code 301 for all incoming requests that match no other route see also redirect-handling","title":"redirectTo"},{"location":"reference/filters/#redirecttolower","text":"Same as redirectTo , but replaces all strings to lower case.","title":"redirectToLower"},{"location":"reference/filters/#static","text":"Serves static content from the filesystem. Parameters: Request path to strip (string) Target base path in the filesystem (string) Example: This serves files from /srv/www/dehydrated when requested via /.well-known/acme-challenge/ , e.g. the request GET /.well-known/acme-challenge/foo will serve the file /srv/www/dehydrated/foo . acme : Host (/./) && Method ( \"GET\" ) && Path ( \"/.well-known/acme-challenge/*\" ) -> static ( \"/.well-known/acme-challenge/\" , \"/srv/www/dehydrated\" ) -> < shunt >; Notes: redirects to the directory when a file index.html exists and it is requested, i.e. GET /foo/index.html redirects to /foo/ which serves then the /foo/index.html serves the content of the index.html when a directory is requested does a simple directory listing of files / directories when no index.html is present","title":"static"},{"location":"reference/filters/#stripquery","text":"Removes the query parameter from the request URL, and if the first filter parameter is \"true\" , preserves the query parameter in the form of x-query-param-<queryParamName>: <queryParamValue> headers, so that ?foo=bar becomes x-query-param-foo: bar Example: * - > stripQuery () - > \"http://backend.example.org\" ; * - > stripQuery ( \"true\" ) - > \"http://backend.example.org\" ;","title":"stripQuery"},{"location":"reference/filters/#preservehost","text":"Sets the incoming Host: header on the outgoing backend connection. It can be used to override the proxyPreserveHost behavior for individual routes. Parameters: \u201ctrue\u201d or \u201cfalse\u201d \u201ctrue\u201d - use the Host header from the incoming request \u201cfalse\u201d - use the host from the backend address Example: route1 : * - > preserveHost ( \"true\" ) - > \"http://backend.example.org\" ;","title":"preserveHost"},{"location":"reference/filters/#status","text":"Sets the response status code to the given value, with no regards to the backend response. Parameters: status code (int) Example: route1 : Host (/^ all401 \\. example \\. org$ /) -> status ( 401 ) -> < shunt >;","title":"status"},{"location":"reference/filters/#compress","text":"The filter, when executed on the response path, checks if the response entity can be compressed. To decide, it checks the Content-Encoding, the Cache-Control and the Content-Type headers. It doesn\u2019t compress the content if the Content-Encoding is set to other than identity, or the Cache-Control applies the no-transform pragma, or the Content-Type is set to an unsupported value. The default supported content types are: text/plain , text/html , application/json , application/javascript , application/x-javascript , text/javascript , text/css , image/svg+xml , application/octet-stream . The default set of MIME types can be reset or extended by passing in the desired types as filter arguments. When extending the defaults, the first argument needs to be \"...\" . E.g. to compress tiff in addition to the defaults: * -> compress(\"...\", \"image/tiff\") -> \"https://www.example.org\" To reset the supported types, e.g. to compress only HTML, the \u201c\u2026\u201d argument needs to be omitted: * -> compress(\"text/html\") -> \"https://www.example.org\" It is possible to control the compression level, by setting it as the first filter argument, in front of the MIME types. The default compression level is best-speed. The possible values are integers between 0 and 9 (inclusive), where 0 means no-compression, 1 means best-speed and 9 means best-compression. Example: * -> compress(9, \"image/tiff\") -> \"https://www.example.org\" The filter also checks the incoming request, if it accepts the supported encodings, explicitly stated in the Accept-Encoding header. The filter currently supports gzip and deflate . It does not assume that the client accepts any encoding if the Accept-Encoding header is not set. It ignores * in the Accept-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, sets the Content-Encoding to the selected encoding and sets the Vary: Accept-Encoding header, if missing. The compression happens in a streaming way, using only a small internal buffer.","title":"compress"},{"location":"reference/filters/#decompress","text":"The filter, when executed on the response path, checks if the response entity is compressed by a supported algorithm. To decide, it checks the Content-Encoding header. When compressing the response, it updates the response header. It deletes the Content-Length value triggering the proxy to always return the response with chunked transfer encoding, deletes the Content-Encoding and the Vary headers, if set. The decompression happens in a streaming way, using only a small internal buffer. Example: * -> decompress() -> \"https://www.example.org\"","title":"decompress"},{"location":"reference/filters/#setquery","text":"Set the query string ?k=v in the request to the backend to a given value. Parameters: key (string) value (string) Example: setQuery(\"k\", \"v\")","title":"setQuery"},{"location":"reference/filters/#dropquery","text":"Delete the query string ?k=v in the request to the backend for a given key. Parameters: key (string) Example: dropQuery(\"k\")","title":"dropQuery"},{"location":"reference/filters/#inlinecontent","text":"Returns arbitrary content in the HTTP body. Parameters: content (string) content type (string) - optional Example: * -> inlineContent(\" <h1> Hello </h1> \") -> <shunt> * -> inlineContent(\"[1,2,3]\", \"application/json\") -> <shunt> Content type will be automatically detected when not provided. Note inlineContent filter is special and must be the last in the filter chain.","title":"inlineContent"},{"location":"reference/filters/#inlinecontentifstatus","text":"Returns arbitrary content in the HTTP body, if the response has the specified status code. Parameters: status code (int) content (string) content type (string) - optional Example: * -> inlineContentIfStatus(404, \" <p class= \\\"problem\\\" > We don't have what you're looking for. </p> \") -> \"https://www.example.org\" * -> inlineContentIfStatus(401, \"{\\\"error\\\": \\\"unauthorized\\\"}\", \"application/json\") -> \"https://www.example.org\" The content type will be automatically detected when not provided.","title":"inlineContentIfStatus"},{"location":"reference/filters/#flowid","text":"Sets an X-Flow-Id header, if it\u2019s not already in the request. This allows you to have a trace in your logs, that traces from the incoming request on the edge to all backend services. Flow IDs must be in a certain format to be reusable in skipper. Valid formats depend on the generator used in skipper. Default generator creates IDs of length 16 matching the following regex: ^[0-9a-zA-Z+-]+$ Parameters: no parameter: resets always the X-Flow-Id header to a new value \"reuse\" : only create X-Flow-Id header if not already set or if the value is invalid in the request Example: * - > flowId () - > \"https://some-backend.example.org\" ; * - > flowId ( \"reuse\" ) - > \"https://some-backend.example.org\" ;","title":"flowId"},{"location":"reference/filters/#xforward","text":"Standard proxy headers. Appends the client remote IP to the X-Forwarded-For and sets the X-Forwarded-Host header.","title":"xforward"},{"location":"reference/filters/#xforwardfirst","text":"Same as xforward , but instead of appending the last remote IP, it prepends it to comply with the approach of certain LB implementations.","title":"xforwardFirst"},{"location":"reference/filters/#randomcontent","text":"Generate response with random text of specified length. Parameters: length of data (int) Example: * -> randomContent(42) -> <shunt>;","title":"randomContent"},{"location":"reference/filters/#latency","text":"Enable adding artificial latency Parameters: latency in milliseconds (int) Example: * - > latency ( 120 ) - > \"https://www.example.org\" ;","title":"latency"},{"location":"reference/filters/#bandwidth","text":"Enable bandwidth throttling. Parameters: bandwidth in kb/s (int) Example: * - > bandwidth ( 30 ) - > \"https://www.example.org\" ;","title":"bandwidth"},{"location":"reference/filters/#chunks","text":"Enables adding chunking responses with custom chunk size with artificial delays in between response chunks. To disable delays, set the second parameter to \u201c0\u201d. Parameters: byte length (int) time duration (time.Duration) Example: * - > chunks ( 1024 , \"120ms\" ) - > \"https://www.example.org\" ; * - > chunks ( 1024 , \"0\" ) - > \"https://www.example.org\" ;","title":"chunks"},{"location":"reference/filters/#backendlatency","text":"Same as latency filter , but on the request path and not on the response path.","title":"backendLatency"},{"location":"reference/filters/#backendbandwidth","text":"Same as bandwidth filter , but on the request path and not on the response path.","title":"backendBandwidth"},{"location":"reference/filters/#backendchunks","text":"Same as chunks filter , but on the request path and not on the response path.","title":"backendChunks"},{"location":"reference/filters/#absorb","text":"The absorb filter reads and discards the payload of the incoming requests. It logs with INFO level and a unique ID per request: the event of receiving the request partial and final events for consuming request payload and total consumed byte count the finishing event of the request any read errors other than EOF","title":"absorb"},{"location":"reference/filters/#logheader","text":"The logHeader filter prints the request line and the header, but not the body, to stderr. Note that this filter should be used only in diagnostics setup and with care, since the request headers may contain sensitive data, and they also can explode the amount of logs. Authorization headers will be truncated in request and response header logs. You can log request or response headers, which defaults for backwards compatibility to request headers. Parameters: no arg, similar to: \u201crequest\u201d \u201crequest\u201d or \u201cresponse\u201d (string varargs) Example: * - > logHeader () - > \"https://www.example.org\" ; * - > logHeader ( \"request\" ) - > \"https://www.example.org\" ; * - > logHeader ( \"response\" ) - > \"https://www.example.org\" ; * - > logHeader ( \"request\" , \"response\" ) - > \"https://www.example.org\" ;","title":"logHeader"},{"location":"reference/filters/#tee","text":"Provides a unix-like tee feature for routing. Using this filter, the request will be sent to a \u201cshadow\u201d backend in addition to the main backend of the route. Example: * - > tee ( \"https://audit-logging.example.org\" ) - > \"https://foo.example.org\" ; This will send an identical request for foo.example.org to audit-logging.example.org. Another use case could be using it for benchmarking a new backend with some real traffic. This we call \u201cshadow traffic\u201d. The above route will forward the request to https://foo.example.org as it normally would do, but in addition to that, it will send an identical request to https://audit-logging.example.org . The request sent to https://audit-logging.example.org will receive the same method and headers, and a copy of the body stream. The tee response is ignored for this shadow backend. It is possible to change the path of the tee request, in a similar way to the modPath filter: Path ( \"/api/v1\" ) - > tee ( \"https://api.example.org\" , \"^/v1\" , \"/v2\" ) - > \"http://api.example.org\" ; In the above example, one can test how a new version of an API would behave on incoming requests.","title":"tee"},{"location":"reference/filters/#teenf","text":"The same as tee filter , but does not follow redirects from the backend.","title":"teenf"},{"location":"reference/filters/#teeloopback","text":"This filter provides a unix-like tee feature for routing, but unlike the tee , this filter feeds the copied request to the start of the routing, including the route lookup and executing the filters on the matched route. It is recommended to use this solution instead of the tee filter, because the same routing facilities are used for the outgoing tee requests as for the normal requests, and all the filters and backend types are supported. To ensure that the right route, or one of the right set of routes, is matched after the loopback, use the filter together with the Tee predicate, however, this is not mandatory if the request is changed via other filters, such that other predicates ensure matching the right route. To avoid infinite looping, the number of requests spawn from a single incoming request is limited similarly as in case of the loopback backend . Parameters: tee group (string): a label identifying which routes should match the loopback request, marked with the Tee predicate Example, generate shadow traffic from 10% of the production traffic: main : * - > \"https://main-backend.example.org; main-split: Traffic(.1) -> teeLoopback(\" test-A \") -> \" https :// main-backend . example . org \"; shadow: Tee(\" test-A \") && True() -> \" https :// test-backend . example . org \" ; See also: Tee predicate Shadow Traffic Tutorial","title":"teeLoopback"},{"location":"reference/filters/#sed","text":"The filter sed replaces all occurences of a pattern with a replacement string in the response body. Example: editorRoute : * - > sed ( \"foo\" , \"bar\" ) - > \"https://www.example.org\" ; Example with larger max buffer: editorRoute : * - > sed ( \"foo\" , \"bar\" , 64000000 ) - > \"https://www.example.org\" ; This filter expects a regexp pattern and a replacement string as arguments. During the streaming of the response body, every occurence of the pattern will be replaced with the replacement string. The editing doesn\u2019t happen right when the filter is executed, only later when the streaming normally happens, after all response filters were called. The sed() filter accepts two optional arguments, the max editor buffer size in bytes, and max buffer handling flag. The max buffer size, when set, defines how much data can be buffered at a given time by the editor. The default value is 2MiB. The max buffer handling flag can take one of two values: \u201cabort\u201d or \u201cbest-effort\u201d (default). Setting \u201cabort\u201d means that the stream will be aborted when reached the limit. Setting \u201cbest-effort\u201d, will run the replacement on the available content, in case of certain patterns, this may result in content that is different from one that would have been edited in a single piece. See more details below. The filter uses the go regular expression implementation: https://github.com/google/re2/wiki/Syntax . Due to the streaming nature, matches with zero length are ignored.","title":"sed"},{"location":"reference/filters/#memory-handling-and-limitations","text":"In order to avoid unbound buffering of unprocessed data, the sed* filters need to apply some limitations. Some patterns, e.g. .* would allow to match the complete payload, and it could result in trying to buffer it all and potentially causing running out of available memory. Similarly, in case of certain expressions, when they don\u2019t match, it\u2019s impossible to tell if they would match without reading more data from the source, and so would potentially need to buffer the entire payload. To prevent too high memory usage, the max buffer size is limited in case of each variant of the filter, by default to 2MiB, which is the same limit as the one we apply when reading the request headers by default. When the limit is reached, and the buffered content matches the pattern, then it is processed by replacing it, when it doesn\u2019t match the pattern, then it is forwarded unchanged. This way, e.g. sed(\".*\", \"\") can be used safely to consume and discard the payload. As a result of this, with large payloads, it is possible that the resulting content will be different than if we had run the replacement on the entire content at once. If we have enough preliminary knowledge about the payload, then it may be better to use the delimited variant of the filters, e.g. for line based editing. If the max buffer handling is set to \u201cabort\u201d, then the stream editing is stopped and the rest of the payload is dropped.","title":"Memory handling and limitations"},{"location":"reference/filters/#seddelim","text":"Like sed() , but it expects an additional argument, before the optional max buffer size argument, that is used to delimit chunks to be processed at once. The pattern replacement is executed only within the boundaries of the chunks defined by the delimiter, and matches across the chunk boundaries are not considered. Example: editorRoute : * - > sedDelim ( \"foo\" , \"bar\" , \"\\n\" ) - > \"https://www.example.org\" ;","title":"sedDelim"},{"location":"reference/filters/#sedrequest","text":"Like sed() , but for the request content. Example: editorRoute : * - > sedRequest ( \"foo\" , \"bar\" ) - > \"https://www.example.org\" ;","title":"sedRequest"},{"location":"reference/filters/#sedrequestdelim","text":"Like sedDelim() , but for the request content. Example: editorRoute : * - > sedRequestDelim ( \"foo\" , \"bar\" , \"\\n\" ) - > \"https://www.example.org\" ;","title":"sedRequestDelim"},{"location":"reference/filters/#basicauth","text":"Enable Basic Authentication The filter accepts two parameters, the first mandatory one is the path to the htpasswd file usually used with Apache or nginx. The second one is the optional realm name that will be displayed in the browser. MD5, SHA1 and BCrypt are supported for Basic authentication password storage, see also the http-auth module page . Examples: basicAuth(\"/path/to/htpasswd\") basicAuth(\"/path/to/htpasswd\", \"My Website\")","title":"basicAuth"},{"location":"reference/filters/#webhook","text":"The webhook filter makes it possible to have your own authentication and authorization endpoint as a filter. Headers from the incoming request will be copied into the request that is being done to the webhook endpoint. It is possible to copy headers from the webhook response into the continuing request by specifying the headers to copy as an optional second argument to the filter. Responses from the webhook with status code less than 300 will be authorized, the rest will be unauthorized. Examples: webhook(\"https://custom-webhook.example.org/auth\") webhook(\"https://custom-webhook.example.org/auth\", \"X-Copy-Webhook-Header,X-Copy-Another-Header\") The webhook timeout has a default of 2 seconds and can be globally changed, if skipper is started with -webhook-timeout=2s flag.","title":"webhook"},{"location":"reference/filters/#oauthtokeninfoanyscope","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured scopes from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyScope(\"s1\", \"s2\", \"s3\")","title":"oauthTokeninfoAnyScope"},{"location":"reference/filters/#oauthtokeninfoallscope","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured scopes from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllScope(\"s1\", \"s2\", \"s3\")","title":"oauthTokeninfoAllScope"},{"location":"reference/filters/#oauthtokeninfoanykv","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If any of the configured key value pairs from the filter is found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokeninfoAnyKV(\"k1\", \"v1\", \"k1\", \"v2\")","title":"oauthTokeninfoAnyKV"},{"location":"reference/filters/#oauthtokeninfoallkv","text":"If skipper is started with -oauth2-tokeninfo-url flag, you can use this filter. The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. There are two rejection scenarios for this filter. If the token is not successfully validated by the oauth server, then a 401 Unauthorised response will be returned. However, if the token is successfully validated but the required scope match isn\u2019t satisfied, then a 403 Forbidden response will be returned. If all of the configured key value pairs from the filter are found inside the tokeninfo result for the incoming token, it will allow the request to pass. Examples: oauthTokeninfoAllKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokeninfoAllKV"},{"location":"reference/filters/#oauthtokenintrospectionanyclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyClaims(\"c1\", \"c2\", \"c3\")","title":"oauthTokenintrospectionAnyClaims"},{"location":"reference/filters/#oauthtokenintrospectionallclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllClaims(\"c1\", \"c2\", \"c3\")","title":"oauthTokenintrospectionAllClaims"},{"location":"reference/filters/#oauthtokenintrospectionanykv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k2\", \"v2\") oauthTokenintrospectionAnyKV(\"k1\", \"v1\", \"k1\", \"v2\")","title":"oauthTokenintrospectionAnyKV"},{"location":"reference/filters/#oauthtokenintrospectionallkv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: oauthTokenintrospectionAllKV(\"k1\", \"v1\", \"k2\", \"v2\")","title":"oauthTokenintrospectionAllKV"},{"location":"reference/filters/#secureoauthtokenintrospectionanyclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\")","title":"secureOauthTokenintrospectionAnyClaims"},{"location":"reference/filters/#secureoauthtokenintrospectionallclaims","text":"The filter accepts variable number of string arguments, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured and supported claims from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"client-id\", \"client-secret\", \"claim1\", \"claim2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllClaims(\"issuerURL\", \"\", \"\", \"claim1\", \"claim2\")","title":"secureOauthTokenintrospectionAllClaims"},{"location":"reference/filters/#secureoauthtokenintrospectionanykv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If one of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAnyKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\")","title":"secureOauthTokenintrospectionAnyKV"},{"location":"reference/filters/#secureoauthtokenintrospectionallkv","text":"The filter accepts an even number of variable arguments of type string, which are used to validate the incoming token from the Authorization: Bearer <token> header. The first argument to the filter is the issuer URL, for example https://accounts.google.com , that will be used as described in RFC Draft to find the configuration and for example supported claims. Use this filter if the Token Introspection endpoint requires authorization to validate and decode the incoming token. The filter will optionally read client-id and client-secret from environment variables: OAUTH_CLIENT_ID, OAUTH_CLIENT_SECRET If all of the configured key value pairs from the filter are found inside the tokenintrospection (RFC7662) result for the incoming token, it will allow the request to pass. Examples: secureOauthTokenintrospectionAllKV(\"issuerURL\", \"client-id\", \"client-secret\", \"k1\", \"v1\", \"k2\", \"v2\") Read client-id and client-secret from environment variables secureOauthTokenintrospectionAllKV(\"issuerURL\", \"\", \"\", \"k1\", \"v1\", \"k2\", \"v2\")","title":"secureOauthTokenintrospectionAllKV"},{"location":"reference/filters/#forwardtoken","text":"The filter takes the (string) header name as its first argument. The result of token info or token introspection is added to this header when the request is passed to the backend. If there are additional arguments, these values are treated as a whitelisted set of JSON keys to be included in the header payload when forwarding to the backend service. If this filter is used when there is no token introspection or token info data then it does not have any effect. Examples: forwardToken(\"X-Tokeninfo-Forward\") forwardToken(\"X-Tokeninfo-Forward\", \"access_token\")","title":"forwardToken"},{"location":"reference/filters/#oauthoidcuserinfo","text":"oauthOidcUserInfo(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims The claims which should be present in the token returned by the provider. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON .","title":"oauthOidcUserInfo"},{"location":"reference/filters/#oauthoidcanyclaims","text":"oauthOidcAnyClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed as long as at least one of them is present. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON .","title":"oauthOidcAnyClaims"},{"location":"reference/filters/#oauthoidcallclaims","text":"oauthOidcAllClaims(\"https://oidc-provider.example.com\", \"client_id\", \"client_secret\", \"http://target.example.com/subpath/callback\", \"email profile\", \"name email picture\", \"parameter=value\", \"X-Auth-Authorization:claims.email\") The filter needs the following parameters: OpenID Connect Provider URL For example Google OpenID Connect is available on https://accounts.google.com Client ID This value is obtained from the provider upon registration of the application. Client Secret Also obtained from the provider Callback URL The entire path to the callback from the provider on which the token will be received. It can be any value which is a subpath on which the filter is applied. Scopes The OpenID scopes separated by spaces which need to be specified when requesting the token from the provider. Claims Several claims can be specified and the request is allowed only when all claims are present. Auth Code Options (optional) Passes key/value parameters to a provider\u2019s authorization endpoint. Upstream Headers (optional) The upstream endpoint will receive these headers which values are parsed from the OIDC information. The header definition can be one or more header-query pairs, space delimited. The query syntax is GJSON .","title":"oauthOidcAllClaims"},{"location":"reference/filters/#requestcookie","text":"Append a cookie to the request header. Parameters: cookie name (string) cookie value (string) Example: requestCookie(\"test-session\", \"abc\")","title":"requestCookie"},{"location":"reference/filters/#oidcclaimsquery","text":"oidcClaimsQuery(\"<path>:[<query>]\", ...) The filter is chained after oauthOidc* authentication as it parses the ID token that has been saved in the internal StateBag for this request. It validates access control of the requested path against the defined query. It accepts one or more arguments, thats is a path prefix which is granted access to when the query definition evaluates positive. It supports exact matches of keys, key-value pairs, introspecting of arrays or exact and wildcard matching of nested structures. The query definition can be one or more queries per path, space delimited. The query syntax is GJSON with a convenience modifier of @_ which unfolds to [@this].#(\"+arg+\") Given following example ID token: { \"email\" : \"someone@example.org\" , \"groups\" : [ \"CD-xyz\" , \"appX-Test-Users\" \"Purchasing-Department\" , ], \"name\" : \"Some One\" } Access to path / would be granted to everyone in example.org , however path /login only to those being member of group \"appX-Tester\" : oauthOidcAnyClaims(...) -> oidcClaimsQuery(\"/login:groups.#[==\\\"appX-Tester\\\"]\", \"/:@_:email%\\\"*@example.org\\\"\") For above ID token following query definitions would also be positive: oidcClaimsQuery(\"/:email\") oidcClaimsQuery(\"/another/path:groups.#[%\\\"CD-*\\\"]\") oidcClaimsQuery(\"/:name%\\\"*One\\\"\", \"/path:groups.#[%\\\"*-Test-Users\\\"] groups.#[==\\\"Purchasing-Department\\\"]\") As of now there is no negative/deny rule possible. The first matching path is evaluated against the defined query/queries and if positive, permitted.","title":"oidcClaimsQuery"},{"location":"reference/filters/#responsecookie","text":"Appends cookies to responses in the \u201cSet-Cookie\u201d header. The response cookie accepts an optional argument to control the max-age property of the cookie, of type int , in seconds. The response cookie accepts an optional fourth argument, \u201cchange-only\u201d, to control if the cookie should be set on every response, or only if the request does not contain a cookie with the provided name and value. Example: responseCookie(\"test-session\", \"abc\") responseCookie(\"test-session\", \"abc\", 31536000), responseCookie(\"test-session\", \"abc\", 31536000, \"change-only\")","title":"responseCookie"},{"location":"reference/filters/#jscookie","text":"The JS cookie behaves exactly as the response cookie, but it does not set the HttpOnly directive, so these cookies will be accessible from JS code running in web browsers. Example: jsCookie(\"test-session-info\", \"abc-debug\", 31536000, \"change-only\")","title":"jsCookie"},{"location":"reference/filters/#consecutivebreaker","text":"This breaker opens when the proxy could not connect to a backend or received a >=500 status code at least N times in a row. When open, the proxy returns 503 - Service Unavailable response during the breaker timeout. After this timeout, the breaker goes into half-open state, in which it expects that M number of requests succeed. The requests in the half-open state are accepted concurrently. If any of the requests during the half-open state fails, the breaker goes back to open state. If all succeed, it goes to closed state again. Parameters: number of consecutive failures to open (int) timeout (time string, parseable by time.Duration ) - optional half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . Can be used as egress feature.","title":"consecutiveBreaker"},{"location":"reference/filters/#ratebreaker","text":"The \u201crate breaker\u201d works similar to the consecutiveBreaker , but instead of considering N consecutive failures for going open, it maintains a sliding window of the last M events, both successes and failures, and opens only when the number of failures reaches N within the window. This way the sliding window is not time based and allows the same breaker characteristics for low and high rate traffic. Parameters: number of consecutive failures to open (int) sliding window (time string, parseable by time.Duration ) half-open requests (int) - optional idle-ttl (time string, parseable by time.Duration ) - optional See also the circuit breaker docs . Can be used as egress feature.","title":"rateBreaker"},{"location":"reference/filters/#disablebreaker","text":"Change (or set) the breaker configurations for an individual route and disable for another, in eskip: updates : Method ( \"POST\" ) && Host ( \"foo.example.org\" ) -> consecutiveBreaker ( 9 ) -> \"https://foo.backend.net\" ; backendHealthcheck : Path ( \"/healthcheck\" ) -> disableBreaker () -> \"https://foo.backend.net\" ; See also the circuit breaker docs . Can be used as egress feature.","title":"disableBreaker"},{"location":"reference/filters/#localratelimit","text":"DEPRECATED use clientRatelimit with the same settings instead.","title":"~~localRatelimit~~"},{"location":"reference/filters/#clientratelimit","text":"Per skipper instance calculated ratelimit, that allows number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional third parameter. If the third parameter is set skipper will use the defined HTTP header to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flag -enable-ratelimits . Skipper will consume roughly 15 MB per filter for 100.000 clients. Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header, in case the provided string contains , , it will combine all these headers (string) clientRatelimit(3, \"1m\") clientRatelimit(3, \"1m\", \"Authorization\") clientRatelimit(3, \"1m\", \"X-Foo,Authorization,X-Bar\") See also the ratelimit docs .","title":"clientRatelimit"},{"location":"reference/filters/#ratelimit","text":"Per skipper instance calculated ratelimit, that allows forwarding a number of requests to the backend group. You need to run skipper with command line flag -enable-ratelimits . Parameters: number of allowed requests per time period (int) time period for requests being counted (time.Duration) ratelimit(20, \"1m\") ratelimit(300, \"1h\") See also the ratelimit docs .","title":"ratelimit"},{"location":"reference/filters/#clusterclientratelimit","text":"This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests by client. The definition of the same client is based on data of the http header and can be changed with an optional fourth parameter. If the fourth parameter is set skipper will use the HTTP header defined by this to put the request in the same client bucket, else the X-Forwarded-For Header will be used. You need to run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) optional parameter to set the same client by header, in case the provided string contains , , it will combine all these headers (string) clusterClientRatelimit(\"groupA\", 10, \"1h\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"Authorization\") clusterClientRatelimit(\"groupA\", 10, \"1h\", \"X-Forwarded-For,Authorization,User-Agent\") See also the ratelimit docs .","title":"clusterClientRatelimit"},{"location":"reference/filters/#clusterratelimit","text":"This ratelimit is calculated across all skipper peers and the same rate limit group. The first parameter is a string to select the same ratelimit group across one or more routes. The rate limit group allows the given number of requests to a backend. You need to have run skipper with command line flags -enable-swarm and -enable-ratelimits . See also our cluster ratelimit tutorial Parameters: rate limit group (string) number of allowed requests per time period (int) time period for requests being counted (time.Duration) clusterRatelimit(\"groupB\", 20, \"1m\") clusterRatelimit(\"groupB\", 300, \"1h\") See also the ratelimit docs .","title":"clusterRatelimit"},{"location":"reference/filters/#lua","text":"See the scripts page","title":"lua"},{"location":"reference/filters/#corsorigin","text":"The filter accepts an optional variadic list of acceptable origin parameters. If the input argument list is empty, the header will always be set to * which means any origin is acceptable. Otherwise the header is only set if the request contains an Origin header and its value matches one of the elements in the input list. The header is only set on the response. Parameters: url (variadic string) Examples: corsOrigin() corsOrigin(\"https://www.example.org\") corsOrigin(\"https://www.example.org\", \"http://localhost:9001\")","title":"corsOrigin"},{"location":"reference/filters/#headertoquery","text":"Filter which assigns the value of a given header from the incoming Request to a given query param Parameters: The name of the header to pick from request The name of the query param key to add to request Examples: headerToQuery(\"X-Foo-Header\", \"foo-query-param\") The above filter will set foo-query-param query param respectively to the X-Foo-Header header and will override the value if the queryparam exists already","title":"headerToQuery"},{"location":"reference/filters/#querytoheader","text":"Filter which assigns the value of a given query param from the incoming Request to a given Header with optional format string value. Parameters: The name of the query param key to pick from request The name of the header to add to request The format string used to create the header value, which gets the value from the query value as before Examples: queryToHeader(\"foo-query-param\", \"X-Foo-Header\") queryToHeader(\"access_token\", \"Authorization\", \"Bearer %s\") The first filter will set X-Foo-Header header respectively to the foo-query-param query param and will not override the value if the header exists already. The second filter will set Authorization header to the access_token query param with a prefix value Bearer and will not override the value if the header exists already.","title":"queryToHeader"},{"location":"reference/filters/#accesslogdisabled","text":"Deprecated: use disableAccessLog or enableAccessLog The accessLogDisabled filter overrides global Skipper AccessLogDisabled setting for a specific route, which allows to either turn-off the access log for specific route while access log, in general, is enabled or vice versa. Example: accessLogDisabled(\"false\")","title":"~~accessLogDisabled~~"},{"location":"reference/filters/#disableaccesslog","text":"Filter overrides global Skipper AccessLogDisabled setting and allows to turn-off the access log for specific route while access log, in general, is enabled. It is also possible to disable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: disableAccessLog() disableAccessLog(1, 301, 40) This disables logs of all requests with status codes 1xxs , 301 and all 40xs .","title":"disableAccessLog"},{"location":"reference/filters/#enableaccesslog","text":"Filter overrides global Skipper AccessLogDisabled setting and allows to turn-on the access log for specific route while access log, in general, is disabled. It is also possible to enable access logs only for a subset of response codes from backend by providing an optional list of response code prefixes. Parameters: response code prefixes (variadic int) - optional Example: enableAccessLog() enableAccessLog(1, 301, 20) This enables logs of all requests with status codes 1xxs , 301 and all 20xs .","title":"enableAccessLog"},{"location":"reference/filters/#auditlog","text":"Filter auditLog() logs the request and N bytes of the body into the log file. N defaults to 1024 and can be overidden with -max-audit-body=<int> . N=0 omits logging the body. Example: auditLog()","title":"auditLog"},{"location":"reference/filters/#unverifiedauditlog","text":"Filter unverifiedAuditLog() adds a Header, X-Unverified-Audit , to the request, the content of which, will also be written to the log file. By default, the value of the audit header will be equal to the value of the sub key, from the Authorization token. This can be changed by providing a string input to the filter which matches another key from the token. N.B. It is important to note that, if the content of the X-Unverified-Audit header does not match the following regex, then a default value of invalid-sub will be populated in the header instead: ^[a-zA-z0-9_/:?=&%@.#-]*$ Examples: unverifiedAuditLog() unverifiedAuditLog(\"azp\")","title":"unverifiedAuditLog"},{"location":"reference/filters/#setdynamicbackendhostfromheader","text":"Filter sets the backend host for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl filters, the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendHostFromHeader ( \"X-Forwarded-Host\" ) - > < dynamic >;","title":"setDynamicBackendHostFromHeader"},{"location":"reference/filters/#setdynamicbackendschemefromheader","text":"Filter sets the backend scheme for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: header name (string) Example: foo : * - > setDynamicBackendSchemeFromHeader ( \"X-Forwarded-Proto\" ) - > < dynamic >;","title":"setDynamicBackendSchemeFromHeader"},{"location":"reference/filters/#setdynamicbackendurlfromheader","text":"Filter sets the backend url for a route, value is taken from the provided header. Can be used only with <dynamic> backend. Parameters: header name (string) Example: foo : * - > setDynamicBackendUrlFromHeader ( \"X-Custom-Url\" ) - > < dynamic >;","title":"setDynamicBackendUrlFromHeader"},{"location":"reference/filters/#setdynamicbackendhost","text":"Filter sets the backend host for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendSchemeFromHeader or setDynamicBackendScheme . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: host (string) Example: foo : * - > setDynamicBackendHost ( \"example.com\" ) - > < dynamic >;","title":"setDynamicBackendHost"},{"location":"reference/filters/#setdynamicbackendscheme","text":"Filter sets the backend scheme for a route. Can be used only with <dynamic> backend. Meant to be used together with setDynamicBackendHostFromHeader or setDynamicBackendHost . If this filter chained together with setDynamicBackendUrlFromHeader or setDynamicBackendUrl , the latter ones would have priority. Parameters: scheme (string) Example: foo : * - > setDynamicBackendScheme ( \"https\" ) - > < dynamic >;","title":"setDynamicBackendScheme"},{"location":"reference/filters/#setdynamicbackendurl","text":"Filter sets the backend url for a route. Can be used only with <dynamic> backend. Parameters: url (string) Example: foo : * - > setDynamicBackendUrl ( \"https://example.com\" ) - > < dynamic >;","title":"setDynamicBackendUrl"},{"location":"reference/filters/#apiusagemonitoring","text":"The apiUsageMonitoring filter adds API related metrics to the Skipper monitoring. It is by default not activated. Activate it by providing the -enable-api-usage-monitoring flag at Skipper startup. In its deactivated state, it is still registered as a valid filter (allowing route configurations to specify it), but will perform no operation. That allows, per instance, production environments to use it and testing environments not to while keeping the same route configuration for all environments. For the client based metrics, additional flags need to be specified. Flag Description api-usage-monitoring-realm-keys Name of the property in the JWT JSON body that contains the name of the realm . api-usage-monitoring-client-keys Name of the property in the JWT JSON body that contains the name of the client . api-usage-monitoring-realms-tracking-pattern RegEx of realms to be monitored. Defaults to \u2018services\u2019. NOTE: Make sure to activate the metrics flavour proper to your environment using the metrics-flavour flag in order to get those metrics. Example: skipper -metrics-flavour prometheus -enable-api-usage-monitoring -api-usage-monitoring-realm-keys = \"realm\" -api-usage-monitoring-client-keys = \"managed-id\" api-usage-monitoring-realms-tracking-pattern = \"services,users\" The structure of the metrics is all of those elements, separated by . dots: Part Description apiUsageMonitoring.custom Every filter metrics starts with the name of the filter followed by custom . This part is constant. Application ID Identifier of the application, configured in the filter under app_id . Tag Tag of the application (e.g. staging), configured in the filter under tag . API ID Identifier of the API, configured in the filter under api_id . Method The request\u2019s method (verb), capitalized (ex: GET , POST , PUT , DELETE ). Path The request\u2019s path, in the form of the path template configured in the filter under path_templates . Realm The realm in which the client is authenticated. Client Identifier under which the client is authenticated. Metric Name Name (or key) of the metric being tracked.","title":"apiUsageMonitoring"},{"location":"reference/filters/#available-metrics","text":"","title":"Available Metrics"},{"location":"reference/filters/#endpoint-related-metrics","text":"Those metrics are not identifying the realm and client. They always have * in their place. Example: + Realm | apiUsageMonitoring.custom.orders-backend.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count | | | + Metric Name + Client The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Histogram latency time between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response )","title":"Endpoint Related Metrics"},{"location":"reference/filters/#client-related-metrics","text":"Those metrics are not identifying endpoint (path) and HTTP verb. They always have * as their place. Example: + HTTP Verb | + Path Template + Metric Name | | | apiUsageMonitoring.custom.orders-backend.staging.orders-api.*.*.users.mmustermann.http_count | | | + Client + Realm The available metrics are: Type Metric Name Description Counter http_count number of HTTP exchanges Counter http1xx_count number of HTTP exchanges resulting in information (HTTP status in the 100s) Counter http2xx_count number of HTTP exchanges resulting in success (HTTP status in the 200s) Counter http3xx_count number of HTTP exchanges resulting in a redirect (HTTP status in the 300s) Counter http4xx_count number of HTTP exchanges resulting in a client error (HTTP status in the 400s) Counter http5xx_count number of HTTP exchanges resulting in a server error (HTTP status in the 500s) Counter latency_sum sum of seconds (in decimal form) between the first observable moment (a call to the filter\u2019s Request ) until the last (a call to the filter\u2019s Response )","title":"Client Related Metrics"},{"location":"reference/filters/#filter-configuration","text":"Endpoints can be monitored using the apiUsageMonitoring filter in the route. It accepts JSON objects (as strings) of the format mentioned below. In case any of the required parameters is missing, no-op filter is created, i.e. no metrics are captured, but the creation of the route does not fail. api-usage-monitoring-configuration : type : object required : - application_id - api_id - path_templates properties : application_id : type : string description : ID of the application example : order-service tag : type : string description : tag of the application example : staging api_id : type : string description : ID of the API example : orders-api path_templates : description : Endpoints to be monitored. type : array minLength : 1 items : type : string description : > Path template in /articles/{article-id} (OpenAPI 3) or in /articles/:article-id format. NOTE: They will be normalized to the :this format for metrics naming. example : /orders/{order-id} client_tracking_pattern : description : > The pattern that matches client id in form of a regular expression. By default (if undefined), it is set to `.*`. An empty string disables the client metrics completely. type : string examples : all_services : summary : All services are tracked (for all activated realms). value : \".*\" just_some_services : summary : Only services `orders-service` and `shipment-service` are tracked. value : \"(orders \\ -service|shipment \\ -service)\" Configuration Example: apiUsageMonitoring(` { \"application_id\": \"my-app\", \"tag\": \"staging\", \"api_id\": \"orders-api\", \"path_templates\": [ \"foo/orders\", \"foo/orders/:order-id\", \"foo/orders/:order-id/order_item/{order-item-id}\" ], \"client_tracking_pattern\": \"(shipping\\-service|payment\\-service)\" }`,`{ \"application_id\": \"my-app\", \"api_id\": \"customers-api\", \"path_templates\": [ \"/foo/customers/\", \"/foo/customers/{customer-id}/\" ] } `) Based on the previous configuration, here is an example of a counter metric. apiUsageMonitoring.custom.my-app.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count Note that a missing tag in the configuration will be replaced by {no-tag} in the metric: apiUsageMonitoring.custom.my-app.{no-tag}.customers-api.GET.foo/customers.*.*.http_count Here is the Prometheus query to obtain it. sum(rate(skipper_custom_total{key=\"apiUsageMonitoring.custom.my-app.staging.orders-api.GET.foo/orders/{order-id}.*.*.http_count\"}[60s])) by (key) Here is an example of a histogram metric. apiUsageMonitoring.custom.my_app.staging.orders-api.POST.foo/orders.latency Here is the Prometheus query to obtain it. histogram_quantile(0.5, sum(rate(skipper_custom_duration_seconds_bucket{key=\"apiUsageMonitoring.custom.my-app.staging.orders-api.POST.foo/orders.*.*.latency\"}[60s])) by (le, key)) NOTE: Non configured paths will be tracked with {unknown} Application ID, Tag, API ID and path template. However, if all application_id s of your configuration refer to the same application, the filter assume that also non configured paths will be directed to this application. E.g.: apiUsageMonitoring.custom.my-app.{unknown}.{unknown}.GET.{no-match}.*.*.http_count","title":"Filter Configuration"},{"location":"reference/filters/#lifo","text":"This Filter changes skipper to handle the route with a bounded last in first out queue (LIFO), instead of an unbounded first in first out queue (FIFO). The default skipper scheduler is based on Go net/http package, which provides an unbounded FIFO request handling. If you enable this filter the request scheduling will change to a LIFO. The idea of a LIFO queue is based on Dropbox bandaid proxy, which is not opensource. Dropbox shared their idea in a public blogpost . All bounded scheduler filters will respond requests with server status error codes in case of overrun. All scheduler filters return HTTP status code: 502, if the specified timeout is reached, because a request could not be scheduled fast enough 503, if the queue is full Parameters: MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxQueueSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifo(100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxQueueSize to 150 and Timeout to 10 seconds. When multiple lifo filters are set in a route, only one of them will be applied. It is undefined which one.","title":"lifo"},{"location":"reference/filters/#lifogroup","text":"This filter is similar to the lifo filter. Parameters: GroupName to group multiple one or many routes to the same queue, which have to have the same settings (string) MaxConcurrency specifies how many goroutines are allowed to work on this queue(int) MaxQueueSize sets the queue size (int) Timeout sets the timeout to get request scheduled (time) Example: lifoGroup(\"mygroup\", 100, 150, \"10s\") The above configuration will set MaxConcurrency to 100, MaxQueueSize to 150 and Timeout to 10 seconds for the lifoGroup \u201cmygroup\u201d, that can be shared between multiple routes. It is enough to set the concurrency, queue size and timeout parameters for one instance of the filter in the group, and only the group name for the rest. Setting these values for multiple instances is fine, too. While only one of them will be used as the source for the applied settings, if there is accidentally a difference between the settings in the same group, a warning will be logged. It is possible to use the lifoGroup filter together with the single lifo filter, e.g. if a route belongs to a group, but needs to have additional stricter settings then the whole group.","title":"lifoGroup"},{"location":"reference/filters/#rfcpath","text":"This filter forces an alternative interpretation of the RFC 2616 and RFC 3986 standards, where paths containing reserved characters will have these characters unescaped when the incoming request also has them unescaped. Example: Path(\"/api/*id) -> rfcPath() -> \"http://api-backend\" In the above case, if the incoming request has something like foo%2Fbar in the id position, the api-backend service will also receive it in the format foo%2Fbar, while without the rfcPath() filter the outgoing request path will become /api/foo/bar. In case we want to use the id while routing the request, we can use the backend. Example: api : Path ( \"/api/:id\" ) -> setPath ( \"/api/${id}/summary\" ) -> \"http://api-backend\" ; patch : Path ( \"/api/*id\" ) -> rfcPath () -> < loopback >; In the above case, if the incoming request path is /api/foo%2Fbar, it will match the \u2018patch\u2019 route, and then the patched request will match the api route, and the api-backend service will receive a request with the path /api/foo%2Fbar/summary. It is also possible to enable this behavior centrally for a Skipper instance with the -rfc-patch-path flag. See URI standards interpretation .","title":"rfcPath"},{"location":"reference/filters/#bearerinjector","text":"This filter injects Bearer tokens into Authorization headers read from file providing the token as content. This is only for use cases using skipper as sidecar to inject tokens for the application on the egress path, if it\u2019s used in the ingress path you likely create a security issue for your application. This filter should be used as an egress only feature. Example: egress1 : Method ( \"POST\" ) && Host ( \"api.example.com\" ) -> bearerinjector ( \"write-token\" ) -> \"https://api.example.com/shoes\" ; egress2 : Method ( \"GET\" ) && Host ( \"api.example.com\" ) -> bearerinjector ( \"read-token\" ) -> \"https://api.example.com/shoes\" ; To integrate with the bearerinjector filter you need to run skipper with -credentials-paths=/tmp/secrets and specify an update interval -credentials-update-interval=10s . Files in the credentials path can be a directory, which will be able to find all files within this directory, but it won\u2019t walk subtrees. For the example case, there have to be filenames write-token and read-token within the specified credential paths /tmp/secrets/ , resulting in /tmp/secrets/write-token and /tmp/secrets/read-token .","title":"bearerinjector"},{"location":"reference/filters/#tracingbaggagetotag","text":"This filter adds an opentracing tag for a given baggage item in the trace. Syntax: tracingBaggageToTag(\"<baggage_item_name>\", \"<tag_name>\") Example: If a trace consists of baggage item named foo with a value bar . Adding below filter will add a tag named baz with value bar tracingBaggageToTag(\"foo\", \"baz\")","title":"tracingBaggageToTag"},{"location":"reference/filters/#tracingtag","text":"This filter adds an opentracing tag. Syntax: tracingTag(\"<tag_name>\", \"<tag_value>\") Example: Adding the below filter will add a tag named foo with the value bar . tracingTag(\"foo\", \"bar\")","title":"tracingTag"},{"location":"reference/filters/#originmarker","text":"This filter is used to measure the time it took to create a route. Other than that, it\u2019s a no-op. You can include the same origin marker when you re-create the route. As long as the origin and id are the same, the route creation time will not be measured again. If there are multiple origin markers with the same origin, the earliest timestamp will be used. Parameters: the name of the origin the ID of the object that is the logical source for the route the creation timestamp (rfc3339) Example: originMarker(\"apiUsageMonitoring\", \"deployment1\", \"2019-08-30T09:55:51Z\")","title":"originMarker"},{"location":"reference/plugins/","text":"Skipper plugins \u00b6 Skipper may be extended with functionality not present in the core. These additions can be built as go plugin, so they do not have to be present in the main skipper repository. Note the warning from Go\u2019s plugin.go: // The plugin support is currently incomplete, only supports Linux, // and has known bugs. Please report any issues. Note the known problem of using plugins together with vendoring, best described here: https://github.com/golang/go/issues/20481 Plugin directories \u00b6 Plugins are loaded from sub directories of the plugin directories. By default the plugin directory is set to ./plugins (i.e. relative to skipper\u2019s working directory). An additional directory may be given with the -plugindir=/path/to/dir option to skipper. Any file with the suffix .so found below the plugin directories (also in sub directories) is attempted to load without any arguments. When a plugin needs an argument, this must be explicitly loaded and the arguments passed, e.g. with -filter-plugin geoip,db=/path/to/db . Building a plugin \u00b6 Each plugin should be built with Go version >= 1.11, enabled Go modules support similar to the following build command line: GO111MODULE=on go build -buildmode=plugin -o example.so example.go There are some pitfalls: packages which are shared between skipper and the plugin must not be in a vendor/ directory, otherwise the plugin will fail to load or in some cases give wrong results (e.g. an opentracing span cannot be found in the context even if it is present). This also means: Do not vendor skipper in a plugin repo\u2026 plugins must be rebuilt when skipper is rebuilt do not attempt to rebuild a module and copy it over a loaded plugin, that will crash skipper immediately\u2026 Use a plugin \u00b6 In this example we use a geoip database, that you need to find and download. We expect that you did a git clone git@github.com:zalando/skipper.git and entered the directory. Build skipper: % make skipper Install filter plugins: % mkdir plugins % git clone git@github.com:skipper-plugins/filters.git plugins/filters % ls plugins/filters geoip / glide . lock glide . yaml ldapauth / Makefile noop / plugin_test . go % cd plugins/filters/geoip % GO111MODULE=on go build -buildmode=plugin -o geoip.so geoip.go % cd - ~/ go / src / github . com / zalando / skipper Start a pseudo backend that shows all headers in plain: % nc -l 9000 Run the proxy with geoip database: % ./bin/skipper -filter-plugin geoip,db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb -inline-routes '* -> geoip() -> \"http://127.0.0.1:9000\"' [ APP ] INFO [ 0000 ] found plugin geoip at plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] loaded plugin geoip ( geoip ) from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] attempting to load plugin from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] plugin geoip already loaded with InitFilter [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] route settings , reset , route : : * -> geoip () -> \" http : // 127.0 . 0.1 : 9000 \" [ APP ] INFO [ 0000 ] certPathTLS or keyPathTLS not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied Or passing a yaml file via config-file flag: inline-routes : '* -> geoip() -> \"http://127.0.0.1:9000\"' filter-plugin : geoip : - db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb Use a client to lookup geoip: % curl -H\"X-Forwarded-For: 107.12.53.5\" localhost:9090/ ^ C pseudo backend should show X-Geoip-Country header: # nc -l 9000 GET / HTTP/1.1 Host: 127.0.0.1:9000 User-Agent: curl/7.49.0 Accept: */* X-Forwarded-For: 107.12.53.5 X-Geoip-Country: US Accept-Encoding: gzip ^C skipper should show additional log lines, because of the CTRL-C: [APP]ERRO[0082] error while proxying, route with backend http://127.0.0.1:9000, status code 500: dialing failed false: EOF 107.12.53.5 - - [28/Nov/2018:14:39:40 +0100] \"GET / HTTP/1.1\" 500 22 \"-\" \"curl/7.49.0\" 2753 localhost:9090 - - Filter plugins \u00b6 All plugins must have a function named InitFilter with the following signature func([]string) (filters.Spec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -filter-plugin parameter. E.g. when the -filter-plugin parameter is myfilter,datafile=/path/to/file,foo=bar the myfilter plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The filter plugin implementation is responsible to parse the received arguments. Filter plugins can be found in the filter repo Example filter plugin \u00b6 An example noop plugin looks like package main import ( \"github.com/zalando/skipper/filters\" ) type noopSpec struct {} func InitFilter ( opts [] string ) ( filters . Spec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"noop\" } func ( s noopSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return noopFilter {}, nil } type noopFilter struct {} func ( f noopFilter ) Request ( filters . FilterContext ) {} func ( f noopFilter ) Response ( filters . FilterContext ) {} Predicate plugins \u00b6 All plugins must have a function named InitPredicate with the following signature func([]string) (routing.PredicateSpec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -predicate-plugin parameter. E.g. when the -predicate-plugin parameter is mypred,datafile=/path/to/file,foo=bar the mypred plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The predicate plugin implementation is responsible to parse the received arguments. Predicate plugins can be found in the predicate repo Example predicate plugin \u00b6 An example MatchAll plugin looks like package main import ( \"github.com/zalando/skipper/routing\" \"net/http\" ) type noopSpec struct {} func InitPredicate ( opts [] string ) ( routing . PredicateSpec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"MatchAll\" } func ( s noopSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { return noopPredicate {}, nil } type noopPredicate struct {} func ( p noopPredicate ) Match ( * http . Request ) bool { return true } DataClient plugins \u00b6 Similar to the above predicate and filter plugins. The command line option for data client plugins is -dataclient-plugin . The module must have a InitDataClient function with the signature func([]string) (routing.DataClient, error) A noop data client looks like package main import ( \"github.com/zalando/skipper/eskip\" \"github.com/zalando/skipper/routing\" ) func InitDataClient ([] string ) ( routing . DataClient , error ) { var dc DataClient = \"\" return dc , nil } type DataClient string func ( dc DataClient ) LoadAll () ([] * eskip . Route , error ) { return eskip . Parse ( string ( dc )) } func ( dc DataClient ) LoadUpdate () ([] * eskip . Route , [] string , error ) { return nil , nil , nil } MultiType plugins \u00b6 Sometimes it is necessary to combine multiple plugin types into one module. This can be done with this kind of plugin. Note that these modules are not auto loaded, these need an explicit -multi-plugin name,arg1,arg2 command line switch for skipper. The module must have a InitPlugin function with the signature func([]string) ([]filters.Spec, []routing.PredicateSpec, []routing.DataClient, error) Any of the returned types may be nil, so you can have e.g. a combined filter / data client plugin or share a filter and a predicate, e.g. like package main import ( \"fmt\" \"net\" \"net/http\" \"strconv\" \"strings\" ot \"github.com/opentracing/opentracing-go\" maxminddb \"github.com/oschwald/maxminddb-golang\" \"github.com/zalando/skipper/filters\" snet \"github.com/zalando/skipper/net\" \"github.com/zalando/skipper/predicates\" \"github.com/zalando/skipper/routing\" ) type geoipSpec struct { db * maxminddb . Reader name string } func InitPlugin ( opts [] string ) ([] filters . Spec , [] routing . PredicateSpec , [] routing . DataClient , error ) { var db string for _ , o := range opts { switch { case strings . HasPrefix ( o , \"db=\" ): db = o [ 3 :] } } if db == \"\" { return nil , nil , nil , fmt . Errorf ( \"missing db= parameter for geoip plugin\" ) } reader , err := maxminddb . Open ( db ) if err != nil { return nil , nil , nil , fmt . Errorf ( \"failed to open db %s: %s\" , db , err ) } return [] filters . Spec { & geoipSpec { db : reader , name : \"geoip\" }}, [] routing . PredicateSpec { & geoipSpec { db : reader , name : \"GeoIP\" }}, nil , nil } func ( s * geoipSpec ) Name () string { return s . name } func ( s * geoipSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { var fromLast bool header := \"X-GeoIP-Country\" var err error for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , filters . ErrInvalidFilterParameters } case strings . HasPrefix ( s , \"header=\" ): header = s [ 7 :] } } } return & geoip { db : s . db , fromLast : fromLast , header : header }, nil } func ( s * geoipSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { var fromLast bool var err error countries := make ( map [ string ] struct {}) for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , predicates . ErrInvalidPredicateParameters } default : countries [ strings . ToUpper ( s )] = struct {}{} } } } return & geoip { db : s . db , fromLast : fromLast , countries : countries }, nil } type geoip struct { db * maxminddb . Reader fromLast bool header string countries map [ string ] struct {} } type countryRecord struct { Country struct { ISOCode string `maxminddb:\"iso_code\"` } `maxminddb:\"country\"` } func ( g * geoip ) lookup ( r * http . Request ) string { var src net . IP if g . fromLast { src = snet . RemoteHostFromLast ( r ) } else { src = snet . RemoteHost ( r ) } record := countryRecord {} err := g . db . Lookup ( src , & record ) if err != nil { fmt . Printf ( \"geoip(): failed to lookup %s: %s\" , src , err ) } if record . Country . ISOCode == \"\" { return \"UNKNOWN\" } return record . Country . ISOCode } func ( g * geoip ) Request ( c filters . FilterContext ) { c . Request (). Header . Set ( g . header , g . lookup ( c . Request ())) } func ( g * geoip ) Response ( c filters . FilterContext ) {} func ( g * geoip ) Match ( r * http . Request ) bool { span := ot . SpanFromContext ( r . Context ()) if span != nil { span . LogKV ( \"GeoIP\" , \"start\" ) } code := g . lookup ( r ) _ , ok := g . countries [ code ] if span != nil { span . LogKV ( \"GeoIP\" , code ) } return ok } OpenTracing plugins \u00b6 The tracers, except for noop , are built as Go Plugins. A tracing plugin can be loaded with -opentracing NAME as parameter to skipper. Implementations of OpenTracing API can be found in the https://github.com/skipper-plugins/opentracing repository. All plugins must have a function named InitTracer with the following signature func([]string) (opentracing.Tracer, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -opentracing parameter. E.g. when the -opentracing parameter is mytracer foo=bar token=xxx somename=bla:3 the \u201cmytracer\u201d plugin will receive []string{\"foo=bar\", \"token=xxx\", \"somename=bla:3\"} as arguments. The tracer plugin implementation is responsible to parse the received arguments. An example plugin looks like package main import ( basic \"github.com/opentracing/basictracer-go\" opentracing \"github.com/opentracing/opentracing-go\" ) func InitTracer ( opts [] string ) ( opentracing . Tracer , error ) { return basic . NewTracerWithOptions ( basic . Options { Recorder : basic . NewInMemoryRecorder (), ShouldSample : func ( traceID uint64 ) bool { return traceID % 64 == 0 }, MaxLogsPerSpan : 25 , }), nil }","title":"Plugins"},{"location":"reference/plugins/#skipper-plugins","text":"Skipper may be extended with functionality not present in the core. These additions can be built as go plugin, so they do not have to be present in the main skipper repository. Note the warning from Go\u2019s plugin.go: // The plugin support is currently incomplete, only supports Linux, // and has known bugs. Please report any issues. Note the known problem of using plugins together with vendoring, best described here: https://github.com/golang/go/issues/20481","title":"Skipper plugins"},{"location":"reference/plugins/#plugin-directories","text":"Plugins are loaded from sub directories of the plugin directories. By default the plugin directory is set to ./plugins (i.e. relative to skipper\u2019s working directory). An additional directory may be given with the -plugindir=/path/to/dir option to skipper. Any file with the suffix .so found below the plugin directories (also in sub directories) is attempted to load without any arguments. When a plugin needs an argument, this must be explicitly loaded and the arguments passed, e.g. with -filter-plugin geoip,db=/path/to/db .","title":"Plugin directories"},{"location":"reference/plugins/#building-a-plugin","text":"Each plugin should be built with Go version >= 1.11, enabled Go modules support similar to the following build command line: GO111MODULE=on go build -buildmode=plugin -o example.so example.go There are some pitfalls: packages which are shared between skipper and the plugin must not be in a vendor/ directory, otherwise the plugin will fail to load or in some cases give wrong results (e.g. an opentracing span cannot be found in the context even if it is present). This also means: Do not vendor skipper in a plugin repo\u2026 plugins must be rebuilt when skipper is rebuilt do not attempt to rebuild a module and copy it over a loaded plugin, that will crash skipper immediately\u2026","title":"Building a plugin"},{"location":"reference/plugins/#use-a-plugin","text":"In this example we use a geoip database, that you need to find and download. We expect that you did a git clone git@github.com:zalando/skipper.git and entered the directory. Build skipper: % make skipper Install filter plugins: % mkdir plugins % git clone git@github.com:skipper-plugins/filters.git plugins/filters % ls plugins/filters geoip / glide . lock glide . yaml ldapauth / Makefile noop / plugin_test . go % cd plugins/filters/geoip % GO111MODULE=on go build -buildmode=plugin -o geoip.so geoip.go % cd - ~/ go / src / github . com / zalando / skipper Start a pseudo backend that shows all headers in plain: % nc -l 9000 Run the proxy with geoip database: % ./bin/skipper -filter-plugin geoip,db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb -inline-routes '* -> geoip() -> \"http://127.0.0.1:9000\"' [ APP ] INFO [ 0000 ] found plugin geoip at plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] loaded plugin geoip ( geoip ) from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] attempting to load plugin from plugins / filters / geoip / geoip . so [ APP ] INFO [ 0000 ] plugin geoip already loaded with InitFilter [ APP ] INFO [ 0000 ] Expose metrics in codahale format [ APP ] INFO [ 0000 ] support listener on : 9911 [ APP ] INFO [ 0000 ] proxy listener on : 9090 [ APP ] INFO [ 0000 ] route settings , reset , route : : * -> geoip () -> \" http : // 127.0 . 0.1 : 9000 \" [ APP ] INFO [ 0000 ] certPathTLS or keyPathTLS not found , defaulting to HTTP [ APP ] INFO [ 0000 ] route settings received [ APP ] INFO [ 0000 ] route settings applied Or passing a yaml file via config-file flag: inline-routes : '* -> geoip() -> \"http://127.0.0.1:9000\"' filter-plugin : geoip : - db=$HOME/Downloads/GeoLite2-City_20181127/GeoLite2-City.mmdb Use a client to lookup geoip: % curl -H\"X-Forwarded-For: 107.12.53.5\" localhost:9090/ ^ C pseudo backend should show X-Geoip-Country header: # nc -l 9000 GET / HTTP/1.1 Host: 127.0.0.1:9000 User-Agent: curl/7.49.0 Accept: */* X-Forwarded-For: 107.12.53.5 X-Geoip-Country: US Accept-Encoding: gzip ^C skipper should show additional log lines, because of the CTRL-C: [APP]ERRO[0082] error while proxying, route with backend http://127.0.0.1:9000, status code 500: dialing failed false: EOF 107.12.53.5 - - [28/Nov/2018:14:39:40 +0100] \"GET / HTTP/1.1\" 500 22 \"-\" \"curl/7.49.0\" 2753 localhost:9090 - -","title":"Use a plugin"},{"location":"reference/plugins/#filter-plugins","text":"All plugins must have a function named InitFilter with the following signature func([]string) (filters.Spec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -filter-plugin parameter. E.g. when the -filter-plugin parameter is myfilter,datafile=/path/to/file,foo=bar the myfilter plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The filter plugin implementation is responsible to parse the received arguments. Filter plugins can be found in the filter repo","title":"Filter plugins"},{"location":"reference/plugins/#example-filter-plugin","text":"An example noop plugin looks like package main import ( \"github.com/zalando/skipper/filters\" ) type noopSpec struct {} func InitFilter ( opts [] string ) ( filters . Spec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"noop\" } func ( s noopSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return noopFilter {}, nil } type noopFilter struct {} func ( f noopFilter ) Request ( filters . FilterContext ) {} func ( f noopFilter ) Response ( filters . FilterContext ) {}","title":"Example filter plugin"},{"location":"reference/plugins/#predicate-plugins","text":"All plugins must have a function named InitPredicate with the following signature func([]string) (routing.PredicateSpec, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -predicate-plugin parameter. E.g. when the -predicate-plugin parameter is mypred,datafile=/path/to/file,foo=bar the mypred plugin will receive []string{\"datafile=/path/to/file\", \"foo=bar\"} as arguments. The predicate plugin implementation is responsible to parse the received arguments. Predicate plugins can be found in the predicate repo","title":"Predicate plugins"},{"location":"reference/plugins/#example-predicate-plugin","text":"An example MatchAll plugin looks like package main import ( \"github.com/zalando/skipper/routing\" \"net/http\" ) type noopSpec struct {} func InitPredicate ( opts [] string ) ( routing . PredicateSpec , error ) { return noopSpec {}, nil } func ( s noopSpec ) Name () string { return \"MatchAll\" } func ( s noopSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { return noopPredicate {}, nil } type noopPredicate struct {} func ( p noopPredicate ) Match ( * http . Request ) bool { return true }","title":"Example predicate plugin"},{"location":"reference/plugins/#dataclient-plugins","text":"Similar to the above predicate and filter plugins. The command line option for data client plugins is -dataclient-plugin . The module must have a InitDataClient function with the signature func([]string) (routing.DataClient, error) A noop data client looks like package main import ( \"github.com/zalando/skipper/eskip\" \"github.com/zalando/skipper/routing\" ) func InitDataClient ([] string ) ( routing . DataClient , error ) { var dc DataClient = \"\" return dc , nil } type DataClient string func ( dc DataClient ) LoadAll () ([] * eskip . Route , error ) { return eskip . Parse ( string ( dc )) } func ( dc DataClient ) LoadUpdate () ([] * eskip . Route , [] string , error ) { return nil , nil , nil }","title":"DataClient plugins"},{"location":"reference/plugins/#multitype-plugins","text":"Sometimes it is necessary to combine multiple plugin types into one module. This can be done with this kind of plugin. Note that these modules are not auto loaded, these need an explicit -multi-plugin name,arg1,arg2 command line switch for skipper. The module must have a InitPlugin function with the signature func([]string) ([]filters.Spec, []routing.PredicateSpec, []routing.DataClient, error) Any of the returned types may be nil, so you can have e.g. a combined filter / data client plugin or share a filter and a predicate, e.g. like package main import ( \"fmt\" \"net\" \"net/http\" \"strconv\" \"strings\" ot \"github.com/opentracing/opentracing-go\" maxminddb \"github.com/oschwald/maxminddb-golang\" \"github.com/zalando/skipper/filters\" snet \"github.com/zalando/skipper/net\" \"github.com/zalando/skipper/predicates\" \"github.com/zalando/skipper/routing\" ) type geoipSpec struct { db * maxminddb . Reader name string } func InitPlugin ( opts [] string ) ([] filters . Spec , [] routing . PredicateSpec , [] routing . DataClient , error ) { var db string for _ , o := range opts { switch { case strings . HasPrefix ( o , \"db=\" ): db = o [ 3 :] } } if db == \"\" { return nil , nil , nil , fmt . Errorf ( \"missing db= parameter for geoip plugin\" ) } reader , err := maxminddb . Open ( db ) if err != nil { return nil , nil , nil , fmt . Errorf ( \"failed to open db %s: %s\" , db , err ) } return [] filters . Spec { & geoipSpec { db : reader , name : \"geoip\" }}, [] routing . PredicateSpec { & geoipSpec { db : reader , name : \"GeoIP\" }}, nil , nil } func ( s * geoipSpec ) Name () string { return s . name } func ( s * geoipSpec ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { var fromLast bool header := \"X-GeoIP-Country\" var err error for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , filters . ErrInvalidFilterParameters } case strings . HasPrefix ( s , \"header=\" ): header = s [ 7 :] } } } return & geoip { db : s . db , fromLast : fromLast , header : header }, nil } func ( s * geoipSpec ) Create ( config [] interface {}) ( routing . Predicate , error ) { var fromLast bool var err error countries := make ( map [ string ] struct {}) for _ , c := range config { if s , ok := c .( string ); ok { switch { case strings . HasPrefix ( s , \"from_last=\" ): fromLast , err = strconv . ParseBool ( s [ 10 :]) if err != nil { return nil , predicates . ErrInvalidPredicateParameters } default : countries [ strings . ToUpper ( s )] = struct {}{} } } } return & geoip { db : s . db , fromLast : fromLast , countries : countries }, nil } type geoip struct { db * maxminddb . Reader fromLast bool header string countries map [ string ] struct {} } type countryRecord struct { Country struct { ISOCode string `maxminddb:\"iso_code\"` } `maxminddb:\"country\"` } func ( g * geoip ) lookup ( r * http . Request ) string { var src net . IP if g . fromLast { src = snet . RemoteHostFromLast ( r ) } else { src = snet . RemoteHost ( r ) } record := countryRecord {} err := g . db . Lookup ( src , & record ) if err != nil { fmt . Printf ( \"geoip(): failed to lookup %s: %s\" , src , err ) } if record . Country . ISOCode == \"\" { return \"UNKNOWN\" } return record . Country . ISOCode } func ( g * geoip ) Request ( c filters . FilterContext ) { c . Request (). Header . Set ( g . header , g . lookup ( c . Request ())) } func ( g * geoip ) Response ( c filters . FilterContext ) {} func ( g * geoip ) Match ( r * http . Request ) bool { span := ot . SpanFromContext ( r . Context ()) if span != nil { span . LogKV ( \"GeoIP\" , \"start\" ) } code := g . lookup ( r ) _ , ok := g . countries [ code ] if span != nil { span . LogKV ( \"GeoIP\" , code ) } return ok }","title":"MultiType plugins"},{"location":"reference/plugins/#opentracing-plugins","text":"The tracers, except for noop , are built as Go Plugins. A tracing plugin can be loaded with -opentracing NAME as parameter to skipper. Implementations of OpenTracing API can be found in the https://github.com/skipper-plugins/opentracing repository. All plugins must have a function named InitTracer with the following signature func([]string) (opentracing.Tracer, error) The parameters passed are all arguments for the plugin, i.e. everything after the first word from skipper\u2019s -opentracing parameter. E.g. when the -opentracing parameter is mytracer foo=bar token=xxx somename=bla:3 the \u201cmytracer\u201d plugin will receive []string{\"foo=bar\", \"token=xxx\", \"somename=bla:3\"} as arguments. The tracer plugin implementation is responsible to parse the received arguments. An example plugin looks like package main import ( basic \"github.com/opentracing/basictracer-go\" opentracing \"github.com/opentracing/opentracing-go\" ) func InitTracer ( opts [] string ) ( opentracing . Tracer , error ) { return basic . NewTracerWithOptions ( basic . Options { Recorder : basic . NewInMemoryRecorder (), ShouldSample : func ( traceID uint64 ) bool { return traceID % 64 == 0 }, MaxLogsPerSpan : 25 , }), nil }","title":"OpenTracing plugins"},{"location":"reference/predicates/","text":"Skipper Predicates \u00b6 Predicates are used to decide which route will handle an incoming request. Routes can contain multiple predicates. A request will match a route only if all the predicates of the route match. See the description of the route matching mechanism here: Route matching . Example route with a Host, Method and Path match predicates and a backend: all : Host (/^ my - host - header \\. example \\. org$ /) && Method(\"GET\") && Path(\"/hello\") -> \"http://127.0.0.1:1234/ \" ; Predicate arguments \u00b6 The predicate arguments can be strings, regular expressions or numbers (float64, int). In the eskip syntax representation: strings are surrounded by double quotes ( \" ). When necessary, characters can be escaped by \\ , e.g. \\\\ or \\\" . regular expressions are a re2 regular expression , surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ . When a predicate expects a regular expression as an argument, the string representation with double quotes can be used, as well. numbers are regular (decimal) numbers like 401 or 1.23456 . The eskip syntax doesn\u2019t define a limitation on the size of the numbers, but the underlying implementation currently relies on the float64 values of the Go runtime. Other higher level argument types must be represented as one of the above types. E.g. it is a convention to represent time duration values as strings, parseable by time.Duration ). The path tree \u00b6 There is an important difference between the evaluation of the Path or PathSubtree predicates, and the evaluation of all the other predicates ( PathRegexp belonging to the second group). Find an explanation in the Route matching section explanation section. Path \u00b6 The path predicate is used to match the path in HTTP request line. It accepts a single argument, that can be a fixed path like \u201c/some/path\u201d, or it can contain wildcards. There can be only zero or one path predicate in a route. Wildcards: Wildcards can be put in place of one or more path segments in the path, e.g. \u201c/some/:dir/:name\u201d, or the path can end with a free wildcard like \"/some/path/*param\" , where the free wildcard can match against a sub-path with multiple segments. Note, that this solution implicitly supports the glob standard, e.g. \"/some/path/**\" will work as expected. The wildcards must follow a / . The arguments are available to the filters while processing the matched requests, but currently only a few built-in filters utilize them, and they can be used rather only from custom filter extensions. Known bug: There is a known bug with how predicates of the form Path(\"/foo/*\") are currently handled. Note the wildcard defined with * doesn\u2019t have a name here. Wildcards must have a name, but Skipper currently does not reject these routes, resulting in undefined behavior. Trailing slash: By default, Path(\"/foo\") and Path(\"/foo/\") are not equivalent. Ignoring the trailing slash can be toggled with the -ignore-trailing-slash command line flag. Examples: Path(\"/foo/bar\") // /foo/bar Path(\"/foo/bar/\") // /foo/bar/, unless started with -ignore-trailing-slash Path(\"/foo/:id\") // /foo/_anything Path(\"/foo/:id/baz\") // /foo/_anything/baz Path(\"/foo/*rest\") // /foo/bar/baz Path(\"/foo/**\") // /foo/bar/baz PathSubtree \u00b6 The path subtree predicate behaves similar to the path predicate, but it matches the exact path in the definition and any sub path below it. The subpath is automatically provided among the path parameters with the name * . If a free wildcard is appended to the definition, e.g. PathSubtree(\"/some/path/*rest\") , the free wildcard name is used instead of * . The simple wildcards behave similar to the Path predicate. The main difference between PathSubtree(\"/foo\") and Path(\"/foo/**\") is that the PathSubtree predicate always ignores the trailing slashes. Examples: PathSubtree(\"/foo/bar\") PathSubtree(\"/\") PathSubtree(\"/foo/*rest\") PathRegexp \u00b6 Regular expressions to match the path. It uses Go\u2019s standard library regexp package to match, which is based on re2 regular expression syntax . Parameters: PathRegexp (regex) A route can contain more than one PathRegexp predicates. It can be also used in combination with the Path predicate. Path(\"/colors/:name/rgb-value\") && PathRegexp(\"^/colors/(red|green|blue|cyan|magenta|pink|yellow)/\") -> returnRGB() -> <shunt> Further examples: PathRegexp(\"^/foo/bar\") PathRegexp(\"/foo/bar$\") PathRegexp(\"/foo/bar/\") PathRegexp(\"^/foo/(bar|qux)\") Host \u00b6 Regular expressions that the host header in the request must match. Parameters: Host (regex) Examples: Host(/^my-host-header\\.example\\.org$/) Host(/header\\.example\\.org$/) Weight (priority) \u00b6 By default, the weight (priority) of a route is determined by the number of defined predicates. If you want to give a route more priority, you can give it more weight. Parameters: Weight (int) Example where route2 has more priority because it has more predicates: route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () -> \"http://www.zalando.de\" ; Example where route1 has more priority because it has more weight: route1 : Path ( \"/test\" ) && Weight ( 100 ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () && True () -> \"http://www.zalando.de\" ; True \u00b6 Does always match. Before Weight predicate existed this was used to give a route more weight. Example where route2 has more weight. route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () -> \"http://www.github.com\" ; False \u00b6 Does not match. Can be used to disable certain routes. Example where route2 is disabled. route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && False () -> \"http://www.github.com\" ; Method \u00b6 The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT. Parameters: Method (string) Examples: Method(\"GET\") Method(\"OPTIONS\") Methods \u00b6 The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT, TRACE. Parameters: Method (\u2026string) methods names Examples: Methods(\"GET\") Methods(\"OPTIONS\", \"POST\") Methods(\"OPTIONS\", \"POST\", \"patch\") Header \u00b6 A header key and exact value that must be present in the request. Note that Header(\u201cKey\u201d, \u201cValue\u201d) is equivalent to HeaderRegexp(\u201cKey\u201d, \u201c^Value$\u201d). Parameters: Header (string, string) Examples: Header(\"X-Forwarded-For\", \"192.168.0.2\") Header(\"Accept\", \"application/json\") HeaderRegexp \u00b6 A header key and a regular expression, where the key must be present in the request and one of the associated values must match the expression. Parameters: HeaderRegexp (string, regex) Examples: HeaderRegexp(\"X-Forwarded-For\", \"^192\\.168\\.0\\.[0-2]?[0-9]?[0-9] \") HeaderRegexp(\"Accept\", \"application/(json|xml)\") Cookie \u00b6 Matches if the specified cookie is set in the request. Parameters: Cookie (string, regex) name and value match Examples: Cookie(\"alpha\", /^enabled$/) Auth \u00b6 Authorization header based match. JWTPayloadAnyKV \u00b6 Match the route if at least one of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\") JWTPayloadAllKV \u00b6 Match the route if all of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\") JWTPayloadAnyKVRegexp, JWTPayloadAllKVRegexp \u00b6 Behaves exactly the same as JWTPayloadAnyKV , JWTPayloadAllKV , but the expected values are regular expressions that will be matched against the JWT value. Examples: JWTPayloadAllKVRegexp(\"iss\", \"^https://\") JWTPayloadAnyKVRegexp(\"iss\", \"^https://\") Interval \u00b6 An interval implements custom predicates to match routes only during some period of time. There are three predicates: Between, Before and After. All predicates can be created using the date represented as a string in RFC3339 format (see https://golang.org/pkg/time/#pkg-constants ), int64 or float64 number. float64 number will be converted into int64 number. After \u00b6 Matches if the request is after the specified time Parameters: After (string) date string After (int) unixtime Examples: After(\"2016-01-01T12:00:00+02:00\") After(1451642400) Before \u00b6 Matches if the request is before the specified time Parameters: Before (string) date string Before (int) unixtime Examples: Before(\"2016-01-01T12:00:00+02:00\") Before(1451642400) Between \u00b6 Matches if the request is between the specified timeframe Parameters: Between (string, string) date string, from - till Between (int, int) unixtime, from - till Examples: Between(\"2016-01-01T12:00:00+02:00\", \"2016-02-01T12:00:00+02:00\") Between(1451642400, 1454320800) Cron \u00b6 Matches routes when the given cron-like expression matches the system time. Parameters: Cron -like expression. See the package documentation for supported & unsupported features. Expressions are expected to be in the same time zone as the system that generates the time.Time instances. Examples: // match everything Cron(\"* * * * *\") // match only when the hour is between 5-7 (inclusive) Cron(\"* 5-7, * * *\") // match only when the hour is between 5-7, equal to 8, or betweeen 12-15 Cron(\"* 5-7,8,12-15 * * *\") // match only when it is weekdays Cron(\"* * * * 1-5\") // match only when it is weekdays & working hours Cron(\"* 7-18 * * 1-5\") QueryParam \u00b6 Match request based on the Query Params in URL Parameters: QueryParam (string) name QueryParam (string, regex) name and value match Examples: // matches http://example.org?bb=a&query=withvalue QueryParam(\"query\") // Even a query param without a value // matches http://example.org?bb=a&query= QueryParam(\"query\") // matches with regexp // matches http://example.org?bb=a&query=example QueryParam(\"query\", \"^example$\") // matches with regexp and multiple values of query param // matches http://example.org?bb=a&query=testing&query=example QueryParam(\"query\", \"^example$\") Source \u00b6 Source implements a custom predicate to match routes based on the source IP or X-Forwarded-For header of a request. Parameters: Source (string, ..) varargs with IPs or CIDR Examples: // only match requests from 1.2.3.4 Source(\"1.2.3.4\") // only match requests from 1.2.3.0 - 1.2.3.255 Source(\"1.2.3.0/24\") // only match requests from 1.2.3.4 and the 2.2.2.0/24 network Source(\"1.2.3.4\", \"2.2.2.0/24\") SourceFromLast \u00b6 The same as Source , but use the last part of the X-Forwarded-For header to match the network. This seems to be only used in the popular loadbalancers from AWS, ELB and ALB, because they put the client-IP as last part of the X-Forwarded-For headers. Parameters: SourceFromLast (string, ..) varargs with IPs or CIDR Examples: SourceFromLast(\"1.2.3.4\", \"2.2.2.0/24\") Tee \u00b6 The Tee predicate matches a route when a request is spawn from the teeLoopback filter as a tee request, using the same provided label. Parameters: tee label (string): the predicate will match only those requests that were spawn from a teeLoopback filter using the same label. See also: teeLoopback filter Shadow Traffic Tutorial Traffic \u00b6 Traffic implements a predicate to control the matching probability for a given route by setting its weight. The probability for matching a route is defined by the mandatory first parameter, that must be a decimal number between 0.0 and 1.0 (both inclusive). The optional second argument is used to specify the cookie name for the traffic group, in case you want to use stickiness. Stickiness allows all subsequent requests from the same client to match the same route. Stickiness of traffic is supported by the optional third parameter, indicating whether the request being matched belongs to the traffic group of the current route. If yes, the predicate matches ignoring the chance argument. Parameters: Traffic (decimal) valid values [0.0, 1.0] Traffic (decimal, string, string) session stickyness Examples: non-sticky: // hit by 10 % percent chance v2 : Traffic ( . 1 ) - > \"https://api-test-green\" ; // hit by remaining chance v1 : * - > \"https://api-test-blue\" ; stickyness: // hit by 5 % percent chance cartTest : Traffic ( . 05 , \"cart-test\" , \"test\" ) && Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"test\" ) - > \"https://cart-test\" ; // hit by remaining chance cart : Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"default\" ) - > \"https://cart\" ; // hit by 15 % percent chance catalogTestA : Traffic ( . 15 , \"catalog-test\" , \"A\" ) - > responseCookie ( \"catalog-test\" , \"A\" ) - > \"https://catalog-test-a\" ; // hit by 30 % percent chance catalogTestB : Traffic ( . 3 , \"catalog-test\" , \"B\" ) - > responseCookie ( \"catalog-test\" , \"B\" ) - > \"https://catalog-test-b\" ; // hit by remaining chance catalog : * - > responseCookie ( \"catalog-test\" , \"default\" ) - > \"https://catalog\" ;","title":"Predicates"},{"location":"reference/predicates/#skipper-predicates","text":"Predicates are used to decide which route will handle an incoming request. Routes can contain multiple predicates. A request will match a route only if all the predicates of the route match. See the description of the route matching mechanism here: Route matching . Example route with a Host, Method and Path match predicates and a backend: all : Host (/^ my - host - header \\. example \\. org$ /) && Method(\"GET\") && Path(\"/hello\") -> \"http://127.0.0.1:1234/ \" ;","title":"Skipper Predicates"},{"location":"reference/predicates/#predicate-arguments","text":"The predicate arguments can be strings, regular expressions or numbers (float64, int). In the eskip syntax representation: strings are surrounded by double quotes ( \" ). When necessary, characters can be escaped by \\ , e.g. \\\\ or \\\" . regular expressions are a re2 regular expression , surrounded by / , e.g. /^www\\.example\\.org(:\\d+)?$/ . When a predicate expects a regular expression as an argument, the string representation with double quotes can be used, as well. numbers are regular (decimal) numbers like 401 or 1.23456 . The eskip syntax doesn\u2019t define a limitation on the size of the numbers, but the underlying implementation currently relies on the float64 values of the Go runtime. Other higher level argument types must be represented as one of the above types. E.g. it is a convention to represent time duration values as strings, parseable by time.Duration ).","title":"Predicate arguments"},{"location":"reference/predicates/#the-path-tree","text":"There is an important difference between the evaluation of the Path or PathSubtree predicates, and the evaluation of all the other predicates ( PathRegexp belonging to the second group). Find an explanation in the Route matching section explanation section.","title":"The path tree"},{"location":"reference/predicates/#path","text":"The path predicate is used to match the path in HTTP request line. It accepts a single argument, that can be a fixed path like \u201c/some/path\u201d, or it can contain wildcards. There can be only zero or one path predicate in a route. Wildcards: Wildcards can be put in place of one or more path segments in the path, e.g. \u201c/some/:dir/:name\u201d, or the path can end with a free wildcard like \"/some/path/*param\" , where the free wildcard can match against a sub-path with multiple segments. Note, that this solution implicitly supports the glob standard, e.g. \"/some/path/**\" will work as expected. The wildcards must follow a / . The arguments are available to the filters while processing the matched requests, but currently only a few built-in filters utilize them, and they can be used rather only from custom filter extensions. Known bug: There is a known bug with how predicates of the form Path(\"/foo/*\") are currently handled. Note the wildcard defined with * doesn\u2019t have a name here. Wildcards must have a name, but Skipper currently does not reject these routes, resulting in undefined behavior. Trailing slash: By default, Path(\"/foo\") and Path(\"/foo/\") are not equivalent. Ignoring the trailing slash can be toggled with the -ignore-trailing-slash command line flag. Examples: Path(\"/foo/bar\") // /foo/bar Path(\"/foo/bar/\") // /foo/bar/, unless started with -ignore-trailing-slash Path(\"/foo/:id\") // /foo/_anything Path(\"/foo/:id/baz\") // /foo/_anything/baz Path(\"/foo/*rest\") // /foo/bar/baz Path(\"/foo/**\") // /foo/bar/baz","title":"Path"},{"location":"reference/predicates/#pathsubtree","text":"The path subtree predicate behaves similar to the path predicate, but it matches the exact path in the definition and any sub path below it. The subpath is automatically provided among the path parameters with the name * . If a free wildcard is appended to the definition, e.g. PathSubtree(\"/some/path/*rest\") , the free wildcard name is used instead of * . The simple wildcards behave similar to the Path predicate. The main difference between PathSubtree(\"/foo\") and Path(\"/foo/**\") is that the PathSubtree predicate always ignores the trailing slashes. Examples: PathSubtree(\"/foo/bar\") PathSubtree(\"/\") PathSubtree(\"/foo/*rest\")","title":"PathSubtree"},{"location":"reference/predicates/#pathregexp","text":"Regular expressions to match the path. It uses Go\u2019s standard library regexp package to match, which is based on re2 regular expression syntax . Parameters: PathRegexp (regex) A route can contain more than one PathRegexp predicates. It can be also used in combination with the Path predicate. Path(\"/colors/:name/rgb-value\") && PathRegexp(\"^/colors/(red|green|blue|cyan|magenta|pink|yellow)/\") -> returnRGB() -> <shunt> Further examples: PathRegexp(\"^/foo/bar\") PathRegexp(\"/foo/bar$\") PathRegexp(\"/foo/bar/\") PathRegexp(\"^/foo/(bar|qux)\")","title":"PathRegexp"},{"location":"reference/predicates/#host","text":"Regular expressions that the host header in the request must match. Parameters: Host (regex) Examples: Host(/^my-host-header\\.example\\.org$/) Host(/header\\.example\\.org$/)","title":"Host"},{"location":"reference/predicates/#weight-priority","text":"By default, the weight (priority) of a route is determined by the number of defined predicates. If you want to give a route more priority, you can give it more weight. Parameters: Weight (int) Example where route2 has more priority because it has more predicates: route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () -> \"http://www.zalando.de\" ; Example where route1 has more priority because it has more weight: route1 : Path ( \"/test\" ) && Weight ( 100 ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () && True () -> \"http://www.zalando.de\" ;","title":"Weight (priority)"},{"location":"reference/predicates/#true","text":"Does always match. Before Weight predicate existed this was used to give a route more weight. Example where route2 has more weight. route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && True () -> \"http://www.github.com\" ;","title":"True"},{"location":"reference/predicates/#false","text":"Does not match. Can be used to disable certain routes. Example where route2 is disabled. route1 : Path ( \"/test\" ) -> \"http://www.zalando.de\" ; route2 : Path ( \"/test\" ) && False () -> \"http://www.github.com\" ;","title":"False"},{"location":"reference/predicates/#method","text":"The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT. Parameters: Method (string) Examples: Method(\"GET\") Method(\"OPTIONS\")","title":"Method"},{"location":"reference/predicates/#methods","text":"The HTTP method that the request must match. HTTP methods are one of GET, HEAD, PATCH, POST, PUT, DELETE, OPTIONS, CONNECT, TRACE. Parameters: Method (\u2026string) methods names Examples: Methods(\"GET\") Methods(\"OPTIONS\", \"POST\") Methods(\"OPTIONS\", \"POST\", \"patch\")","title":"Methods"},{"location":"reference/predicates/#header","text":"A header key and exact value that must be present in the request. Note that Header(\u201cKey\u201d, \u201cValue\u201d) is equivalent to HeaderRegexp(\u201cKey\u201d, \u201c^Value$\u201d). Parameters: Header (string, string) Examples: Header(\"X-Forwarded-For\", \"192.168.0.2\") Header(\"Accept\", \"application/json\")","title":"Header"},{"location":"reference/predicates/#headerregexp","text":"A header key and a regular expression, where the key must be present in the request and one of the associated values must match the expression. Parameters: HeaderRegexp (string, regex) Examples: HeaderRegexp(\"X-Forwarded-For\", \"^192\\.168\\.0\\.[0-2]?[0-9]?[0-9] \") HeaderRegexp(\"Accept\", \"application/(json|xml)\")","title":"HeaderRegexp"},{"location":"reference/predicates/#cookie","text":"Matches if the specified cookie is set in the request. Parameters: Cookie (string, regex) name and value match Examples: Cookie(\"alpha\", /^enabled$/)","title":"Cookie"},{"location":"reference/predicates/#auth","text":"Authorization header based match.","title":"Auth"},{"location":"reference/predicates/#jwtpayloadanykv","text":"Match the route if at least one of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAnyKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\")","title":"JWTPayloadAnyKV"},{"location":"reference/predicates/#jwtpayloadallkv","text":"Match the route if all of the base64 decoded JWT content matches the key value configuration. Parameters: Key-Value pairs (\u2026string), odd index is the key of the JWT content and even index is the value of the JWT content Examples: JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\") JWTPayloadAllKV(\"iss\", \"https://accounts.google.com\", \"email\", \"skipper-router@googlegroups.com\")","title":"JWTPayloadAllKV"},{"location":"reference/predicates/#jwtpayloadanykvregexp-jwtpayloadallkvregexp","text":"Behaves exactly the same as JWTPayloadAnyKV , JWTPayloadAllKV , but the expected values are regular expressions that will be matched against the JWT value. Examples: JWTPayloadAllKVRegexp(\"iss\", \"^https://\") JWTPayloadAnyKVRegexp(\"iss\", \"^https://\")","title":"JWTPayloadAnyKVRegexp, JWTPayloadAllKVRegexp"},{"location":"reference/predicates/#interval","text":"An interval implements custom predicates to match routes only during some period of time. There are three predicates: Between, Before and After. All predicates can be created using the date represented as a string in RFC3339 format (see https://golang.org/pkg/time/#pkg-constants ), int64 or float64 number. float64 number will be converted into int64 number.","title":"Interval"},{"location":"reference/predicates/#after","text":"Matches if the request is after the specified time Parameters: After (string) date string After (int) unixtime Examples: After(\"2016-01-01T12:00:00+02:00\") After(1451642400)","title":"After"},{"location":"reference/predicates/#before","text":"Matches if the request is before the specified time Parameters: Before (string) date string Before (int) unixtime Examples: Before(\"2016-01-01T12:00:00+02:00\") Before(1451642400)","title":"Before"},{"location":"reference/predicates/#between","text":"Matches if the request is between the specified timeframe Parameters: Between (string, string) date string, from - till Between (int, int) unixtime, from - till Examples: Between(\"2016-01-01T12:00:00+02:00\", \"2016-02-01T12:00:00+02:00\") Between(1451642400, 1454320800)","title":"Between"},{"location":"reference/predicates/#cron","text":"Matches routes when the given cron-like expression matches the system time. Parameters: Cron -like expression. See the package documentation for supported & unsupported features. Expressions are expected to be in the same time zone as the system that generates the time.Time instances. Examples: // match everything Cron(\"* * * * *\") // match only when the hour is between 5-7 (inclusive) Cron(\"* 5-7, * * *\") // match only when the hour is between 5-7, equal to 8, or betweeen 12-15 Cron(\"* 5-7,8,12-15 * * *\") // match only when it is weekdays Cron(\"* * * * 1-5\") // match only when it is weekdays & working hours Cron(\"* 7-18 * * 1-5\")","title":"Cron"},{"location":"reference/predicates/#queryparam","text":"Match request based on the Query Params in URL Parameters: QueryParam (string) name QueryParam (string, regex) name and value match Examples: // matches http://example.org?bb=a&query=withvalue QueryParam(\"query\") // Even a query param without a value // matches http://example.org?bb=a&query= QueryParam(\"query\") // matches with regexp // matches http://example.org?bb=a&query=example QueryParam(\"query\", \"^example$\") // matches with regexp and multiple values of query param // matches http://example.org?bb=a&query=testing&query=example QueryParam(\"query\", \"^example$\")","title":"QueryParam"},{"location":"reference/predicates/#source","text":"Source implements a custom predicate to match routes based on the source IP or X-Forwarded-For header of a request. Parameters: Source (string, ..) varargs with IPs or CIDR Examples: // only match requests from 1.2.3.4 Source(\"1.2.3.4\") // only match requests from 1.2.3.0 - 1.2.3.255 Source(\"1.2.3.0/24\") // only match requests from 1.2.3.4 and the 2.2.2.0/24 network Source(\"1.2.3.4\", \"2.2.2.0/24\")","title":"Source"},{"location":"reference/predicates/#sourcefromlast","text":"The same as Source , but use the last part of the X-Forwarded-For header to match the network. This seems to be only used in the popular loadbalancers from AWS, ELB and ALB, because they put the client-IP as last part of the X-Forwarded-For headers. Parameters: SourceFromLast (string, ..) varargs with IPs or CIDR Examples: SourceFromLast(\"1.2.3.4\", \"2.2.2.0/24\")","title":"SourceFromLast"},{"location":"reference/predicates/#tee","text":"The Tee predicate matches a route when a request is spawn from the teeLoopback filter as a tee request, using the same provided label. Parameters: tee label (string): the predicate will match only those requests that were spawn from a teeLoopback filter using the same label. See also: teeLoopback filter Shadow Traffic Tutorial","title":"Tee"},{"location":"reference/predicates/#traffic","text":"Traffic implements a predicate to control the matching probability for a given route by setting its weight. The probability for matching a route is defined by the mandatory first parameter, that must be a decimal number between 0.0 and 1.0 (both inclusive). The optional second argument is used to specify the cookie name for the traffic group, in case you want to use stickiness. Stickiness allows all subsequent requests from the same client to match the same route. Stickiness of traffic is supported by the optional third parameter, indicating whether the request being matched belongs to the traffic group of the current route. If yes, the predicate matches ignoring the chance argument. Parameters: Traffic (decimal) valid values [0.0, 1.0] Traffic (decimal, string, string) session stickyness Examples: non-sticky: // hit by 10 % percent chance v2 : Traffic ( . 1 ) - > \"https://api-test-green\" ; // hit by remaining chance v1 : * - > \"https://api-test-blue\" ; stickyness: // hit by 5 % percent chance cartTest : Traffic ( . 05 , \"cart-test\" , \"test\" ) && Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"test\" ) - > \"https://cart-test\" ; // hit by remaining chance cart : Path ( \"/cart\" ) - > responseCookie ( \"cart-test\" , \"default\" ) - > \"https://cart\" ; // hit by 15 % percent chance catalogTestA : Traffic ( . 15 , \"catalog-test\" , \"A\" ) - > responseCookie ( \"catalog-test\" , \"A\" ) - > \"https://catalog-test-a\" ; // hit by 30 % percent chance catalogTestB : Traffic ( . 3 , \"catalog-test\" , \"B\" ) - > responseCookie ( \"catalog-test\" , \"B\" ) - > \"https://catalog-test-b\" ; // hit by remaining chance catalog : * - > responseCookie ( \"catalog-test\" , \"default\" ) - > \"https://catalog\" ;","title":"Traffic"},{"location":"reference/scripts/","text":"Lua filter scripts \u00b6 LUA scripts can be used as filters in skipper. The current implementation supports Lua 5.1 . Route filters \u00b6 The lua scripts can be added to a route description with the lua() filter, the first parameter for the filter is the script. This can be either a file name (ending with .lua ) or inline code, e.g. as file lua(\"/path/to/file.lua\") - if a file path is not absolute, the path is relative to skipper\u2019s working directory. inline lua(\"function request(c, p); print(c.request.url); end\") Any other additional parameters for the filter must be key=value strings. These will be passed as table to the called functions as second parameter. NOTE : Any parameter starting with \u201clua-\u201d should not be used to pass values for the script - those will be used for configuring the filter. Script requirements \u00b6 A filter script needs at least one global function: request or response . If present, they are called with a skipper filter context and the params passed in the route as table like -- route looks like -- -- any: * -> lua(\"./test.lua\", \"myparam=foo\", \"other=bar\") -> <shunt> -- function request ( ctx , params ) print ( ctx . request . method .. \" \" .. ctx . request . url .. \" -> \" .. params . myparam ) end Available lua modules \u00b6 Besides the standard modules - except for debug - the following modules have been preloaded and can be used with e.g. local http = require(\"http\") , see also the examples below http gluahttp - TODO: configurable with something different than &http.Client{} url gluaurl json gopher-json base64 lua base64 For differences between the standard modules and the gopher-lua implementation check the gopher-lua documentation . Any other module can be loaded in non-byte code form from the lua path (by default for require(\"mod\") this is ./mod.lua , /usr/local/share/lua/5.1/mod.lua and /usr/local/share/lua/5.1/mod/init.lua ). Lua states \u00b6 There is no guarantee that the request() and response() functions of a lua script run in the same lua state during one request. Setting a variable in the request and accessing it in the response will most likely fail and lead to hard debuggable errors. Use the ctx.state_bag to propagate values from request to response - and any other filter in the chain. Request \u00b6 The request() function is run for an incoming request. Headers \u00b6 Request headers can be accessed by accessing the ctx.request.header map like ua = ctx . request . header [ \"user-agent\" ] Header names are normalized by the net/http go module like usual . Setting a header is done by assigning to the headers map. Setting a header to nil or an empty string deletes the header - setting to nil is preferred. ctx . request . header [ \"user-agent\" ] = \"skipper.lua/0.0.1\" ctx . request . header [ \"Authorization\" ] = nil -- delete authorization header Response headers work the same way by accessing / assigning to ctx.response.header - this is of course only valid in the response() phase. Other request fields \u00b6 backend_url - (read only) returns the backend url specified in the route or an empty value in case it\u2019s a shunt or loopback host - (read only) the \u2018Host\u2019 header that was in the incoming request to the proxy outgoing_host - (read/write) the host that will be set for the outgoing proxy request as the \u2018Host\u2019 header. remote_addr - (read only) the remote host, usually IP:port content_length - (read only) content length proto - (read only) something like \u201cHTTP/1.1\u201d method - (read only) request method, e.g. \u201cGET\u201d or \u201cPOST\u201d url - (read/write) request URL as string Serving requests from lua \u00b6 Requests can be served with ctx.serve(table) , you must return after this call. Possible keys for the table: status_code (number) - required (but currently not enforced) header (table) body (string) See also redirect and internal server error examples below StateBag \u00b6 The state bag can be used to pass values from one filter to another in the same chain. It is shared by all filters in one request. function request ( ctx , params ) -- the value of \"mykey\" will be available to all filters in the chain now: ctx . state_bag [ \"mykey\" ] = \"foo\" end function response ( ctx , params ) print ( ctx . state_bag [ \"mykey\" ]) end Examples \u00b6 Note: the examples serve as examples. If there is a go based plugin available, use that instead. The overhead of calling lua is 4-5 times slower than pure go. OAuth2 token as basic auth password \u00b6 local base64 = require ( \"base64\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) user = ctx . request . header [ \"x-username\" ] if user == \"\" then user = params . username end ctx . request . header [ \"Authorization\" ] = \"Basic \" .. base64 . encode ( user .. \":\" .. token ) -- print(ctx.request.header[\"Authorization\"]) end validate token \u00b6 local http = require ( \"http\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) if token == \"\" then ctx . serve ({ status_code = 401 , body = \"Missing Token\" }) return end res , err = http . get ( \"https://auth.example.com/oauth2/tokeninfo?access_token=\" .. token ) if err ~= nil then print ( \"Failed to get tokeninfo: \" .. err ) ctx . serve ({ status_code = 401 , body = \"Failed to validate token: \" .. err }) return end if res . status_code ~= 200 then ctx . serve ({ status_code = 401 , body = \"Invalid token\" }) return end end strip query \u00b6 function request ( ctx , params ) ctx . request . url = string.gsub ( ctx . request . url , \"%?.*$\" , \"\" ) -- print(\"URL=\"..ctx.request.url) end redirect \u00b6 function request ( ctx , params ) ctx . serve ({ status_code = 302 , header = { location = \"http://www.example.org/\" , }, }) end internal server error \u00b6 function request ( ctx , params ) -- let 10% of all requests fail with 500 if math.random () < 0.1 then ctx . serve ({ status_code = 500 , body = \"Internal Server Error. \\n \" , }) end end Benchmark \u00b6 redirectTo vs lua redirect \u00b6 See skptesting/benchmark-lua.sh Route for \u201cskipper\u201d is * -> redirectTo(302, \"http://localhost:9980\") -> <shunt> , route for \u201clua\u201d is * -> lua(\"function request(c,p); c.serve({status_code=302, header={location='http://localhost:9980'}});end\") -> <shunt> [benchmarking skipper-redirectTo] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.91ms 4.87ms 59.40ms 85.80% Req/Sec 24.92k 6.05k 36.78k 60.83% Latency Distribution 50% 1.83ms 75% 6.01ms 90% 10.37ms 99% 21.33ms 596683 requests in 12.04s, 87.07MB read Requests/sec: 49542.84 Transfer/sec: 7.23MB [benchmarking skipper-redirectTo done] [benchmarking redirect-lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 14.86ms 21.87ms 342.03ms 87.17% Req/Sec 10.44k 2.00k 15.07k 67.08% Latency Distribution 50% 4.48ms 75% 22.31ms 90% 42.07ms 99% 98.44ms 250358 requests in 12.05s, 33.90MB read Requests/sec: 20775.38 Transfer/sec: 2.81MB [benchmarking redirect-lua done] The benchmark was run with the default pool size of script.InitialPoolSize = 3; script.MaxPoolSize = 10 . With script.InitialPoolSize = 128; script.MaxPoolSize = 128 (tweaked for this benchmark) you get about 31k req/s in lua: [benchmarking skipper-redirectTo] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.96ms 4.89ms 78.09ms 85.34% Req/Sec 24.45k 3.74k 37.68k 77.92% Latency Distribution 50% 1.78ms 75% 6.13ms 90% 10.57ms 99% 21.11ms 585192 requests in 12.04s, 85.39MB read Requests/sec: 48617.36 Transfer/sec: 7.09MB [benchmarking skipper-redirectTo done] [benchmarking redirect-lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 8.25ms 12.37ms 170.95ms 87.93% Req/Sec 15.82k 1.96k 22.00k 69.33% Latency Distribution 50% 2.80ms 75% 10.20ms 90% 23.99ms 99% 57.44ms 378803 requests in 12.05s, 51.30MB read Requests/sec: 31447.98 Transfer/sec: 4.26MB [benchmarking redirect-lua done] Similar results are achieved when testing stripQuery() vs the lua version from above.","title":"Scripts"},{"location":"reference/scripts/#lua-filter-scripts","text":"LUA scripts can be used as filters in skipper. The current implementation supports Lua 5.1 .","title":"Lua filter scripts"},{"location":"reference/scripts/#route-filters","text":"The lua scripts can be added to a route description with the lua() filter, the first parameter for the filter is the script. This can be either a file name (ending with .lua ) or inline code, e.g. as file lua(\"/path/to/file.lua\") - if a file path is not absolute, the path is relative to skipper\u2019s working directory. inline lua(\"function request(c, p); print(c.request.url); end\") Any other additional parameters for the filter must be key=value strings. These will be passed as table to the called functions as second parameter. NOTE : Any parameter starting with \u201clua-\u201d should not be used to pass values for the script - those will be used for configuring the filter.","title":"Route filters"},{"location":"reference/scripts/#script-requirements","text":"A filter script needs at least one global function: request or response . If present, they are called with a skipper filter context and the params passed in the route as table like -- route looks like -- -- any: * -> lua(\"./test.lua\", \"myparam=foo\", \"other=bar\") -> <shunt> -- function request ( ctx , params ) print ( ctx . request . method .. \" \" .. ctx . request . url .. \" -> \" .. params . myparam ) end","title":"Script requirements"},{"location":"reference/scripts/#available-lua-modules","text":"Besides the standard modules - except for debug - the following modules have been preloaded and can be used with e.g. local http = require(\"http\") , see also the examples below http gluahttp - TODO: configurable with something different than &http.Client{} url gluaurl json gopher-json base64 lua base64 For differences between the standard modules and the gopher-lua implementation check the gopher-lua documentation . Any other module can be loaded in non-byte code form from the lua path (by default for require(\"mod\") this is ./mod.lua , /usr/local/share/lua/5.1/mod.lua and /usr/local/share/lua/5.1/mod/init.lua ).","title":"Available lua modules"},{"location":"reference/scripts/#lua-states","text":"There is no guarantee that the request() and response() functions of a lua script run in the same lua state during one request. Setting a variable in the request and accessing it in the response will most likely fail and lead to hard debuggable errors. Use the ctx.state_bag to propagate values from request to response - and any other filter in the chain.","title":"Lua states"},{"location":"reference/scripts/#request","text":"The request() function is run for an incoming request.","title":"Request"},{"location":"reference/scripts/#headers","text":"Request headers can be accessed by accessing the ctx.request.header map like ua = ctx . request . header [ \"user-agent\" ] Header names are normalized by the net/http go module like usual . Setting a header is done by assigning to the headers map. Setting a header to nil or an empty string deletes the header - setting to nil is preferred. ctx . request . header [ \"user-agent\" ] = \"skipper.lua/0.0.1\" ctx . request . header [ \"Authorization\" ] = nil -- delete authorization header Response headers work the same way by accessing / assigning to ctx.response.header - this is of course only valid in the response() phase.","title":"Headers"},{"location":"reference/scripts/#other-request-fields","text":"backend_url - (read only) returns the backend url specified in the route or an empty value in case it\u2019s a shunt or loopback host - (read only) the \u2018Host\u2019 header that was in the incoming request to the proxy outgoing_host - (read/write) the host that will be set for the outgoing proxy request as the \u2018Host\u2019 header. remote_addr - (read only) the remote host, usually IP:port content_length - (read only) content length proto - (read only) something like \u201cHTTP/1.1\u201d method - (read only) request method, e.g. \u201cGET\u201d or \u201cPOST\u201d url - (read/write) request URL as string","title":"Other request fields"},{"location":"reference/scripts/#serving-requests-from-lua","text":"Requests can be served with ctx.serve(table) , you must return after this call. Possible keys for the table: status_code (number) - required (but currently not enforced) header (table) body (string) See also redirect and internal server error examples below","title":"Serving requests from lua"},{"location":"reference/scripts/#statebag","text":"The state bag can be used to pass values from one filter to another in the same chain. It is shared by all filters in one request. function request ( ctx , params ) -- the value of \"mykey\" will be available to all filters in the chain now: ctx . state_bag [ \"mykey\" ] = \"foo\" end function response ( ctx , params ) print ( ctx . state_bag [ \"mykey\" ]) end","title":"StateBag"},{"location":"reference/scripts/#examples","text":"Note: the examples serve as examples. If there is a go based plugin available, use that instead. The overhead of calling lua is 4-5 times slower than pure go.","title":"Examples"},{"location":"reference/scripts/#oauth2-token-as-basic-auth-password","text":"local base64 = require ( \"base64\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) user = ctx . request . header [ \"x-username\" ] if user == \"\" then user = params . username end ctx . request . header [ \"Authorization\" ] = \"Basic \" .. base64 . encode ( user .. \":\" .. token ) -- print(ctx.request.header[\"Authorization\"]) end","title":"OAuth2 token as basic auth password"},{"location":"reference/scripts/#validate-token","text":"local http = require ( \"http\" ) function request ( ctx , params ) token = string.gsub ( ctx . request . header [ \"Authorization\" ], \"^%s*[Bb]earer%s+\" , \"\" , 1 ) if token == \"\" then ctx . serve ({ status_code = 401 , body = \"Missing Token\" }) return end res , err = http . get ( \"https://auth.example.com/oauth2/tokeninfo?access_token=\" .. token ) if err ~= nil then print ( \"Failed to get tokeninfo: \" .. err ) ctx . serve ({ status_code = 401 , body = \"Failed to validate token: \" .. err }) return end if res . status_code ~= 200 then ctx . serve ({ status_code = 401 , body = \"Invalid token\" }) return end end","title":"validate token"},{"location":"reference/scripts/#strip-query","text":"function request ( ctx , params ) ctx . request . url = string.gsub ( ctx . request . url , \"%?.*$\" , \"\" ) -- print(\"URL=\"..ctx.request.url) end","title":"strip query"},{"location":"reference/scripts/#redirect","text":"function request ( ctx , params ) ctx . serve ({ status_code = 302 , header = { location = \"http://www.example.org/\" , }, }) end","title":"redirect"},{"location":"reference/scripts/#internal-server-error","text":"function request ( ctx , params ) -- let 10% of all requests fail with 500 if math.random () < 0.1 then ctx . serve ({ status_code = 500 , body = \"Internal Server Error. \\n \" , }) end end","title":"internal server error"},{"location":"reference/scripts/#benchmark","text":"","title":"Benchmark"},{"location":"reference/scripts/#redirectto-vs-lua-redirect","text":"See skptesting/benchmark-lua.sh Route for \u201cskipper\u201d is * -> redirectTo(302, \"http://localhost:9980\") -> <shunt> , route for \u201clua\u201d is * -> lua(\"function request(c,p); c.serve({status_code=302, header={location='http://localhost:9980'}});end\") -> <shunt> [benchmarking skipper-redirectTo] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.91ms 4.87ms 59.40ms 85.80% Req/Sec 24.92k 6.05k 36.78k 60.83% Latency Distribution 50% 1.83ms 75% 6.01ms 90% 10.37ms 99% 21.33ms 596683 requests in 12.04s, 87.07MB read Requests/sec: 49542.84 Transfer/sec: 7.23MB [benchmarking skipper-redirectTo done] [benchmarking redirect-lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 14.86ms 21.87ms 342.03ms 87.17% Req/Sec 10.44k 2.00k 15.07k 67.08% Latency Distribution 50% 4.48ms 75% 22.31ms 90% 42.07ms 99% 98.44ms 250358 requests in 12.05s, 33.90MB read Requests/sec: 20775.38 Transfer/sec: 2.81MB [benchmarking redirect-lua done] The benchmark was run with the default pool size of script.InitialPoolSize = 3; script.MaxPoolSize = 10 . With script.InitialPoolSize = 128; script.MaxPoolSize = 128 (tweaked for this benchmark) you get about 31k req/s in lua: [benchmarking skipper-redirectTo] Running 12s test @ http://127.0.0.1:9990/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.96ms 4.89ms 78.09ms 85.34% Req/Sec 24.45k 3.74k 37.68k 77.92% Latency Distribution 50% 1.78ms 75% 6.13ms 90% 10.57ms 99% 21.11ms 585192 requests in 12.04s, 85.39MB read Requests/sec: 48617.36 Transfer/sec: 7.09MB [benchmarking skipper-redirectTo done] [benchmarking redirect-lua] Running 12s test @ http://127.0.0.1:9991/lorem.html 2 threads and 128 connections Thread Stats Avg Stdev Max +/- Stdev Latency 8.25ms 12.37ms 170.95ms 87.93% Req/Sec 15.82k 1.96k 22.00k 69.33% Latency Distribution 50% 2.80ms 75% 10.20ms 90% 23.99ms 99% 57.44ms 378803 requests in 12.05s, 51.30MB read Requests/sec: 31447.98 Transfer/sec: 4.26MB [benchmarking redirect-lua done] Similar results are achieved when testing stripQuery() vs the lua version from above.","title":"redirectTo vs lua redirect"},{"location":"tutorials/auth/","text":"Basic auth \u00b6 Basic Auth is defined in RFC7617 . Install htpasswd command line tool, we assume Debian based system. Please refer the documentation of your Operating System or package management vendor how to install htpasswd : apt-get install apache2-utils Create a htpasswd file foo.passwd and use captain with password apassword : htpasswd -bcB foo.passwd captain apassword Start skipper with a basicAuth filter referencing the just created htpasswd file: ./bin/skipper -address :8080 -inline-routes 'r: * -> basicAuth(\"foo.passwd\") -> status(200) -> <shunt>' A client request without login credentials or wrong credentials: % curl localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 401 Unauthorized < Server : Skipper < Www - Authenticate : Basic realm = \" Basic Realm \" < Date : Thu , 01 Nov 2018 21 : 27 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact A client request with the correct credentials: % curl captain:apassword@localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) * Server auth using Basic with user 'captain' > GET / HTTP / 1.1 > Host : localhost : 8080 > Authorization : Basic Y2FwdGFpbjphcGFzc3dvcmQ = > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Server : Skipper < Date : Thu , 01 Nov 2018 21 : 29 : 21 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact Token service-to-service \u00b6 Service to service authentication and authorization is often done by using the HTTP Authorization header with the content prefix \u201cBearer \u201c, for example \u201cAuthorization: Bearer mytoken\u201d. Supported token formats OAuth2 access tokens JWT Tokeninfo \u00b6 Tokeninfo is a common, but not specified protocol, only supporting Bearer tokens in the Authorization header. In most cases you would have to have your own OAuth2 token infrastructure, that can return JWT or OAuth2 access tokens to authenticated parties and validate tokens with their custom tokeninfo endpoint. In case of JWT the access token is signed and can be validated without a central tokeninfo endpoint. Example route: all : Path ( \"/\" ) -> oauthTokeninfoAnyScope ( \"read-X\" , \"readwrite-X\" ) -> \"http://localhost:9090/\" The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token unchanged as Bearer token in the Authorization header to the Tokeninfo endpoint. The request flow with a Tokeninfo setup is shown in the following picture: Tokenintrospection RFC7662 \u00b6 Tokenintrospection service to service authentication and authorization is specified by RFC7662 . Skipper uses RFC Draft for discovering token infrastructure configuration , to find the introspection_endpoint . Example route: all : * - > oauthTokenintrospectionAnyKV ( \"https://identity.example.com/managed-id\" , \"jdoe\" ) - > \"http://localhost:9090/\" ; The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token as defined in RFC7662 in a POST request \u201capplication/x-www-form-urlencoded\u201d as value for key token to the Tokenintrospection endpoint. The request flow with Tokenintrospection setup is shown in the following picture: OpenID Connect \u00b6 OpenID Connect is an OAuth2.0 based authentication and authorization mechanism supported by several providers. Skipper can act as a proxy for backend server which requires authenticated clients. Skipper handles the authentication with the provider and upon sucessful completion of authentication passes subsequent requests to the backend server. Skipper\u2019s implementation of OpenID Connect Client works as follows: Filter is initialized with the following parameters: Secrets file with keys used for encrypting the token in a cookie and also for generating shared secret. OpenID Connect Provider URL The Client ID The Client Secret The Callback URL for the client when a user successfully authenticates and is returned. The Scopes to be requested along with the openid scope The claims that should be present in the token or the fields need in the user information. The user makes a request to a backend which is covered by an OpenID filter. Skipper checks if a cookie is set with any previous successfully completed OpenID authentication. If the cookie is valid then Skipper passes the request to the backend. If the cookie is not valid then Skipper redirects the user to the OpenID provider with its Client ID and a callback URL. When the user successfully completes authentication the provider redirects the user to the callback URL with a token. Skipper receives this token and makes a backend channel call to get an ID token and other required information. If all the user information/claims are present then it encrypts this and sets a cookie which is encrypted and redirects the user to the originally requested URL. To use OpenID define a filter for a backend which needs to be covered by OpenID Connection authentication. oauthOidcAllClaims ( \"https://accounts.identity-provider.com\" , \"some-client-id\" , \"some-client-secret\" , \"http://callback.com/auth/provider/callback\" , \"scope1 scope2\" , \"claim1 claim2\" ) - > \"https://internal.example.org\" ; Here scope1 scope2 are the scopes that should be included which requesting authentication from the OpenID provider. Any number of scopes can be specified here. The openid scope is added automatically by the filter. The other fields which need to be specified are the URL of the provider which in the above example is https://accounts.identity-provider.com . The client ID and the client secret. The callback URL which is specified while generating the client id and client secret. Then the scopes and finally the claims which should be present along with the return id token. oauthOidcUserInfo ( \"https://oidc-provider.example.com\" , \"client_id\" , \"client_secret\" , \"http://target.example.com/subpath/callback\" , \"email profile\" , \"name email picture\" ) - > \"https://internal.example.org\" ; This filter is similar but it verifies that the token has certain user information information fields accesible with the token return by the provider. The fields can be specified at the end like in the example above where the fields name , email and picture are requested. Upon sucessful authentication Skipper will start allowing the user requests through to the backend. Along with the orginal request to the backend Skipper will include information which it obtained from the provider. The information is in JSON format with the header name Skipper-Oidc-Info . In the case of the claims container the header value is in the format. { \"oauth2token\" : \"xxx\" , \"claims\" : { \"claim1\" : \"val1\" , \"claim2\" : \"val2\" }, \"subject\" : \"subj\" } In the case of a user info filter the payload is in the format: { \"oauth2token\" : \"xxx\" , \"userInfo\" : { \"sub\" : \"sub\" , \"profile\" : \"prof\" , \"email\" : \"abc@example.com\" , \"email_verified\" : \"abc@example.com\" }, \"subject\" : \"subj\" } Skipper encrypts the cookies and also generates a nonce during the OAuth2.0 flow for which it needs a secret key. This key is in a file which can be rotated periodically because it is reread by Skipper. The path to this file can be passed with the flag -oidc-secret-file when Skipper is started. AuthZ and access control \u00b6 Authorization validation and access control is available by means of a subsequent filter oidcClaimsQuery . It inspects the ID token, which exists after a successful oauthOidc* filter step, and validates the defined query with the request path. Given following example ID token: { \"email\" : \"someone@example.org\" , \"groups\" : [ \"CD-xyz\" , \"appX-Tester\" ], \"name\" : \"Some One\" } Access to path / would be granted to everyone in example.org , however path /login only to those being member of group \"appX-Tester\" : oauthOidcAnyClaims(...) -> oidcClaimsQuery(\"/login:groups.#[==\\\"appX-Tester\\\"]\", \"/:@_:email%\\\"*@example.org\\\"\")","title":"Authentication and Autorization"},{"location":"tutorials/auth/#basic-auth","text":"Basic Auth is defined in RFC7617 . Install htpasswd command line tool, we assume Debian based system. Please refer the documentation of your Operating System or package management vendor how to install htpasswd : apt-get install apache2-utils Create a htpasswd file foo.passwd and use captain with password apassword : htpasswd -bcB foo.passwd captain apassword Start skipper with a basicAuth filter referencing the just created htpasswd file: ./bin/skipper -address :8080 -inline-routes 'r: * -> basicAuth(\"foo.passwd\") -> status(200) -> <shunt>' A client request without login credentials or wrong credentials: % curl localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 401 Unauthorized < Server : Skipper < Www - Authenticate : Basic realm = \" Basic Realm \" < Date : Thu , 01 Nov 2018 21 : 27 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact A client request with the correct credentials: % curl captain:apassword@localhost:8080/ -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) * Server auth using Basic with user 'captain' > GET / HTTP / 1.1 > Host : localhost : 8080 > Authorization : Basic Y2FwdGFpbjphcGFzc3dvcmQ = > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Server : Skipper < Date : Thu , 01 Nov 2018 21 : 29 : 21 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Basic auth"},{"location":"tutorials/auth/#token-service-to-service","text":"Service to service authentication and authorization is often done by using the HTTP Authorization header with the content prefix \u201cBearer \u201c, for example \u201cAuthorization: Bearer mytoken\u201d. Supported token formats OAuth2 access tokens JWT","title":"Token service-to-service"},{"location":"tutorials/auth/#tokeninfo","text":"Tokeninfo is a common, but not specified protocol, only supporting Bearer tokens in the Authorization header. In most cases you would have to have your own OAuth2 token infrastructure, that can return JWT or OAuth2 access tokens to authenticated parties and validate tokens with their custom tokeninfo endpoint. In case of JWT the access token is signed and can be validated without a central tokeninfo endpoint. Example route: all : Path ( \"/\" ) -> oauthTokeninfoAnyScope ( \"read-X\" , \"readwrite-X\" ) -> \"http://localhost:9090/\" The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token unchanged as Bearer token in the Authorization header to the Tokeninfo endpoint. The request flow with a Tokeninfo setup is shown in the following picture:","title":"Tokeninfo"},{"location":"tutorials/auth/#tokenintrospection-rfc7662","text":"Tokenintrospection service to service authentication and authorization is specified by RFC7662 . Skipper uses RFC Draft for discovering token infrastructure configuration , to find the introspection_endpoint . Example route: all : * - > oauthTokenintrospectionAnyKV ( \"https://identity.example.com/managed-id\" , \"jdoe\" ) - > \"http://localhost:9090/\" ; The access token should be passed from the client as Bearer token in the Authorization header. Skipper will send this token as defined in RFC7662 in a POST request \u201capplication/x-www-form-urlencoded\u201d as value for key token to the Tokenintrospection endpoint. The request flow with Tokenintrospection setup is shown in the following picture:","title":"Tokenintrospection RFC7662"},{"location":"tutorials/auth/#openid-connect","text":"OpenID Connect is an OAuth2.0 based authentication and authorization mechanism supported by several providers. Skipper can act as a proxy for backend server which requires authenticated clients. Skipper handles the authentication with the provider and upon sucessful completion of authentication passes subsequent requests to the backend server. Skipper\u2019s implementation of OpenID Connect Client works as follows: Filter is initialized with the following parameters: Secrets file with keys used for encrypting the token in a cookie and also for generating shared secret. OpenID Connect Provider URL The Client ID The Client Secret The Callback URL for the client when a user successfully authenticates and is returned. The Scopes to be requested along with the openid scope The claims that should be present in the token or the fields need in the user information. The user makes a request to a backend which is covered by an OpenID filter. Skipper checks if a cookie is set with any previous successfully completed OpenID authentication. If the cookie is valid then Skipper passes the request to the backend. If the cookie is not valid then Skipper redirects the user to the OpenID provider with its Client ID and a callback URL. When the user successfully completes authentication the provider redirects the user to the callback URL with a token. Skipper receives this token and makes a backend channel call to get an ID token and other required information. If all the user information/claims are present then it encrypts this and sets a cookie which is encrypted and redirects the user to the originally requested URL. To use OpenID define a filter for a backend which needs to be covered by OpenID Connection authentication. oauthOidcAllClaims ( \"https://accounts.identity-provider.com\" , \"some-client-id\" , \"some-client-secret\" , \"http://callback.com/auth/provider/callback\" , \"scope1 scope2\" , \"claim1 claim2\" ) - > \"https://internal.example.org\" ; Here scope1 scope2 are the scopes that should be included which requesting authentication from the OpenID provider. Any number of scopes can be specified here. The openid scope is added automatically by the filter. The other fields which need to be specified are the URL of the provider which in the above example is https://accounts.identity-provider.com . The client ID and the client secret. The callback URL which is specified while generating the client id and client secret. Then the scopes and finally the claims which should be present along with the return id token. oauthOidcUserInfo ( \"https://oidc-provider.example.com\" , \"client_id\" , \"client_secret\" , \"http://target.example.com/subpath/callback\" , \"email profile\" , \"name email picture\" ) - > \"https://internal.example.org\" ; This filter is similar but it verifies that the token has certain user information information fields accesible with the token return by the provider. The fields can be specified at the end like in the example above where the fields name , email and picture are requested. Upon sucessful authentication Skipper will start allowing the user requests through to the backend. Along with the orginal request to the backend Skipper will include information which it obtained from the provider. The information is in JSON format with the header name Skipper-Oidc-Info . In the case of the claims container the header value is in the format. { \"oauth2token\" : \"xxx\" , \"claims\" : { \"claim1\" : \"val1\" , \"claim2\" : \"val2\" }, \"subject\" : \"subj\" } In the case of a user info filter the payload is in the format: { \"oauth2token\" : \"xxx\" , \"userInfo\" : { \"sub\" : \"sub\" , \"profile\" : \"prof\" , \"email\" : \"abc@example.com\" , \"email_verified\" : \"abc@example.com\" }, \"subject\" : \"subj\" } Skipper encrypts the cookies and also generates a nonce during the OAuth2.0 flow for which it needs a secret key. This key is in a file which can be rotated periodically because it is reread by Skipper. The path to this file can be passed with the flag -oidc-secret-file when Skipper is started.","title":"OpenID Connect"},{"location":"tutorials/auth/#authz-and-access-control","text":"Authorization validation and access control is available by means of a subsequent filter oidcClaimsQuery . It inspects the ID token, which exists after a successful oauthOidc* filter step, and validates the defined query with the request path. Given following example ID token: { \"email\" : \"someone@example.org\" , \"groups\" : [ \"CD-xyz\" , \"appX-Tester\" ], \"name\" : \"Some One\" } Access to path / would be granted to everyone in example.org , however path /login only to those being member of group \"appX-Tester\" : oauthOidcAnyClaims(...) -> oidcClaimsQuery(\"/login:groups.#[==\\\"appX-Tester\\\"]\", \"/:@_:email%\\\"*@example.org\\\"\")","title":"AuthZ and access control"},{"location":"tutorials/basics/","text":"Architecture \u00b6 The core business of skipper is routing based on HTTP. It performs and scales well, for example it handles more than 800000 routes in production with 60000 requests per second. Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example local routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target backend must be set in a filter. Opentracing API is supported via tracers and you can find all of them in ./tracing/tracers/ . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can also be exported in Prometheus format. Concepts \u00b6 Route definition \u00b6 A route consists of an ID, predicates, filters and a backend and is most often written in eskip syntax . Syntax: ID : Predicate1 () && .. && PredicateN () -> filter1 () ... -> filterN () -> BACKEND An example routing configuration: baidu : Path ( \"/baidu\" ) -> setRequestHeader ( \"Host\" , \"www.baidu.com\" ) -> setPath ( \"/s\" ) -> setQuery ( \"wd\" , \"godoc skipper\" ) -> \"http://www.baidu.com\" ; google : * -> setPath ( \"/search\" ) -> setQuery ( \"q\" , \"godoc skipper\" ) -> \"https://www.google.com\" ; yandex : * && Cookie ( \"yandex\" , \"true\" ) -> setPath ( \"/search/\" ) -> setQuery ( \"text\" , \"godoc skipper\" ) -> tee ( \"http://127.0.0.1:12345/\" ) -> \"https://yandex.ru\" ; Predicate \u00b6 A Predicate adds a matching rule to a route. For example the Cookie predicate, Cookie(\"yandex\", \"true\") , matched if there is a cookie in the request with name \u201cyandex\u201d and the value is \u201ctrue\u201d, else the route processing will go on and try to find another matching route for the given request. Multiple predicates can be combined by && which means a logical AND . If you need a logical OR , you have to create another route. Special Predicates: * catch all is always true Path() reduces the number of routes in O(log n) time to scan afterwards a subset in linear time PathSubtree() reduces the number of routes O(log n) time to scan afterwards a subset in linear time Predicate and routing table \u00b6 A routing table consists of a number of routes. A route has a list of predicates and filters. Predicates match an incoming request to a specific, best matching, route. Each route has a set of filters. Filter \u00b6 A filter changes a HTTP request or response or both. Multiple filters can be concatenated by -> . Some special filters are: inlineContent() sets the HTTP response body, should be used with status() filter and backend static() serves static files and should be used with backend status() sets HTTP status code to a given value, should be used with backend tee() clones request to given target Filter in context of an HTTP request \u00b6 The picture shows the transformation of the requests and responses Backend \u00b6 The last entry of a route is the backend definition, that will be called with the result request after filter processing. Normally this is an URL string. Special backends: <loopback> restart route processing with the possibly changed request <shunt> stops processing, used for fast returns <dynamic> target is set dynamically in a filter <$algorithm, \"be1\", \"be2\", ..., \"beN\"> load balanced backend with N backends See more about backends in backend references . Dataclient \u00b6 Dataclients are used to pull route information from a data source. The data will be used to create routes according to the dataclient. As a special case, for example kubernetes dataclient automatically adds HTTP->HTTPS redirects if skipper is started with -kubernetes-https-redirect . Dataclients: eskip-file route string kubernetes etcd Route processing \u00b6 Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. In case it will always find a <loopback> route it will stop after maximum number of loopbacks is reached and logs an error. Routing mechanism \u00b6 The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response. Route matching \u00b6 Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the highest weight is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one. See more details about the predicates here: Predicates . Building skipper \u00b6 We use Go modules to build skipper, therefore you need Go version >= 1.11 . Local build \u00b6 To get a local build of skipper for your CPU architecture, you can run make skipper . To cross compile to non Linux platforms you can use: make build.osx for Mac OS X (amd64) make build.windows for Windows (amd64) The local build will write into ./bin/ directory. CI build \u00b6 The current used CI flow to build the official docker container, you can see in delivery.yaml . Official release versions you will find at registry.opensource.zalan.do/pathfinder/skipper:${RELEASE_VERSION} , where ${RELEASE_VERSION} is the git tag got by $(git describe --tags --always --dirty) . Test versions are released at registry.opensource.zalan.do/pathfinder/skipper-test:${CDP_BUILD_VERSION} for every pull request, limited to only repository members, because of compliance and security reasons. Testing routes \u00b6 To test routes you can use a local build of skipper and pass arguments -inline-routes=<route string> or for more complex ones use a local eskip file on disk and use -routes-file=<filepath> . Example: ./bin/skipper -address :9999 -inline-routes 'r: * -> setQuery(\"lang\", \"pt\") -> \"http://127.0.0.1:8080/\"' Now you have a proxy running that will set a query to your request URL and call http://127.0.0.1:8080/?lang=pt The simplest way of testing a proxy is using a local backend and a local browser. Local backend example: ./bin/skipper -address :8080 -inline-routes 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' If you want to do the request and see the response in detail, you can use curl as a browser, which should be installed on most Linux and Mac OS X computers. Example client call to our defined proxy: % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Content - Length : 12 < Content - Type : text / plain ; charset = utf - 8 < Server : Skipper < Date : Thu , 01 Nov 2018 15 : 54 : 13 GMT < * Connection # 0 to host localhost left intact Hello world ! YAML Configuration \u00b6 The usage of flags to configure the skipper binary can get quickly out of hand. You can use a yaml file instead to populate the flags presented in the skipper -help command. kubernetes : true kubernetes-in-cluster : true kubernetes-https-redirect : true proxy-preserve-host : true serve-host-metrics : true address : \":8080\" enable-ratelimits : true experimental-upgrade : true metrics-exp-decay-sample : true lb-healthcheck-interval : \"3s\" metrics-flavour : [ \"codahale\" , \"prometheus\" ] enable-connection-metrics : true whitelisted-healthcheck-cidr : \"172.20.0.0/16\" ignore-trailing-slash : true inline-routes : 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' Considering that this file would be named config.yaml you can use it to populate the flags using the config-file flag: ./bin/skipper -config-file=config.yaml Performing the same call to the address as exemplified in the previous section should yield the same results. Current routing table \u00b6 To investigate the current routing table skipper has loaded into its memory, you can use the -support-listener , which defaults to port 9911 and you have to do a GET request to the /routes endpoint. Example: % curl localhost:9911/routes r : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If you do not see your route, then you have most probably a syntax error in your route definition, such that the route was not loaded into memory. To print the number of routes, X-Count header, and the last update timestamp, X-Timestamp header, you can use a HEAD request to the support listener /routes endpoint: % curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1541086036 Date: Fri, 02 Nov 2018 00 :30:43 GMT For skipper operators the number of routes can be interesting for statistics and the timestamp to detect skipper instances that have not updated its routing table. If there is more than 1024 routes used, then the paging the results is possible with the offset and limit query parameters: curl locahost:9911/routes?offset=2048&limit=512 Route IDs \u00b6 In the following example rid is the route ID: % curl localhost:9911/routes rid : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If the route ID has a prefix kube_ , then it is a route created by the Kubernetes dataclient. We do not disallow that you create manually routes with kube_ prefix, but most of the time you should not use it in other routes to differentiate the routes created by other dataclients, in case you use multiple at the same time.","title":"Basics"},{"location":"tutorials/basics/#architecture","text":"The core business of skipper is routing based on HTTP. It performs and scales well, for example it handles more than 800000 routes in production with 60000 requests per second. Skipper is written as a library and is also a multi binary project with 2 binaries, named skipper and eskip . Skipper is the HTTP proxy and eskip is a CLI application to verify, print, update or delete Skipper routes. Skipper\u2019s internal architecture is split into different packages. The skipper package has connections to multiple dataclient , that pull information from different sources, for example local routes from an eskip file or dynamic routes from Kubernetes ingress objects. The proxy package gets the routes populated by skipper and has always a current routing table which will be replaced on change. A route is one entry in the routing table. A route consists of one or more predicate , that are used to find a route for a given HTTP request. A route can also have one or more filter , that can modify the content of the request or response. A route can point to a backend, it can be a <shunt> , meaning that skipper serves the requests for the route, a <loopback> , meaning that the requests will be matched against the routing table again after filters have modified them, or a <dynamic> , meaning that the target backend must be set in a filter. Opentracing API is supported via tracers and you can find all of them in ./tracing/tracers/ . For example Jaeger is supported. Skipper has a rich set of metrics that are exposed as json, but can also be exported in Prometheus format.","title":"Architecture"},{"location":"tutorials/basics/#concepts","text":"","title":"Concepts"},{"location":"tutorials/basics/#route-definition","text":"A route consists of an ID, predicates, filters and a backend and is most often written in eskip syntax . Syntax: ID : Predicate1 () && .. && PredicateN () -> filter1 () ... -> filterN () -> BACKEND An example routing configuration: baidu : Path ( \"/baidu\" ) -> setRequestHeader ( \"Host\" , \"www.baidu.com\" ) -> setPath ( \"/s\" ) -> setQuery ( \"wd\" , \"godoc skipper\" ) -> \"http://www.baidu.com\" ; google : * -> setPath ( \"/search\" ) -> setQuery ( \"q\" , \"godoc skipper\" ) -> \"https://www.google.com\" ; yandex : * && Cookie ( \"yandex\" , \"true\" ) -> setPath ( \"/search/\" ) -> setQuery ( \"text\" , \"godoc skipper\" ) -> tee ( \"http://127.0.0.1:12345/\" ) -> \"https://yandex.ru\" ;","title":"Route definition"},{"location":"tutorials/basics/#predicate","text":"A Predicate adds a matching rule to a route. For example the Cookie predicate, Cookie(\"yandex\", \"true\") , matched if there is a cookie in the request with name \u201cyandex\u201d and the value is \u201ctrue\u201d, else the route processing will go on and try to find another matching route for the given request. Multiple predicates can be combined by && which means a logical AND . If you need a logical OR , you have to create another route. Special Predicates: * catch all is always true Path() reduces the number of routes in O(log n) time to scan afterwards a subset in linear time PathSubtree() reduces the number of routes O(log n) time to scan afterwards a subset in linear time","title":"Predicate"},{"location":"tutorials/basics/#predicate-and-routing-table","text":"A routing table consists of a number of routes. A route has a list of predicates and filters. Predicates match an incoming request to a specific, best matching, route. Each route has a set of filters.","title":"Predicate and routing table"},{"location":"tutorials/basics/#filter","text":"A filter changes a HTTP request or response or both. Multiple filters can be concatenated by -> . Some special filters are: inlineContent() sets the HTTP response body, should be used with status() filter and backend static() serves static files and should be used with backend status() sets HTTP status code to a given value, should be used with backend tee() clones request to given target","title":"Filter"},{"location":"tutorials/basics/#filter-in-context-of-an-http-request","text":"The picture shows the transformation of the requests and responses","title":"Filter in context of an HTTP request"},{"location":"tutorials/basics/#backend","text":"The last entry of a route is the backend definition, that will be called with the result request after filter processing. Normally this is an URL string. Special backends: <loopback> restart route processing with the possibly changed request <shunt> stops processing, used for fast returns <dynamic> target is set dynamically in a filter <$algorithm, \"be1\", \"be2\", ..., \"beN\"> load balanced backend with N backends See more about backends in backend references .","title":"Backend"},{"location":"tutorials/basics/#dataclient","text":"Dataclients are used to pull route information from a data source. The data will be used to create routes according to the dataclient. As a special case, for example kubernetes dataclient automatically adds HTTP->HTTPS redirects if skipper is started with -kubernetes-https-redirect . Dataclients: eskip-file route string kubernetes etcd","title":"Dataclient"},{"location":"tutorials/basics/#route-processing","text":"Package skipper has a Go http.Server and does the ListenAndServe call with the loggingHandler wrapped proxy . The loggingHandler is basically a middleware for the proxy providing access logs and both implement the plain Go http.Handler interface . For each incoming http.Request the proxy will create a request context and enhance it with an Opentracing API Span. It will check proxy global ratelimits first and after that lookup the route in the routing table. After that skipper will apply all request filters, that can modify the http.Request . It will then check the route local ratelimits, the circuitbreakers and do the backend call. If the backend call got a TCP or TLS connection error in a loadbalanced route, skipper will do a retry to another backend of that loadbalanced group automatically. Just before the response to the caller, skipper will process the response filters, that can change the http.Response . In two special cases, skipper doesn\u2019t forward the request to the backend. When the route is shunted ( <shunt> ), skipper serves the request alone, by using only the filters. When the route is a <loopback> , the request is passed to the routing table for finding another route, based on the changes that the filters made to the request. In case it will always find a <loopback> route it will stop after maximum number of loopbacks is reached and logs an error.","title":"Route processing"},{"location":"tutorials/basics/#routing-mechanism","text":"The routing executes the following steps in the typical case: Select the best fitting route by matching the request against the predicates. When no route found, respond with 404 (unless the default status code is configured to a different value). Execute the filters defined in the route in normal order on the request. The filters may or may not alter the request. Forward the request to the backend defined by the route and receive a response. Execute the filters defined in the route in reverse order on the response. The filters may or may not alter the response. Respond to the incoming request with the resulting response.","title":"Routing mechanism"},{"location":"tutorials/basics/#route-matching","text":"Skipper can handle a relatively large number of routes with acceptable performance, while being able to use any attribute of the incoming HTTP requests to distinguish between them. In order to be able to do so, the path matching predicates ( Path() and PathSubtree() but not PathRegexp() ) have a special role during route matching, which is a tradeoff by design, and needs to be kept in mind to understand in some cases why a certain route was matched for a request instead of another. The route matching logic can be summed up as follows: Lookup in the path tree based on the Path() and the PathSubtree() predicates, using the path component of the incoming request\u2019s URI. Then the remaining predicates of the found route(s) are evaluated. the path lookup is a radix tree with O(log(n)) time complexity in case of intersecting paths, the more specific path is matched in the tree PathRegexp() is not used in the tree, but it is evaluated only after Path() or PathSubtree() , just like e.g. Method() or Host() . If step #1 matches multiple routes, which means there are multiple routes in the same position of the path tree, and all other predicates match the request, too, then the route with the highest weight is matched. this is an O(n) lookup, but only on the same leaf the root of the tree is considered a single leaf, so if not using the Path() or PathSubtree() predicates, the entire lookup will become O(n) over all the routes. If #2 results in multiple matching routes, then one route will be selected. It is unspecified which one. See more details about the predicates here: Predicates .","title":"Route matching"},{"location":"tutorials/basics/#building-skipper","text":"We use Go modules to build skipper, therefore you need Go version >= 1.11 .","title":"Building skipper"},{"location":"tutorials/basics/#local-build","text":"To get a local build of skipper for your CPU architecture, you can run make skipper . To cross compile to non Linux platforms you can use: make build.osx for Mac OS X (amd64) make build.windows for Windows (amd64) The local build will write into ./bin/ directory.","title":"Local build"},{"location":"tutorials/basics/#ci-build","text":"The current used CI flow to build the official docker container, you can see in delivery.yaml . Official release versions you will find at registry.opensource.zalan.do/pathfinder/skipper:${RELEASE_VERSION} , where ${RELEASE_VERSION} is the git tag got by $(git describe --tags --always --dirty) . Test versions are released at registry.opensource.zalan.do/pathfinder/skipper-test:${CDP_BUILD_VERSION} for every pull request, limited to only repository members, because of compliance and security reasons.","title":"CI build"},{"location":"tutorials/basics/#testing-routes","text":"To test routes you can use a local build of skipper and pass arguments -inline-routes=<route string> or for more complex ones use a local eskip file on disk and use -routes-file=<filepath> . Example: ./bin/skipper -address :9999 -inline-routes 'r: * -> setQuery(\"lang\", \"pt\") -> \"http://127.0.0.1:8080/\"' Now you have a proxy running that will set a query to your request URL and call http://127.0.0.1:8080/?lang=pt The simplest way of testing a proxy is using a local backend and a local browser. Local backend example: ./bin/skipper -address :8080 -inline-routes 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' If you want to do the request and see the response in detail, you can use curl as a browser, which should be installed on most Linux and Mac OS X computers. Example client call to our defined proxy: % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 200 OK < Content - Length : 12 < Content - Type : text / plain ; charset = utf - 8 < Server : Skipper < Date : Thu , 01 Nov 2018 15 : 54 : 13 GMT < * Connection # 0 to host localhost left intact Hello world !","title":"Testing routes"},{"location":"tutorials/basics/#yaml-configuration","text":"The usage of flags to configure the skipper binary can get quickly out of hand. You can use a yaml file instead to populate the flags presented in the skipper -help command. kubernetes : true kubernetes-in-cluster : true kubernetes-https-redirect : true proxy-preserve-host : true serve-host-metrics : true address : \":8080\" enable-ratelimits : true experimental-upgrade : true metrics-exp-decay-sample : true lb-healthcheck-interval : \"3s\" metrics-flavour : [ \"codahale\" , \"prometheus\" ] enable-connection-metrics : true whitelisted-healthcheck-cidr : \"172.20.0.0/16\" ignore-trailing-slash : true inline-routes : 'r: * -> inlineContent(\"Hello world!\") -> status(200) -> <shunt>' Considering that this file would be named config.yaml you can use it to populate the flags using the config-file flag: ./bin/skipper -config-file=config.yaml Performing the same call to the address as exemplified in the previous section should yield the same results.","title":"YAML Configuration"},{"location":"tutorials/basics/#current-routing-table","text":"To investigate the current routing table skipper has loaded into its memory, you can use the -support-listener , which defaults to port 9911 and you have to do a GET request to the /routes endpoint. Example: % curl localhost:9911/routes r : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If you do not see your route, then you have most probably a syntax error in your route definition, such that the route was not loaded into memory. To print the number of routes, X-Count header, and the last update timestamp, X-Timestamp header, you can use a HEAD request to the support listener /routes endpoint: % curl -I localhost:9911/routes HTTP/1.1 200 OK Content-Type: text/plain X-Count: 1 X-Timestamp: 1541086036 Date: Fri, 02 Nov 2018 00 :30:43 GMT For skipper operators the number of routes can be interesting for statistics and the timestamp to detect skipper instances that have not updated its routing table. If there is more than 1024 routes used, then the paging the results is possible with the offset and limit query parameters: curl locahost:9911/routes?offset=2048&limit=512","title":"Current routing table"},{"location":"tutorials/basics/#route-ids","text":"In the following example rid is the route ID: % curl localhost:9911/routes rid : * -> setQuery ( \" lang \" , \" pt \" ) -> \" http : // 127.0 . 0.1 : 8000 \" ; If the route ID has a prefix kube_ , then it is a route created by the Kubernetes dataclient. We do not disallow that you create manually routes with kube_ prefix, but most of the time you should not use it in other routes to differentiate the routes created by other dataclients, in case you use multiple at the same time.","title":"Route IDs"},{"location":"tutorials/common-use-cases/","text":"Common Use Cases \u00b6 To understand common use cases, we assume you read the basics . Redirect handling \u00b6 If you want to do a redirect from a route, you can use the redirectTo() filter in combination with the <shunt> backend. If you do not specify a path in your redirect, then the path from the client will be passed further and not modified by the redirect. Example: % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 02 + 0100 ] \" GET / HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 08 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 14 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact set absolute path \u00b6 If you set a path, in this example / , in your redirect definition, then the path is set to the chosen value. The Location header is set in the response to / , but the client sent /foo . % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999/\") -> <shunt>' % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 47 : 17 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact change base path \u00b6 If you want a redirect definition that adds a base path and the specified path by the client should be appended to this base path you can use the modPath filter just before the redirectTo() to modify the base path as you like. Route Example shows, that calls to /a/base/foo/bar would be redirected to https://another-example.com/my/new/base/foo/bar : redirect : Path ( \"/a/base/\" ) -> modPath ( \"/a/base/\" , \"/my/new/base/\" ) -> redirectTo ( 308 , \"https://another-example.com\" ) -> < shunt > ' The next example shows how to test a redirect with changed base path on your computer: % ./bin/skipper -address :8080 -inline-routes 'r: * -> modPath(\"/\", \"/my/new/base/\") -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 49 : 45 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / my / new / base / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 49 : 45 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Common Use Cases"},{"location":"tutorials/common-use-cases/#common-use-cases","text":"To understand common use cases, we assume you read the basics .","title":"Common Use Cases"},{"location":"tutorials/common-use-cases/#redirect-handling","text":"If you want to do a redirect from a route, you can use the redirectTo() filter in combination with the <shunt> backend. If you do not specify a path in your redirect, then the path from the client will be passed further and not modified by the redirect. Example: % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 02 + 0100 ] \" GET / HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - :: 1 - - [ 01 / Nov / 2018 : 18 : 42 : 08 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080 -v * Rebuilt URL to : localhost : 8080 / * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 18 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 42 : 14 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"Redirect handling"},{"location":"tutorials/common-use-cases/#set-absolute-path","text":"If you set a path, in this example / , in your redirect definition, then the path is set to the chosen value. The Location header is set in the response to / , but the client sent /foo . % ./bin/skipper -address :8080 -inline-routes 'r: * -> redirectTo(308, \"http://127.0.0.1:9999/\") -> <shunt>' % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 47 : 17 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"set absolute path"},{"location":"tutorials/common-use-cases/#change-base-path","text":"If you want a redirect definition that adds a base path and the specified path by the client should be appended to this base path you can use the modPath filter just before the redirectTo() to modify the base path as you like. Route Example shows, that calls to /a/base/foo/bar would be redirected to https://another-example.com/my/new/base/foo/bar : redirect : Path ( \"/a/base/\" ) -> modPath ( \"/a/base/\" , \"/my/new/base/\" ) -> redirectTo ( 308 , \"https://another-example.com\" ) -> < shunt > ' The next example shows how to test a redirect with changed base path on your computer: % ./bin/skipper -address :8080 -inline-routes 'r: * -> modPath(\"/\", \"/my/new/base/\") -> redirectTo(308, \"http://127.0.0.1:9999\") -> <shunt>' :: 1 - - [ 01 / Nov / 2018 : 18 : 49 : 45 + 0100 ] \" GET / foo HTTP / 1.1 \" 308 0 \" - \" \" curl / 7.49 . 0 \" 0 localhost : 8080 - - % curl localhost:8080/foo -v * Trying :: 1. .. * Connected to localhost (:: 1 ) port 8080 ( # 0 ) > GET / foo HTTP / 1.1 > Host : localhost : 8080 > User - Agent : curl / 7.49 . 0 > Accept : */* > < HTTP / 1.1 308 Permanent Redirect < Location : http : // 127.0 . 0.1 : 9999 / my / new / base / foo < Server : Skipper < Date : Thu , 01 Nov 2018 17 : 49 : 45 GMT < Content - Length : 0 < * Connection # 0 to host localhost left intact","title":"change base path"},{"location":"tutorials/development/","text":"Docs \u00b6 We have user documentation and developer documentation separated. In docs/ you find the user documentation in mkdocs format and rendered at https://opensource.zalando.com/skipper . Developer documentation for skipper as library users godoc format is used and rendered at https://godoc.org/github.com/zalando/skipper . User documentation \u00b6 local Preview \u00b6 To see rendered documentation locally you need to replace /skipper path with / to see them correctly. This you can easily do with skipper in front of mkdocs serve . The following skipper inline route will do this for you, assuming that you build skipper with make skipper : ./bin/skipper -inline-routes 'r: * -> modPath(\"/skipper\", \"\") -> \"http://127.0.0.1:8000\"' Now you should be able to see the documentation at http://127.0.0.1:9090 . Filters \u00b6 Filters allow to change arbitrary HTTP data in the Request or Response. If you need to read and write the http.Body, please make sure you discuss the use case before creating a pull request. A filter consists of at least two types a filters.Spec and a filters.Filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the filters.Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the filter.Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. The simplest filter possible is, if filters.Spec and filters.Filter are the same type: type myFilter struct {} func NewMyFilter () filters . Spec { return & myFilter {} } func ( spec * myFilter ) Name () string { return \"myFilter\" } func ( spec * myFilter ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return NewMyFilter (), nil } func ( f * myFilter ) Request ( ctx filters . FilterContext ) { // change data in ctx.Request() for example } func ( f * myFilter ) Response ( ctx filters . FilterContext ) { // change data in ctx.Response() for example } Find a detailed example at how to develop a filter . Predicates \u00b6 Predicates allow to match a condition, that can be based on arbitrary HTTP data in the Request. There are also predicates, that use a chance Traffic() or the current local time, for example After() , to match a request and do not use the HTTP data at all. A predicate consists of at least two types routing.Predicate and routing.PredicateSpec , which are both interfaces. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the routing.PredicateSpec interface Name() string and Create([]interface{}) (routing.Predicate, error) . The actual predicate implementation has to satisfy the routing.Predicate interface Match(*http.Request) bool and returns true if the predicate matches the request. If false is returned, the routing table will be searched for another route that might match the given request. The simplest possible predicate implementation is, if routing.PredicateSpec and routing.Predicate are the same type: type myPredicate struct {} func NewMyPredicate () routing . PredicateSpec { return & myPredicate {} } func ( spec * myPredicate ) Name () string { return \"myPredicate\" } func ( spec * myPredicate ) Create ( config [] interface {}) ( routing . Predicate , error ) { return NewMyPredicate (), nil } func ( f * myPredicate ) Match ( r * http . Request ) bool { // match data in *http.Request for example return true } Predicates are quite similar to implement as Filters, so for a more complete example, find an example how to develop a filter . Dataclients \u00b6 Dataclients are the way how to integrate new route sources. Dataclients pull information from a source and create routes for skipper\u2019s routing table. You have to implement routing.DataClient , which is an interface that defines function signatures LoadAll() ([]*eskip.Route, error) and LoadUpdate() ([]*eskip.Route, []string, error) . The LoadUpdate() method can be implemented either in a way that returns immediately, or blocks until there is a change. The routing package will regularly call the LoadUpdate() method with a small delay between the calls. A complete example is the routestring implementation , which fits in less than 50 lines of code. Opentracing \u00b6 Your custom Opentracing implementations need to satisfy the opentracing.Tracer interface from https://github.com/opentracing/opentracing-go and need to be loaded as a plugin, which might change in the future. Please check the tracing package and ask for further guidance in our community channels . Core \u00b6 Non trivial changes, proposals and enhancements to the core of skipper should be discussed first in a Github issue, such that we can think about how this fits best in the project and how to achieve the most useful result. Feel also free to reach out to our community channels and discuss there your idea. Every change in core has to have tests included and should be a non breaking change. We planned since a longer time a breaking change, but we should coordinate to make it as good as possible for all skipper as library users. Most often a breaking change can be postponed to the future and a feature independently added and the old feature might be deprecated to delete it later. Use of deprecated features should be shown in logs with a log.Warning .","title":"Development"},{"location":"tutorials/development/#docs","text":"We have user documentation and developer documentation separated. In docs/ you find the user documentation in mkdocs format and rendered at https://opensource.zalando.com/skipper . Developer documentation for skipper as library users godoc format is used and rendered at https://godoc.org/github.com/zalando/skipper .","title":"Docs"},{"location":"tutorials/development/#user-documentation","text":"","title":"User documentation"},{"location":"tutorials/development/#local-preview","text":"To see rendered documentation locally you need to replace /skipper path with / to see them correctly. This you can easily do with skipper in front of mkdocs serve . The following skipper inline route will do this for you, assuming that you build skipper with make skipper : ./bin/skipper -inline-routes 'r: * -> modPath(\"/skipper\", \"\") -> \"http://127.0.0.1:8000\"' Now you should be able to see the documentation at http://127.0.0.1:9090 .","title":"local Preview"},{"location":"tutorials/development/#filters","text":"Filters allow to change arbitrary HTTP data in the Request or Response. If you need to read and write the http.Body, please make sure you discuss the use case before creating a pull request. A filter consists of at least two types a filters.Spec and a filters.Filter . Spec consists of everything that is needed and known before a user will instantiate a filter. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the filters.Spec interface Name() string and CreateFilter([]interface{}) (filters.Filter, error) . The actual filter implementation has to satisfy the filter.Filter interface Request(filters.FilterContext) and Response(filters.FilterContext) . If you need to clean up for example a goroutine you can do it in Close() , which will be called on filter shutdown. The simplest filter possible is, if filters.Spec and filters.Filter are the same type: type myFilter struct {} func NewMyFilter () filters . Spec { return & myFilter {} } func ( spec * myFilter ) Name () string { return \"myFilter\" } func ( spec * myFilter ) CreateFilter ( config [] interface {}) ( filters . Filter , error ) { return NewMyFilter (), nil } func ( f * myFilter ) Request ( ctx filters . FilterContext ) { // change data in ctx.Request() for example } func ( f * myFilter ) Response ( ctx filters . FilterContext ) { // change data in ctx.Response() for example } Find a detailed example at how to develop a filter .","title":"Filters"},{"location":"tutorials/development/#predicates","text":"Predicates allow to match a condition, that can be based on arbitrary HTTP data in the Request. There are also predicates, that use a chance Traffic() or the current local time, for example After() , to match a request and do not use the HTTP data at all. A predicate consists of at least two types routing.Predicate and routing.PredicateSpec , which are both interfaces. A spec will be created in the bootstrap procedure of a skipper process. A spec has to satisfy the routing.PredicateSpec interface Name() string and Create([]interface{}) (routing.Predicate, error) . The actual predicate implementation has to satisfy the routing.Predicate interface Match(*http.Request) bool and returns true if the predicate matches the request. If false is returned, the routing table will be searched for another route that might match the given request. The simplest possible predicate implementation is, if routing.PredicateSpec and routing.Predicate are the same type: type myPredicate struct {} func NewMyPredicate () routing . PredicateSpec { return & myPredicate {} } func ( spec * myPredicate ) Name () string { return \"myPredicate\" } func ( spec * myPredicate ) Create ( config [] interface {}) ( routing . Predicate , error ) { return NewMyPredicate (), nil } func ( f * myPredicate ) Match ( r * http . Request ) bool { // match data in *http.Request for example return true } Predicates are quite similar to implement as Filters, so for a more complete example, find an example how to develop a filter .","title":"Predicates"},{"location":"tutorials/development/#dataclients","text":"Dataclients are the way how to integrate new route sources. Dataclients pull information from a source and create routes for skipper\u2019s routing table. You have to implement routing.DataClient , which is an interface that defines function signatures LoadAll() ([]*eskip.Route, error) and LoadUpdate() ([]*eskip.Route, []string, error) . The LoadUpdate() method can be implemented either in a way that returns immediately, or blocks until there is a change. The routing package will regularly call the LoadUpdate() method with a small delay between the calls. A complete example is the routestring implementation , which fits in less than 50 lines of code.","title":"Dataclients"},{"location":"tutorials/development/#opentracing","text":"Your custom Opentracing implementations need to satisfy the opentracing.Tracer interface from https://github.com/opentracing/opentracing-go and need to be loaded as a plugin, which might change in the future. Please check the tracing package and ask for further guidance in our community channels .","title":"Opentracing"},{"location":"tutorials/development/#core","text":"Non trivial changes, proposals and enhancements to the core of skipper should be discussed first in a Github issue, such that we can think about how this fits best in the project and how to achieve the most useful result. Feel also free to reach out to our community channels and discuss there your idea. Every change in core has to have tests included and should be a non breaking change. We planned since a longer time a breaking change, but we should coordinate to make it as good as possible for all skipper as library users. Most often a breaking change can be postponed to the future and a feature independently added and the old feature might be deprecated to delete it later. Use of deprecated features should be shown in logs with a log.Warning .","title":"Core"},{"location":"tutorials/operations/","text":"Kubernetes \u00b6 In the beginning we chose to run Skipper as daemonset to run it on all worker nodes. Since 2018 we run Skipper as deployment with an hpa, horizontal Pod autoscaler, to scale Skipper by CPU usage. All our clusters are using AWS autoscaling groups (ASG), to increase and decrease the number of running nodes in a cluster based on use. In both deployment styles we run Skipper with hostnetwork: true and point the loadbalancer in front of it to the skipper port of all worker nodes. In our case we run an AWS Application loadbalancer (ALB) in front, and we terminate TLS on the ALB. A health check from the ALB detects, if Skipper is running on a worker node or not. First steps \u00b6 The next part will show you how to run Skipper with a minimal feature set, that supports already most of the features. A minimal set of arguments that should be chosen to support most Kubernetes use cases: - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=prometheus\" - \"-metrics-exp-decay-sample\" - \"-serve-host-metrics\" - \"-disable-metrics-compat\" - \"-enable-connection-metrics\" - \"-histogram-metric-buckets=.0001,.00025,.0005,.00075,.001,.0025,.005,.0075,.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" - \"-max-audit-body=0\" - \"-idle-timeout-server=62s\" Skipper started with these options will support instance based ratelimits, a wide range of Prometheus metrics, websockets and a better HTTP path routing than the default Kubernetes Ingress spec supports. The Kubernetes Ingress spec defines a path as regular expression, which is not what most people would expect, nor want. Skipper defaults in Kubernetes to use the PathRegexp predicate for routing, because of the spec. We believe the better default is the path prefix mode, that uses PathSubtree predicate , instead. Path prefix search is much more scalable and can not lead to unexpected results by not so experienced regular expressions users. To find more information about Metrics, including formats and example Prometheus queries you find in the metrics section . The settings shown above support system and application metrics to carefully monitor Skipper and your backend applications. Backend application metrics get error rates and latency buckets based on host headers. The chosen options are a good setup to safely run all workloads from small to high traffic. The option -max-audit-body=0 , won\u2019t log the HTTP body, if you would do audit logging, to have a safe default. The last option -idle-timeout-server=62s was chosen, because of a known issue , if you run in a multi layer loadbalancer, with ALBs in front of Skipper. ALBs idle connection timeout is 60s and AWS support told us to run the backends with a bigger timeout, than the ALB in front. Opt-In more features \u00b6 Depending on the HTTP loadbalancer in front of your Skippers, you might want to set -reverse-source-predicate . This setting reverses the lookup of the client IP to find it in the X-Forwarded-For header values. If you do not care about clientRatelimits based on X-Forwarded-For headers, you can also ignore this. Ratelimits can be calculated for the whole cluster instead of having only the instance based ratelimits. The common term we use in skipper documentation is cluster ratelimit . There are two option, but we highly recommend the use of Redis based cluster ratelimits. To support redis based cluster ratelimits you have to use -enable-swarm and add a list of URLs to redis -swarm-redis-urls=skipper-ingress-redis-0.skipper-ingress-redis.kube-system.svc.cluster.local:6379,skipper-ingress-redis-1.skipper-ingress-redis.kube-system.svc.cluster.local:6379 . We run redis as statefulset with a headless service to have predictable names. We chose to not use a persistent volume, because storing the data in memory is good enough for this use case. Skipper supports cluster internal service-to-service communication as part of running as an API Gateway with an East-West setup . You have to add -enable-kubernetes-east-west and optionally choose a domain -kubernetes-east-west-domain=.ingress.cluster.local . Be warned: There is a known bug , if you combine it with custom routes. As part of API Gateway features, skipper supports API monitoring and common authentication and authorization protocols in Microservices architectures. Skipper has support for different OpenTracing API vendors, including jaeger , lightstep and instana . For example to configure the lightstep opentracing plugin, with a searchable component and cluster tag you can use: - \"-opentracing=lightstep component-name=skipper-ingress token=$(LIGHTSTEP_TOKEN) collector=tracing-collector.endpoint:8444 cmd-line=skipper-ingress max-buffered-spans=4096 tag=cluster=mycluster\" . The LIGHTSTEP_TOKEN is passed as environment variable to the process. Skipper can also add global default filters , which will be automatically added to all routes. For example you can use -default-filters-prepend=\"enableAccessLog(4,5)\" to enable only access logs in case of HTTP codes 4xx or 5xx. In the specific case of *AccessLog filters and -default-filters-prepend , the default choice can be overridden by users via zalando.org/skipper-filter ingress annotation. Production example \u00b6 A full production deployment example you find at Zalando\u2019s configuration repository . Recommendations \u00b6 We recommend to run a loadbalancer in front of Skipper to terminate TLS, such that cluster users can not access your keys and certificates. While skipper supports SNI, hardware and cloud loadbalancers often have hardware support to terminate TLS. It\u2019s cheaper for you to offload TLS to these devices and trust your compute vendor. We recommend to start simple and grow the feature set from there. Check features, that are used in >60 production clusters in Zalando\u2019s configuration repository . Dashboards \u00b6 As an operator, build a Skipper dashboard and learn how Skipper and the Go runtime behaves with your workload. We successfully ran several load tests from 0 to 25k requests per seconds. The load test was ramping up in less than a minute with initially 3 Skipper Pods, with an HPA that has CPU target value of 100%. Operations dashboard: Application metrics dashboard:","title":"Operations"},{"location":"tutorials/operations/#kubernetes","text":"In the beginning we chose to run Skipper as daemonset to run it on all worker nodes. Since 2018 we run Skipper as deployment with an hpa, horizontal Pod autoscaler, to scale Skipper by CPU usage. All our clusters are using AWS autoscaling groups (ASG), to increase and decrease the number of running nodes in a cluster based on use. In both deployment styles we run Skipper with hostnetwork: true and point the loadbalancer in front of it to the skipper port of all worker nodes. In our case we run an AWS Application loadbalancer (ALB) in front, and we terminate TLS on the ALB. A health check from the ALB detects, if Skipper is running on a worker node or not.","title":"Kubernetes"},{"location":"tutorials/operations/#first-steps","text":"The next part will show you how to run Skipper with a minimal feature set, that supports already most of the features. A minimal set of arguments that should be chosen to support most Kubernetes use cases: - \"skipper\" - \"-kubernetes\" - \"-kubernetes-in-cluster\" - \"-kubernetes-path-mode=path-prefix\" - \"-address=:9999\" - \"-wait-first-route-load\" - \"-proxy-preserve-host\" - \"-enable-ratelimits\" - \"-experimental-upgrade\" - \"-lb-healthcheck-interval=3s\" - \"-metrics-flavour=prometheus\" - \"-metrics-exp-decay-sample\" - \"-serve-host-metrics\" - \"-disable-metrics-compat\" - \"-enable-connection-metrics\" - \"-histogram-metric-buckets=.0001,.00025,.0005,.00075,.001,.0025,.005,.0075,.01,.025,.05,.075,.1,.2,.3,.4,.5,.75,1,2,3,4,5,7,10,15,20,30,60,120,300,600\" - \"-max-audit-body=0\" - \"-idle-timeout-server=62s\" Skipper started with these options will support instance based ratelimits, a wide range of Prometheus metrics, websockets and a better HTTP path routing than the default Kubernetes Ingress spec supports. The Kubernetes Ingress spec defines a path as regular expression, which is not what most people would expect, nor want. Skipper defaults in Kubernetes to use the PathRegexp predicate for routing, because of the spec. We believe the better default is the path prefix mode, that uses PathSubtree predicate , instead. Path prefix search is much more scalable and can not lead to unexpected results by not so experienced regular expressions users. To find more information about Metrics, including formats and example Prometheus queries you find in the metrics section . The settings shown above support system and application metrics to carefully monitor Skipper and your backend applications. Backend application metrics get error rates and latency buckets based on host headers. The chosen options are a good setup to safely run all workloads from small to high traffic. The option -max-audit-body=0 , won\u2019t log the HTTP body, if you would do audit logging, to have a safe default. The last option -idle-timeout-server=62s was chosen, because of a known issue , if you run in a multi layer loadbalancer, with ALBs in front of Skipper. ALBs idle connection timeout is 60s and AWS support told us to run the backends with a bigger timeout, than the ALB in front.","title":"First steps"},{"location":"tutorials/operations/#opt-in-more-features","text":"Depending on the HTTP loadbalancer in front of your Skippers, you might want to set -reverse-source-predicate . This setting reverses the lookup of the client IP to find it in the X-Forwarded-For header values. If you do not care about clientRatelimits based on X-Forwarded-For headers, you can also ignore this. Ratelimits can be calculated for the whole cluster instead of having only the instance based ratelimits. The common term we use in skipper documentation is cluster ratelimit . There are two option, but we highly recommend the use of Redis based cluster ratelimits. To support redis based cluster ratelimits you have to use -enable-swarm and add a list of URLs to redis -swarm-redis-urls=skipper-ingress-redis-0.skipper-ingress-redis.kube-system.svc.cluster.local:6379,skipper-ingress-redis-1.skipper-ingress-redis.kube-system.svc.cluster.local:6379 . We run redis as statefulset with a headless service to have predictable names. We chose to not use a persistent volume, because storing the data in memory is good enough for this use case. Skipper supports cluster internal service-to-service communication as part of running as an API Gateway with an East-West setup . You have to add -enable-kubernetes-east-west and optionally choose a domain -kubernetes-east-west-domain=.ingress.cluster.local . Be warned: There is a known bug , if you combine it with custom routes. As part of API Gateway features, skipper supports API monitoring and common authentication and authorization protocols in Microservices architectures. Skipper has support for different OpenTracing API vendors, including jaeger , lightstep and instana . For example to configure the lightstep opentracing plugin, with a searchable component and cluster tag you can use: - \"-opentracing=lightstep component-name=skipper-ingress token=$(LIGHTSTEP_TOKEN) collector=tracing-collector.endpoint:8444 cmd-line=skipper-ingress max-buffered-spans=4096 tag=cluster=mycluster\" . The LIGHTSTEP_TOKEN is passed as environment variable to the process. Skipper can also add global default filters , which will be automatically added to all routes. For example you can use -default-filters-prepend=\"enableAccessLog(4,5)\" to enable only access logs in case of HTTP codes 4xx or 5xx. In the specific case of *AccessLog filters and -default-filters-prepend , the default choice can be overridden by users via zalando.org/skipper-filter ingress annotation.","title":"Opt-In more features"},{"location":"tutorials/operations/#production-example","text":"A full production deployment example you find at Zalando\u2019s configuration repository .","title":"Production example"},{"location":"tutorials/operations/#recommendations","text":"We recommend to run a loadbalancer in front of Skipper to terminate TLS, such that cluster users can not access your keys and certificates. While skipper supports SNI, hardware and cloud loadbalancers often have hardware support to terminate TLS. It\u2019s cheaper for you to offload TLS to these devices and trust your compute vendor. We recommend to start simple and grow the feature set from there. Check features, that are used in >60 production clusters in Zalando\u2019s configuration repository .","title":"Recommendations"},{"location":"tutorials/operations/#dashboards","text":"As an operator, build a Skipper dashboard and learn how Skipper and the Go runtime behaves with your workload. We successfully ran several load tests from 0 to 25k requests per seconds. The load test was ramping up in less than a minute with initially 3 Skipper Pods, with an HPA that has CPU target value of 100%. Operations dashboard: Application metrics dashboard:","title":"Dashboards"},{"location":"tutorials/ratelimit/","text":"Overview \u00b6 Ratelimits are calculated for a number of requests and a time.Duration for a given bucket. To enable rate limits you need to run skipper with -enable-ratelimits . A time.Duration is specified as string and can for example be \u201c10s\u201d for ten seconds, \u201c5m\u201d for five minutes or \u201c2h\u201d for two hours. As bucket skipper can use either the backend or some client information. In case of a backend ratelimit the bucket is only one global for one route. In case of a client ratelimit the buckets are created by the used ratelimit.Lookuper , which defaults to the X-Forwarded-For header, but can be also the Authorization header. So for the client ratelimit with X-Forwarded-For header, the client IP that the first proxy in the list sees will be used to lookup the bucket to count requests. Instance local Ratelimit \u00b6 Filters ratelimit() and clientRatelimit() calculate the ratelimit in a local view having no information about other skipper instances. Backend Ratelimit \u00b6 The backend ratelimit filter is ratelimit() and it is the simplest one. You can define how many requests a route allows for a given time.Duration to send to all backends of the route. This means that you can not limit traffic to a single backend instance. For example to limit the route to 10 requests per minute for each skipper instance, you can specify: ratelimit(10, \"1m\") Client Ratelimit \u00b6 The client ratelimit filter is clientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. For example to limit the route to 10 requests per minute for each skipper instance for the same client selected by the X-Forwarded-For header, you can specify: clientRatelimit(10, \"1m\") There is an optional third argument that selects the same client by HTTP header value. As an example for Authorization Header you would use: clientRatelimit(10, \"1m\", \"Authorization\") The optional third argument can create an AND combined Header ratelimit. The header names must be separated by , . For example all of the specified headers have to be the same to recognize them as the same client: clientRatelimit(10, \"1m\", \"X-Forwarded-For,Authorization,X-Foo\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run. Security Consideration \u00b6 ClientRatelimit works on data provided by the client. In theory an attacker likely can workaround all of your configurations. On the other hand there is always a pattern in attacks, and you are more likely being able to find the pattern and mitigate the attack, if you have a powerful tool like the provided clientRatelimit . Cluster Ratelimit \u00b6 A cluster ratelimit computes all requests for all skipper peers. This requires, that you run skipper with -enable-swarm and select one of the two implementations: Redis SWIM Make sure all requirements, that are dependent on the implementation and your dataclient in use. Redis based Cluster Ratelimits \u00b6 This solution is independent of the dataclient being used. You have to run N number of Redis instances, where N is > 0. Specify -swarm-redis-urls , multiple instances can be separated by , , for example: -swarm-redis-urls=redis1:6379,redis2:6379 . For running skipper in Kubernetes with this, see also Running with Redis based Cluster Ratelimits The implementation use redis ring to be able to shard via client hashing and spread the load across multiple Redis instances to be able to scale out the shared storage. The ratelimit algorithm is a sliding window and makes use of the following Redis commands: ZREMRANGEBYSCORE , ZCARD , ZADD and ZRANGEBYSCORE SWIM based Cluster Ratelimits \u00b6 SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting to use for cluster ratelimits. The implementation has some weaknesses in the algorithm, that lead sometimes to too much ratelimits or too few and therefore is not considered to be stable. For running skipper in Kubernetes with this, see also Running with SWIM based Cluster Ratelimits In case of Kubernetes you might specify additionally -swarm-label-selector-key , which defaults to \u201capplication\u201d and -swarm-label-selector-value , which defaults to \u201cskipper-ingress\u201d and -swarm-namespace , which defaults to \u201ckube-system\u201d. The following shows the setup of a SWIM based cluster ratelimit: Backend Ratelimit \u00b6 The backend ratelimit filter is clusterRatelimit() . You can define how many requests a route allows for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupA\u201d limits the rate limit group to 10 requests per minute in total for the cluster, you can specify: clusterRatelimit(\"groupA\", 10, \"1m\") Client Ratelimit \u00b6 The client ratelimit filter is clusterClientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. You can define how many requests a client is allowed to hit this route for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupB\u201d limits the rate limit group to 10 requests per minute for the full skipper swarm for the same client selected by the X-Forwarded-For header, you can specify: clusterClientRatelimit(\"groupB\", 10, \"1m\") The same for Authorization Header you would use: clusterClientRatelimit(\"groupC\", 10, \"1m\", \"Authorization) The optional fourth argument can create an AND combined Header ratelimit. The header names must be separated by , . For example all of the specified headers have to be the same to recognize them as the same client: clusterClientRatelimit(\"groupC\", 5, \"10s\", \"X-Forwarded-For,Authorization,X-Foo\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run. Security Consideration \u00b6 ClusterClientRatelimit works on data provided by the client. In theory an attacker likely can workaround all of your configurations. On the other hand there is always a pattern in attacks, and you are more likely being able to find the pattern and mitigate the attack, if you have a powerful tool like the provided clusterClientRatelimit .","title":"Ratelimits"},{"location":"tutorials/ratelimit/#overview","text":"Ratelimits are calculated for a number of requests and a time.Duration for a given bucket. To enable rate limits you need to run skipper with -enable-ratelimits . A time.Duration is specified as string and can for example be \u201c10s\u201d for ten seconds, \u201c5m\u201d for five minutes or \u201c2h\u201d for two hours. As bucket skipper can use either the backend or some client information. In case of a backend ratelimit the bucket is only one global for one route. In case of a client ratelimit the buckets are created by the used ratelimit.Lookuper , which defaults to the X-Forwarded-For header, but can be also the Authorization header. So for the client ratelimit with X-Forwarded-For header, the client IP that the first proxy in the list sees will be used to lookup the bucket to count requests.","title":"Overview"},{"location":"tutorials/ratelimit/#instance-local-ratelimit","text":"Filters ratelimit() and clientRatelimit() calculate the ratelimit in a local view having no information about other skipper instances.","title":"Instance local Ratelimit"},{"location":"tutorials/ratelimit/#backend-ratelimit","text":"The backend ratelimit filter is ratelimit() and it is the simplest one. You can define how many requests a route allows for a given time.Duration to send to all backends of the route. This means that you can not limit traffic to a single backend instance. For example to limit the route to 10 requests per minute for each skipper instance, you can specify: ratelimit(10, \"1m\")","title":"Backend Ratelimit"},{"location":"tutorials/ratelimit/#client-ratelimit","text":"The client ratelimit filter is clientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. For example to limit the route to 10 requests per minute for each skipper instance for the same client selected by the X-Forwarded-For header, you can specify: clientRatelimit(10, \"1m\") There is an optional third argument that selects the same client by HTTP header value. As an example for Authorization Header you would use: clientRatelimit(10, \"1m\", \"Authorization\") The optional third argument can create an AND combined Header ratelimit. The header names must be separated by , . For example all of the specified headers have to be the same to recognize them as the same client: clientRatelimit(10, \"1m\", \"X-Forwarded-For,Authorization,X-Foo\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run.","title":"Client Ratelimit"},{"location":"tutorials/ratelimit/#security-consideration","text":"ClientRatelimit works on data provided by the client. In theory an attacker likely can workaround all of your configurations. On the other hand there is always a pattern in attacks, and you are more likely being able to find the pattern and mitigate the attack, if you have a powerful tool like the provided clientRatelimit .","title":"Security Consideration"},{"location":"tutorials/ratelimit/#cluster-ratelimit","text":"A cluster ratelimit computes all requests for all skipper peers. This requires, that you run skipper with -enable-swarm and select one of the two implementations: Redis SWIM Make sure all requirements, that are dependent on the implementation and your dataclient in use.","title":"Cluster Ratelimit"},{"location":"tutorials/ratelimit/#redis-based-cluster-ratelimits","text":"This solution is independent of the dataclient being used. You have to run N number of Redis instances, where N is > 0. Specify -swarm-redis-urls , multiple instances can be separated by , , for example: -swarm-redis-urls=redis1:6379,redis2:6379 . For running skipper in Kubernetes with this, see also Running with Redis based Cluster Ratelimits The implementation use redis ring to be able to shard via client hashing and spread the load across multiple Redis instances to be able to scale out the shared storage. The ratelimit algorithm is a sliding window and makes use of the following Redis commands: ZREMRANGEBYSCORE , ZCARD , ZADD and ZRANGEBYSCORE","title":"Redis based Cluster Ratelimits"},{"location":"tutorials/ratelimit/#swim-based-cluster-ratelimits","text":"SWIM is a \u201cScalable Weakly-consistent Infection-style Process Group Membership Protocol\u201d, which is very interesting to use for cluster ratelimits. The implementation has some weaknesses in the algorithm, that lead sometimes to too much ratelimits or too few and therefore is not considered to be stable. For running skipper in Kubernetes with this, see also Running with SWIM based Cluster Ratelimits In case of Kubernetes you might specify additionally -swarm-label-selector-key , which defaults to \u201capplication\u201d and -swarm-label-selector-value , which defaults to \u201cskipper-ingress\u201d and -swarm-namespace , which defaults to \u201ckube-system\u201d. The following shows the setup of a SWIM based cluster ratelimit:","title":"SWIM based Cluster Ratelimits"},{"location":"tutorials/ratelimit/#backend-ratelimit_1","text":"The backend ratelimit filter is clusterRatelimit() . You can define how many requests a route allows for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupA\u201d limits the rate limit group to 10 requests per minute in total for the cluster, you can specify: clusterRatelimit(\"groupA\", 10, \"1m\")","title":"Backend Ratelimit"},{"location":"tutorials/ratelimit/#client-ratelimit_1","text":"The client ratelimit filter is clusterClientRatelimit() and it uses information from the request to find the bucket which will get the increased request count. You can define how many requests a client is allowed to hit this route for a given time.Duration in total for all skipper instances summed up. The first parameter is the group parameter, which can be used to select the same ratelimit group across one or more routes For example rate limit \u201cgroupB\u201d limits the rate limit group to 10 requests per minute for the full skipper swarm for the same client selected by the X-Forwarded-For header, you can specify: clusterClientRatelimit(\"groupB\", 10, \"1m\") The same for Authorization Header you would use: clusterClientRatelimit(\"groupC\", 10, \"1m\", \"Authorization) The optional fourth argument can create an AND combined Header ratelimit. The header names must be separated by , . For example all of the specified headers have to be the same to recognize them as the same client: clusterClientRatelimit(\"groupC\", 5, \"10s\", \"X-Forwarded-For,Authorization,X-Foo\") Internally skipper has a clean interval to clean up old buckets to reduce the memory footprint in the long run.","title":"Client Ratelimit"},{"location":"tutorials/ratelimit/#security-consideration_1","text":"ClusterClientRatelimit works on data provided by the client. In theory an attacker likely can workaround all of your configurations. On the other hand there is always a pattern in attacks, and you are more likely being able to find the pattern and mitigate the attack, if you have a powerful tool like the provided clusterClientRatelimit .","title":"Security Consideration"},{"location":"tutorials/shadow-traffic/","text":"Shadow Traffic \u00b6 This tutorial will show how to setup routing for shadow traffic, where one backend (main) will receive the full traffic, while a shadowing backend (test) will receive only a certain percentage of the same traffic. Used Predicates: \u00b6 Tee Traffic Used Filters: \u00b6 teeLoopback 1. Initial state \u00b6 Before the shadow traffic, we are sending all traffic to the main backend. main : * - > \"https://main.example.org\" ; 2. Clone the main route, handling 10% of the traffic \u00b6 Before generating the shadow traffic, we create an identical clone of the main route that will handle only 10% of the traffic, while the rest stays being handled by the main route. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > \"https://main.example.org\" ; 3. Prepare the route for the shadow traffic \u00b6 The route introduced next won\u2019t handle directly any incoming requests, because they won\u2019t be matched by the Tee predicate, but it is prepared to send tee requests to the alternative, \u2018shadow\u2019 backend. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > \"https://main.example.org\" ; shadow : Tee ( \"shadow-test-1\" ) && True () - > \"https://shadow.example.org\" ; 4. Apply the teeLoopback filter \u00b6 Now we can apply the teeLoopback filter to the \u2018split\u2019 route, using the same label as we did in the Tee predicate. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > teeLoopback ( \"shadow-test-1\" ) - > \"https://main.example.org\" ; shadow : Tee ( \"shadow-test-1\" ) && True () - > \"https://shadow.example.org\" ; Note that as of now, we need to increase the weight of the \u2018shadow\u2019 route by adding the True() predicate in order to avoid that the \u2018split\u2019 route would match the cloned request again. After this, the \u2018split\u2019 route will still send all the handled requests, 10% of the total traffic, to the main backend, while the rest of the traffic is routed there by the \u2018main\u2019 route. However, the teeLoopback filter will also clone the traffic of the \u2018split\u2019 route, 10% of the total, and reapply the routing on it, during which these requests will be matched by the Tee predicate, and sent to the shadow backend.","title":"Shadow Traffic"},{"location":"tutorials/shadow-traffic/#shadow-traffic","text":"This tutorial will show how to setup routing for shadow traffic, where one backend (main) will receive the full traffic, while a shadowing backend (test) will receive only a certain percentage of the same traffic.","title":"Shadow Traffic"},{"location":"tutorials/shadow-traffic/#used-predicates","text":"Tee Traffic","title":"Used Predicates:"},{"location":"tutorials/shadow-traffic/#used-filters","text":"teeLoopback","title":"Used Filters:"},{"location":"tutorials/shadow-traffic/#1-initial-state","text":"Before the shadow traffic, we are sending all traffic to the main backend. main : * - > \"https://main.example.org\" ;","title":"1. Initial state"},{"location":"tutorials/shadow-traffic/#2-clone-the-main-route-handling-10-of-the-traffic","text":"Before generating the shadow traffic, we create an identical clone of the main route that will handle only 10% of the traffic, while the rest stays being handled by the main route. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > \"https://main.example.org\" ;","title":"2. Clone the main route, handling 10% of the traffic"},{"location":"tutorials/shadow-traffic/#3-prepare-the-route-for-the-shadow-traffic","text":"The route introduced next won\u2019t handle directly any incoming requests, because they won\u2019t be matched by the Tee predicate, but it is prepared to send tee requests to the alternative, \u2018shadow\u2019 backend. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > \"https://main.example.org\" ; shadow : Tee ( \"shadow-test-1\" ) && True () - > \"https://shadow.example.org\" ;","title":"3. Prepare the route for the shadow traffic"},{"location":"tutorials/shadow-traffic/#4-apply-the-teeloopback-filter","text":"Now we can apply the teeLoopback filter to the \u2018split\u2019 route, using the same label as we did in the Tee predicate. main : * - > \"https://main.example.org\" ; split : Traffic ( . 1 ) - > teeLoopback ( \"shadow-test-1\" ) - > \"https://main.example.org\" ; shadow : Tee ( \"shadow-test-1\" ) && True () - > \"https://shadow.example.org\" ; Note that as of now, we need to increase the weight of the \u2018shadow\u2019 route by adding the True() predicate in order to avoid that the \u2018split\u2019 route would match the cloned request again. After this, the \u2018split\u2019 route will still send all the handled requests, 10% of the total traffic, to the main backend, while the rest of the traffic is routed there by the \u2018main\u2019 route. However, the teeLoopback filter will also clone the traffic of the \u2018split\u2019 route, 10% of the total, and reapply the routing on it, during which these requests will be matched by the Tee predicate, and sent to the shadow backend.","title":"4. Apply the teeLoopback filter"},{"location":"tutorials/video-howto-build/","text":"How to build Skipper \u00b6 We expect you to have Go and glide installed. How to build Skipper without plugins \u00b6 How to build Skipper with plugins \u00b6 TODO How to run Skipper \u00b6 We expect you to have already built Skipper. TODO","title":"Video - How to build"},{"location":"tutorials/video-howto-build/#how-to-build-skipper","text":"We expect you to have Go and glide installed.","title":"How to build Skipper"},{"location":"tutorials/video-howto-build/#how-to-build-skipper-without-plugins","text":"","title":"How to build Skipper without plugins"},{"location":"tutorials/video-howto-build/#how-to-build-skipper-with-plugins","text":"TODO","title":"How to build Skipper with plugins"},{"location":"tutorials/video-howto-build/#how-to-run-skipper","text":"We expect you to have already built Skipper. TODO","title":"How to run Skipper"}]}